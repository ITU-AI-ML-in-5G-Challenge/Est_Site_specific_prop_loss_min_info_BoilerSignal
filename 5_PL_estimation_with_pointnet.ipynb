{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55daa7ed-1b5d-4cb7-8ff6-3fc7eba80c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mkrishne/default/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d606f0-7b19-4980-9c7b-c25d10e7fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mkrishne/PL_competition\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be203d1c-c67a-416b-8db7-d63826c7219d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in /home/mkrishne/default/lib/python3.10/site-packages (2.7.0)\n",
      "Collecting torch_scatter\n",
      "  Using cached torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl\n",
      "Collecting torch_sparse\n",
      "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch_cluster\n",
      "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pyg_lib (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for pyg_lib\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install torch_geometric torch_scatter torch_sparse torch_cluster pyg_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b795f25-a974-45c7-ac64-3c9017d73148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Reading Tx coordinates and selecting 3 diverse points ---\n",
      "\n",
      "Loaded 15 coordinates.\n",
      "Selected point 1: Index 0 (Folder: tx_sphere_Tx_1) Coords: [4342.70852986 2714.91536661   42.7       ]\n",
      "Selected point 2: Index 7 (Folder: tx_sphere_Tx_18) Coords: [5680.98977986 5196.16536661   83.9       ]\n",
      "Selected point 3: Index 14 (Folder: tx_sphere_Tx_8) Coords: [4311.33352986 4357.16536661   70.3       ]\n",
      "\n",
      "--- Final {num_points_to_select} diverse Tx points: ---\n",
      "  Folder: tx_sphere_Tx_1, Coords: [4342.70852986 2714.91536661   42.7       ]\n",
      "  Folder: tx_sphere_Tx_18, Coords: [5680.98977986 5196.16536661   83.9       ]\n",
      "  Folder: tx_sphere_Tx_8, Coords: [4311.33352986 4357.16536661   70.3       ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# --- Configuration ---\n",
    "base_dir = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "folder_names = [\n",
    "    \"tx_sphere_Tx_1\", \"tx_sphere_Tx_10\", \"tx_sphere_Tx_11\", \"tx_sphere_Tx_13\",\n",
    "    \"tx_sphere_Tx_15\", \"tx_sphere_Tx_16\", \"tx_sphere_Tx_17\", \"tx_sphere_Tx_18\",\n",
    "    \"tx_sphere_Tx_19\", \"tx_sphere_Tx_2\", \"tx_sphere_Tx_3\", \"tx_sphere_Tx_4\",\n",
    "    \"tx_sphere_Tx_6\", \"tx_sphere_Tx_7\", \"tx_sphere_Tx_8\"\n",
    "]\n",
    "npz_filename = \"pair00000_tx_sphere50.npz\"\n",
    "key_name = \"Tx\"\n",
    "num_points_to_select = 3\n",
    "# ---------------------\n",
    "\n",
    "print(f\"--- Reading Tx coordinates and selecting {num_points_to_select} diverse points ---\")\n",
    "\n",
    "all_coords_list = []\n",
    "all_folder_names = []\n",
    "\n",
    "# --- 1. Load all coordinates ---\n",
    "for folder in folder_names:\n",
    "    file_path = os.path.join(base_dir, folder, npz_filename)\n",
    "    try:\n",
    "        data = np.load(file_path)\n",
    "        if key_name in data:\n",
    "            tx_coords = data[key_name]\n",
    "            # Ensure coordinates are 1D array of 3 numbers\n",
    "            if tx_coords.ndim == 1 and tx_coords.shape[0] == 3:\n",
    "                 all_coords_list.append(tx_coords)\n",
    "                 all_folder_names.append(folder)\n",
    "            elif tx_coords.ndim == 2 and tx_coords.shape == (1, 3):\n",
    "                 all_coords_list.append(tx_coords.flatten()) # Flatten if shape is (1, 3)\n",
    "                 all_folder_names.append(folder)\n",
    "            else:\n",
    "                print(f\"  Warning: Skipping {folder}. Unexpected coordinate shape: {tx_coords.shape}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"  Warning: Key '{key_name}' not found in {file_path}. Skipping folder.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  Warning: File not found: {file_path}. Skipping folder.\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Error processing {folder}: {e}. Skipping folder.\")\n",
    "\n",
    "if len(all_coords_list) < num_points_to_select:\n",
    "    print(f\"\\nError: Only found {len(all_coords_list)} valid coordinates. Cannot select {num_points_to_select}.\")\n",
    "else:\n",
    "    all_coords = np.array(all_coords_list)\n",
    "    num_total_points = all_coords.shape[0]\n",
    "    print(f\"\\nLoaded {num_total_points} coordinates.\")\n",
    "\n",
    "    selected_indices = []\n",
    "    remaining_indices = list(range(num_total_points))\n",
    "\n",
    "    # --- 2. Iterative Farthest Point Selection ---\n",
    "    # Start with the first point (or could be random)\n",
    "    start_index = 0\n",
    "    selected_indices.append(start_index)\n",
    "    remaining_indices.pop(start_index)\n",
    "    print(f\"Selected point 1: Index {start_index} (Folder: {all_folder_names[start_index]}) Coords: {all_coords[start_index]}\")\n",
    "\n",
    "\n",
    "    for i in range(1, num_points_to_select):\n",
    "        # Coordinates of already selected points\n",
    "        selected_coords = all_coords[selected_indices]\n",
    "        # Coordinates of remaining points\n",
    "        remaining_coords = all_coords[remaining_indices]\n",
    "\n",
    "        # Calculate distances from each remaining point to *all* selected points\n",
    "        # dists will have shape (num_remaining, num_selected)\n",
    "        dists = pairwise_distances(remaining_coords, selected_coords)\n",
    "\n",
    "        # Find the minimum distance from each remaining point to any selected point\n",
    "        # min_dists will have shape (num_remaining,)\n",
    "        min_dists = np.min(dists, axis=1)\n",
    "\n",
    "        # Find the index *within remaining_indices* of the point with the maximum minimum distance\n",
    "        farthest_remaining_idx = np.argmax(min_dists)\n",
    "\n",
    "        # Get the original index of that point\n",
    "        farthest_original_idx = remaining_indices[farthest_remaining_idx]\n",
    "\n",
    "        # Add to selected list and remove from remaining list\n",
    "        selected_indices.append(farthest_original_idx)\n",
    "        remaining_indices.pop(farthest_remaining_idx) # Remove by index within remaining_indices\n",
    "\n",
    "        print(f\"Selected point {i+1}: Index {farthest_original_idx} (Folder: {all_folder_names[farthest_original_idx]}) Coords: {all_coords[farthest_original_idx]}\")\n",
    "\n",
    "\n",
    "    # --- 3. Display Results ---\n",
    "    print(\"\\n--- Final {num_points_to_select} diverse Tx points: ---\")\n",
    "    selected_final_coords = all_coords[selected_indices]\n",
    "    selected_final_folders = [all_folder_names[i] for i in selected_indices]\n",
    "\n",
    "    for i in range(num_points_to_select):\n",
    "        print(f\"  Folder: {selected_final_folders[i]}, Coords: {selected_final_coords[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f11610-0466-4e5c-a751-f40d26bc2e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx_subset_selected = [1,19,18,8,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16526f4f-6af5-45fa-bfd4-428cfea59d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # Use only GPU 1\n",
    "\n",
    "# --- Rest of your imports ---\n",
    "import torch\n",
    "# ... other imports\n",
    "\n",
    "# --- Setup ---\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Old way\n",
    "# The line above will now automatically select the visible GPU (GPU 1) if cuda is available\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu') # Explicitly use the *first visible* GPU\n",
    "print(f\"Using device: {device}\")\n",
    "# ... rest of script ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59fb555b-47bc-43c1-ae01-f5e8878ee79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting script in: /home/mkrishne/PL_competition/extracted_regions/train\n",
      "Found 45 matching folders. Processing...\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_1 ---\n",
      "  Found 29551 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_10 ---\n",
      "  Found 26167 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_11 ---\n",
      "  Found 25263 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_13 ---\n",
      "  Found 24098 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_15 ---\n",
      "  Found 22348 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_16 ---\n",
      "  Found 22245 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_17 ---\n",
      "  Found 24730 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_18 ---\n",
      "  Found 26405 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_19 ---\n",
      "  Found 21283 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_2 ---\n",
      "  Found 23262 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_3 ---\n",
      "  Found 25100 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_4 ---\n",
      "  Found 23783 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_6 ---\n",
      "  Found 24512 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_7 ---\n",
      "  Found 23475 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 7GHz_processed__for_training_Tx_8 ---\n",
      "  Found 24016 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_1 ---\n",
      "  Found 29554 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_10 ---\n",
      "  Found 26169 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_11 ---\n",
      "  Found 25272 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_13 ---\n",
      "  Found 24160 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_15 ---\n",
      "  Found 22350 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_16 ---\n",
      "  Found 22246 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_17 ---\n",
      "  Found 24732 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_18 ---\n",
      "  Found 26404 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_19 ---\n",
      "  Found 21289 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_2 ---\n",
      "  Found 23263 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_3 ---\n",
      "  Found 25113 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_4 ---\n",
      "  Found 23831 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_6 ---\n",
      "  Found 24524 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_7 ---\n",
      "  Found 23499 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 800MHz_processed__for_training_Tx_8 ---\n",
      "  Found 24018 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_1 ---\n",
      "  Found 29473 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_10 ---\n",
      "  Found 25484 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_11 ---\n",
      "  Found 24388 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_13 ---\n",
      "  Found 23518 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_15 ---\n",
      "  Found 22241 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_16 ---\n",
      "  Found 21793 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_17 ---\n",
      "  Found 24108 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_18 ---\n",
      "  Found 26343 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_19 ---\n",
      "  Found 20833 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_2 ---\n",
      "  Found 23043 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_3 ---\n",
      "  Found 24540 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_4 ---\n",
      "  Found 22857 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_6 ---\n",
      "  Found 23773 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_7 ---\n",
      "  Found 22447 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Processing: 28GHz_processed__for_training_Tx_8 ---\n",
      "  Found 23411 total pair files (e.g., 'pair00000').\n",
      "  Successfully created 'random_subset' with 8000 IDs.\n",
      "\n",
      "--- Script finished ---\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "BASE_DIR = Path('/home/mkrishne/PL_competition/extracted_regions/train')  # Assumes you run this script from the parent directory\n",
    "FOLDER_PATTERN = '*_processed__for_training_Tx_*' # Pattern to find the target folders\n",
    "FILE_PATTERN = 'pair*_for_train.npy' # Pattern for the individual data files\n",
    "OUTPUT_FILENAME = 'random_subset' # The new file to be created in each folder\n",
    "SAMPLE_SIZE = 8000\n",
    "# ---------------------\n",
    "\n",
    "def create_random_subset_from_filenames():\n",
    "    \"\"\"\n",
    "    Finds all processed folders, scans for .npy files, and creates a\n",
    "    'random_subset' file in each containing a random sample of pair IDs.\n",
    "    \"\"\"\n",
    "    print(f\"Starting script in: {BASE_DIR.resolve()}\")\n",
    "    \n",
    "    # 1. Find all target folders\n",
    "    target_folders = [d for d in BASE_DIR.glob(FOLDER_PATTERN) if d.is_dir()]\n",
    "    \n",
    "    if not target_folders:\n",
    "        print(f\"Error: No folders found matching pattern '{FOLDER_PATTERN}'.\")\n",
    "        print(\"Please run this script from the directory containing all the 'freq_processed...' folders.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(target_folders)} matching folders. Processing...\")\n",
    "\n",
    "    for folder_path in target_folders:\n",
    "        print(f\"\\n--- Processing: {folder_path.name} ---\")\n",
    "\n",
    "        # 2. Find all .npy files matching the pattern\n",
    "        # We use .glob() to find the files and .stem to get the filename without .npy\n",
    "        # e.g., 'pair00000_for_train.npy' -> 'pair00000_for_train'\n",
    "        # We must adjust this if the ID is just 'pair00000'\n",
    "        \n",
    "        all_pair_files = list(folder_path.glob(FILE_PATTERN))\n",
    "        \n",
    "        if not all_pair_files:\n",
    "            print(f\"  [WARNING] No files found matching '{FILE_PATTERN}' in '{folder_path}'. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # 3. Extract the pair ID from the filename.\n",
    "        # We assume the ID is the filename without the '_for_train.npy' part\n",
    "        # Example: 'pair00000_for_train.npy' -> 'pair00000'\n",
    "        all_pair_ids_list = []\n",
    "        for f_path in all_pair_files:\n",
    "            # f_path.stem is 'pair00000_for_train'\n",
    "            # We split at the known suffix '_for_train'\n",
    "            pair_id = f_path.stem.split('_for_train')[0]\n",
    "            all_pair_ids_list.append(pair_id)\n",
    "\n",
    "        num_ids = len(all_pair_ids_list)\n",
    "        print(f\"  Found {num_ids} total pair files (e.g., '{all_pair_ids_list[0]}').\")\n",
    "\n",
    "        # 4. Randomly sample 8,000 IDs\n",
    "        if num_ids == 0:\n",
    "            print(\"  [WARNING] No IDs to sample. Creating an empty file.\")\n",
    "            subset_ids = []\n",
    "        elif num_ids < SAMPLE_SIZE:\n",
    "            print(f\"  [WARNING] Only {num_ids} IDs available (less than {SAMPLE_SIZE}). Using all of them.\")\n",
    "            subset_ids = all_pair_ids_list\n",
    "            random.shuffle(subset_ids) # Still randomize the order\n",
    "        else:\n",
    "            subset_ids = random.sample(all_pair_ids_list, SAMPLE_SIZE)\n",
    "        \n",
    "        # 5. & 6. Write the IDs to the new 'random_subset' file\n",
    "        output_file_path = folder_path / OUTPUT_FILENAME\n",
    "        with open(output_file_path, 'w') as f:\n",
    "            for pid in subset_ids:\n",
    "                f.write(f\"{pid}\\n\") # Write one ID per line\n",
    "\n",
    "        print(f\"  Successfully created '{output_file_path.name}' with {len(subset_ids)} IDs.\")\n",
    "\n",
    "    print(\"\\n--- Script finished ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_random_subset_from_filenames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "125aec85-d170-4e69-b71d-98f1dcf2911b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical Batch Size: 32\n",
      "Filtered to 15 folders for Tx IDs: [1, 18, 8, 19, 2]\n",
      "Using device: cuda:1\n",
      "Starting training with LEARNING_RATE = 0.01 for 10 epochs.\n",
      "Scanning 15 folders for files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning folders: 100%|██████████| 15/15 [00:01<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 372148 total potential files across all folders.\n",
      "Using 120000 files for training after sampling.\n",
      "Model Initialized: PointNetPathLoss (Dual-Stream Encoder)\n",
      "Target Encoder Output Dimension: 1536\n",
      "Total Trainable Parameters: 3,175,489\n",
      "No existing model found at pointnet_dual_stream_model.pth. Starting fresh from epoch 0.\n",
      "\n",
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 3750/3750 [11:32<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train RMSE:  21.8341\n",
      "Saving model checkpoint after epoch 1...\n",
      "Model saved to pointnet_dual_stream_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 3750/3750 [11:31<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train RMSE:  16.5587\n",
      "Saving model checkpoint after epoch 2...\n",
      "Model saved to pointnet_dual_stream_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 3750/3750 [11:31<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train RMSE:  15.5850\n",
      "Saving model checkpoint after epoch 3...\n",
      "Model saved to pointnet_dual_stream_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 3750/3750 [11:30<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train RMSE:  15.1135\n",
      "Saving model checkpoint after epoch 4...\n",
      "Model saved to pointnet_dual_stream_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 3750/3750 [11:30<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train RMSE:  14.6821\n",
      "Saving model checkpoint after epoch 5...\n",
      "Model saved to pointnet_dual_stream_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 3750/3750 [11:09<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train RMSE:  14.3362\n",
      "Saving model checkpoint after epoch 6...\n",
      "Model saved to pointnet_dual_stream_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 3750/3750 [11:30<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train RMSE:  14.0933\n",
      "Saving model checkpoint after epoch 7...\n",
      "Model saved to pointnet_dual_stream_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 3750/3750 [11:30<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train RMSE:  13.9100\n",
      "Saving model checkpoint after epoch 8...\n",
      "Model saved to pointnet_dual_stream_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 3750/3750 [11:29<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train RMSE:  13.6960\n",
      "Saving model checkpoint after epoch 9...\n",
      "Model saved to pointnet_dual_stream_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 3750/3750 [11:30<00:00,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train RMSE:  13.5521\n",
      "Saving model checkpoint after epoch 10...\n",
      "Model saved to pointnet_dual_stream_model.pth\n",
      "--- Training Complete ---\n",
      "Finished training. Final model state saved at pointnet_dual_stream_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random # Needed for sampling\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "# Base directory for all ..._for_training_Tx_... folders\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "\n",
    "# --- Checkpoint Configuration ---\n",
    "MODEL_SAVE_PATH = \"pointnet_dual_stream_model.pth\" # New save path\n",
    "# ... (rest of config) ...\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "print(f\"Physical Batch Size: {BATCH_SIZE}\")\n",
    "TX_SUBSET_SELECTED = [1, 18, 8, 19, 2]\n",
    "NUM_SAMPLES_PER_FOLDER = 8000\n",
    "FEATURE_DIM = 1536 # This will be the output of the encoder\n",
    "\n",
    "# List of ALL potential folders (will be filtered)\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_1\", \"28GHz_processed__for_training_Tx_10\",\n",
    "    \"28GHz_processed__for_training_Tx_11\", \"28GHz_processed__for_training_Tx_13\",\n",
    "    \"28GHz_processed__for_training_Tx_15\", \"28GHz_processed__for_training_Tx_16\",\n",
    "    \"28GHz_processed__for_training_Tx_17\", \"28GHz_processed__for_training_Tx_18\",\n",
    "    \"28GHz_processed__for_training_Tx_19\", \"28GHz_processed__for_training_Tx_2\",\n",
    "    \"28GHz_processed__for_training_Tx_3\", \"28GHz_processed__for_training_Tx_4\",\n",
    "    \"28GHz_processed__for_training_Tx_6\", \"28GHz_processed__for_training_Tx_7\",\n",
    "    \"28GHz_processed__for_training_Tx_8\",\n",
    "    \"7GHz_processed__for_training_Tx_1\", \"7GHz_processed__for_training_Tx_10\",\n",
    "    \"7GHz_processed__for_training_Tx_11\", \"7GHz_processed__for_training_Tx_13\",\n",
    "    \"7GHz_processed__for_training_Tx_15\", \"7GHz_processed__for_training_Tx_16\",\n",
    "    \"7GHz_processed__for_training_Tx_17\", \"7GHz_processed__for_training_Tx_18\",\n",
    "    \"7GHz_processed__for_training_Tx_19\", \"7GHz_processed__for_training_Tx_2\",\n",
    "    \"7GHz_processed__for_training_Tx_3\", \"7GHz_processed__for_training_Tx_4\",\n",
    "    \"7GHz_processed__for_training_Tx_6\", \"7GHz_processed__for_training_Tx_7\",\n",
    "    \"7GHz_processed__for_training_Tx_8\",\n",
    "    \"800MHz_processed__for_training_Tx_1\", \"800MHz_processed__for_training_Tx_10\",\n",
    "    \"800MHz_processed__for_training_Tx_11\", \"800MHz_processed__for_training_Tx_13\",\n",
    "    \"800MHz_processed__for_training_Tx_15\", \"800MHz_processed__for_training_Tx_16\",\n",
    "    \"800MHz_processed__for_training_Tx_17\", \"800MHz_processed__for_training_Tx_18\",\n",
    "    \"800MHz_processed__for_training_Tx_19\", \"800MHz_processed__for_training_Tx_2\",\n",
    "    \"800MHz_processed__for_training_Tx_3\", \"800MHz_processed__for_training_Tx_4\",\n",
    "    \"800MHz_processed__for_training_Tx_6\", \"800MHz_processed__for_training_Tx_7\",\n",
    "    \"800MHz_processed__for_training_Tx_8\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "ALL_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str\n",
    "]\n",
    "if not ALL_DATA_FOLDERS:\n",
    "    raise ValueError(\"No data folders found matching the TX_SUBSET_SELECTED. Check folder names and IDs.\")\n",
    "print(f\"Filtered to {len(ALL_DATA_FOLDERS)} folders for Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "\n",
    "# --- 2. Standard PyTorch Dataset (Same as before) ---\n",
    "class StandardPointCloudDataset(Dataset):\n",
    "    def __init__(self, data_folders, base_dir, num_samples_per_folder=None):\n",
    "        self.file_pairs = []\n",
    "        print(f\"Scanning {len(data_folders)} folders for files...\")\n",
    "        total_potential_files = 0\n",
    "\n",
    "        for folder_name in tqdm(data_folders, desc=\"Scanning folders\"):\n",
    "            folder_path = os.path.join(base_dir, folder_name)\n",
    "            potential_files_in_folder = []\n",
    "            input_files = sorted(glob.glob(os.path.join(folder_path, \"pair*_for_train.npy\")))\n",
    "\n",
    "            for input_path in input_files:\n",
    "                filename = os.path.basename(input_path)\n",
    "                pair_id_str = filename.split('_')[0].replace('pair', '')\n",
    "                label_filename = f\"pair{pair_id_str}_path_loss.npy\"\n",
    "                label_path = os.path.join(folder_path, label_filename)\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    potential_files_in_folder.append((input_path, label_path))\n",
    "\n",
    "            num_found_in_folder = len(potential_files_in_folder)\n",
    "            total_potential_files += num_found_in_folder\n",
    "\n",
    "            if num_samples_per_folder is not None and num_found_in_folder > num_samples_per_folder:\n",
    "                sampled_files_for_folder = random.sample(potential_files_in_folder, num_samples_per_folder)\n",
    "                self.file_pairs.extend(sampled_files_for_folder)\n",
    "            elif num_samples_per_folder is not None and num_found_in_folder < num_samples_per_folder:\n",
    "                 print(f\"  Warning: Found only {num_found_in_folder} files in {folder_name}, less than requested {num_samples_per_folder}. Using all found.\")\n",
    "                 self.file_pairs.extend(potential_files_in_folder)\n",
    "            else:\n",
    "                self.file_pairs.extend(potential_files_in_folder)\n",
    "\n",
    "        print(f\"\\nFound {total_potential_files} total potential files across all folders.\")\n",
    "        print(f\"Using {len(self.file_pairs)} files for training after sampling.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label = np.load(label_path).astype(np.float32)\n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_tensor = torch.from_numpy(label).squeeze()\n",
    "        return pc_tensor, label_tensor\n",
    "\n",
    "# --- 3. MODIFIED: Dual-Stream PointNet Model ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Modified PointNet encoder.\n",
    "    Processes (x,y,z) coordinates and (other) features in separate streams\n",
    "    before combining them. This is closer to the PointNet++ concept.\n",
    "    \"\"\"\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        \n",
    "        # --- Stream 1: Process Coordinates (x,y,z) ---\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "\n",
    "        # --- Stream 2: Process Features (is_bldg, f1, f2, f3) ---\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        \n",
    "        # --- Combined Stream ---\n",
    "        # Takes the concatenated features (128 from pos + 128 from feat = 256)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: (batch, input_dim, num_points), e.g., (batch, 7, 7000)\n",
    "        \n",
    "        # Split the input into coordinates and features\n",
    "        pos_stream = x[:, :3, :] # (batch, 3, 7000)\n",
    "        feat_stream = x[:, 3:, :] # (batch, 4, 7000)\n",
    "\n",
    "        # Process coordinates\n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out))) # (batch, 128, 7000)\n",
    "        \n",
    "        # Process features\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out))) # (batch, 128, 7000)\n",
    "\n",
    "        # Combine the processed streams\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1) # (batch, 256, 7000)\n",
    "\n",
    "        # Process the combined features\n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x))) # (batch, feature_dim_out, 7000)\n",
    "\n",
    "        # Global max pooling\n",
    "        x = torch.max(x, 2)[0]  # (batch, feature_dim_out)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    \"\"\"PointNet for path loss prediction (Regression Head)\"\"\"\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        # Use the new Dual-Stream Encoder\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "\n",
    "        # Regression head\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: (batch, num_points, input_dim), e.g., (batch, 7000, 7)\n",
    "        x = x.transpose(1, 2)  # -> (batch, 7, 7000)\n",
    "        \n",
    "        # Encoder processes the 7D input, splitting it internally\n",
    "        x = self.encoder(x) # -> (batch, feature_dim_encoder)\n",
    "\n",
    "        # Regression head\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "# --- 4. Main Training Script ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- Setup ---\n",
    "    device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Starting training with LEARNING_RATE = {LEARNING_RATE} for {NUM_EPOCHS} epochs.\")\n",
    "\n",
    "    # --- Create Datasets and Dataloaders ---\n",
    "    train_dataset = StandardPointCloudDataset(\n",
    "        data_folders=ALL_DATA_FOLDERS,\n",
    "        base_dir=BASE_TRAIN_DIR,\n",
    "        num_samples_per_folder=NUM_SAMPLES_PER_FOLDER\n",
    "    )\n",
    "\n",
    "    if len(train_dataset) == 0:\n",
    "        raise ValueError(\"Dataset is empty after filtering and sampling. Check paths and configuration.\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "\n",
    "    # --- Initialize Model ---\n",
    "    model = PointNetPathLoss().to(device) # This now uses the Dual-Stream model\n",
    "\n",
    "    # Calculate Model Size\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model Initialized: {model.__class__.__name__} (Dual-Stream Encoder)\")\n",
    "    print(f\"Target Encoder Output Dimension: {FEATURE_DIM}\")\n",
    "    print(f\"Total Trainable Parameters: {total_params:,}\")\n",
    "\n",
    "    # --- Load existing MODEL WEIGHTS if they exist ---\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"Loading existing model weights from {MODEL_SAVE_PATH}\")\n",
    "        try:\n",
    "            checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "            # Use strict=False, as the architecture has changed from the previous model\n",
    "            model.load_state_dict(checkpoint['model_state_dict'], strict=False) \n",
    "            print(\"Model weights loaded (non-strictly).\")\n",
    "            # Check if optimizer and epoch can be loaded (they probably won't match)\n",
    "            if 'optimizer_state_dict' in checkpoint and 'epoch' in checkpoint:\n",
    "                 # optimizer.load_state_dict(checkpoint['optimizer_state_dict']) # Better to start optimizer fresh with new arch\n",
    "                 # start_epoch = checkpoint['epoch'] + 1\n",
    "                 print(\"Starting from epoch 0 with fresh optimizer due to arch change.\")\n",
    "            else:\n",
    "                print(\"Starting from epoch 0.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model state dict: {e}. Starting fresh from epoch 0.\")\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        print(f\"No existing model found at {MODEL_SAVE_PATH}. Starting fresh from epoch 0.\")\n",
    "\n",
    "    # --- Initialize Loss and Optimizer ---\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for i, (pc_batch, label_batch) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")):\n",
    "            pc_batch = pc_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(pc_batch)\n",
    "            loss = criterion(out, label_batch)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"Warning: Encountered non-finite loss: {loss.item()} at step {i}. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * pc_batch.size(0)\n",
    "\n",
    "        if len(train_loader.dataset) > 0:\n",
    "             avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "             avg_train_rmse = np.sqrt(max(0, avg_train_loss))\n",
    "             print(f\"Epoch {epoch+1:02d} | Train RMSE: {avg_train_rmse:8.4f}\")\n",
    "        else:\n",
    "             print(f\"Epoch {epoch+1:02d} | No data processed.\")\n",
    "\n",
    "        # --- Save Checkpoint After Each Epoch ---\n",
    "        print(f\"Saving model checkpoint after epoch {epoch+1}...\")\n",
    "        try:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_train_loss,\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model checkpoint: {e}\")\n",
    "        # ----------------------------------------\n",
    "\n",
    "    print(\"--- Training Complete ---\")\n",
    "    print(f\"Finished training. Final model state saved at {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d16a4aa-6d48-4bfb-890a-91e9d15c2d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical Batch Size: 32\n",
      "Filtered to 15 folders for Tx IDs: [1, 18, 8, 19, 2]\n",
      "Using device: cuda\n",
      "Starting training with LEARNING_RATE = 0.01 for 20 epochs.\n",
      "Scanning 15 folders for 'random_subset' files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning folders: 100%|██████████| 15/15 [00:00<00:00, 19.87it/s]\n",
      "/tmp/ipykernel_87127/2284511277.py:280: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded a total of 120000 file pairs from all 'random_subset' files.\n",
      "Total dataset size: 120000 files.\n",
      "Model Initialized: PointNetPathLoss (Dual-Stream Encoder)\n",
      "Target Encoder Output Dimension: 1536\n",
      "Total Trainable Parameters: 3,175,489\n",
      "Loading existing checkpoint from pointnet_dual_stream_model_1536.pth\n",
      "Model weights loaded successfully.\n",
      "Optimizer state loaded. Resuming training from epoch 16.\n",
      "\n",
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Train]: 100%|██████████| 3750/3750 [05:10<00:00, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train RMSE:  12.7749\n",
      "Saving model checkpoint after epoch 16...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Train]: 100%|██████████| 3750/3750 [05:09<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train RMSE:  12.7071\n",
      "Saving model checkpoint after epoch 17...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Train]: 100%|██████████| 3750/3750 [05:09<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train RMSE:  12.6105\n",
      "Saving model checkpoint after epoch 18...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train RMSE:  12.5234\n",
      "Saving model checkpoint after epoch 19...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Train]: 100%|██████████| 3750/3750 [05:09<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train RMSE:  12.3919\n",
      "Saving model checkpoint after epoch 20...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n",
      "--- Training Complete ---\n",
      "Finished training. Final model state\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random # Needed for sampling\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "# Base directory for all ..._for_training_Tx_... folders\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "\n",
    "# --- Checkpoint Configuration ---\n",
    "MODEL_SAVE_PATH = \"pointnet_dual_stream_model_1536.pth\" # New save path\n",
    "# ... (rest of config) ...\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "print(f\"Physical Batch Size: {BATCH_SIZE}\")\n",
    "TX_SUBSET_SELECTED = [1, 18, 8, 19, 2]\n",
    "# NUM_SAMPLES_PER_FOLDER = 8000 # <-- This is no longer needed, we use 'random_subset'\n",
    "FEATURE_DIM = 1536 # This will be the output of the encoder\n",
    "\n",
    "# List of ALL potential folders (will be filtered)\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_1\", \"28GHz_processed__for_training_Tx_10\",\n",
    "    \"28GHz_processed__for_training_Tx_11\", \"28GHz_processed__for_training_Tx_13\",\n",
    "    \"28GHz_processed__for_training_Tx_15\", \"28GHz_processed__for_training_Tx_16\",\n",
    "    \"28GHz_processed__for_training_Tx_17\", \"28GHz_processed__for_training_Tx_18\",\n",
    "    \"28GHz_processed__for_training_Tx_19\", \"28GHz_processed__for_training_Tx_2\",\n",
    "    \"28GHz_processed__for_training_Tx_3\", \"28GHz_processed__for_training_Tx_4\",\n",
    "    \"28GHz_processed__for_training_Tx_6\", \"28GHz_processed__for_training_Tx_7\",\n",
    "    \"28GHz_processed__for_training_Tx_8\",\n",
    "    \"7GHz_processed__for_training_Tx_1\", \"7GHz_processed__for_training_Tx_10\",\n",
    "    \"7GHz_processed__for_training_Tx_11\", \"7GHz_processed__for_training_Tx_13\",\n",
    "    \"7GHz_processed__for_training_Tx_15\", \"7GHz_processed__for_training_Tx_16\",\n",
    "    \"7Gzz_processed__for_training_Tx_17\", \"7GHz_processed__for_training_Tx_18\",\n",
    "    \"7GHz_processed__for_training_Tx_19\", \"7GHz_processed__for_training_Tx_2\",\n",
    "    \"7GHz_processed__for_training_Tx_3\", \"7GHz_processed__for_training_Tx_4\",\n",
    "    \"7GHz_processed__for_training_Tx_6\", \"7GHz_processed__for_training_Tx_7\",\n",
    "    \"7GHz_processed__for_training_Tx_8\",\n",
    "    \"800MHz_processed__for_training_Tx_1\", \"800MHz_processed__for_training_Tx_10\",\n",
    "    \"800MHz_processed__for_training_Tx_11\", \"800MHz_processed__for_training_Tx_13\",\n",
    "    \"800MHz_processed__for_training_Tx_15\", \"800MHz_processed__for_training_Tx_16\",\n",
    "    \"800MHz_processed__for_training_Tx_17\", \"800MHz_processed__for_training_Tx_18\",\n",
    "    \"800MHz_processed__for_training_Tx_19\", \"800MHz_processed__for_training_Tx_2\",\n",
    "    \"800MHz_processed__for_training_Tx_3\", \"800MHz_processed__for_training_Tx_4\",\n",
    "    \"800MHz_processed__for_training_Tx_6\", \"800MHz_processed__for_training_Tx_7\",\n",
    "    \"800MHz_processed__for_training_Tx_8\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "ALL_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str\n",
    "]\n",
    "if not ALL_DATA_FOLDERS:\n",
    "    raise ValueError(\"No data folders found matching the TX_SUBSET_SELECTED. Check folder names and IDs.\")\n",
    "print(f\"Filtered to {len(ALL_DATA_FOLDERS)} folders for Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "\n",
    "# --- 2. MODIFIED: Dataset reads from 'random_subset' ---\n",
    "class StandardPointCloudDataset(Dataset):\n",
    "    def __init__(self, data_folders, base_dir):\n",
    "        self.file_pairs = []\n",
    "        print(f\"Scanning {len(data_folders)} folders for 'random_subset' files...\")\n",
    "        \n",
    "        total_files_loaded = 0\n",
    "\n",
    "        for folder_name in tqdm(data_folders, desc=\"Scanning folders\"):\n",
    "            folder_path = os.path.join(base_dir, folder_name)\n",
    "            # This is the file we created in the previous step\n",
    "            subset_file_path = os.path.join(folder_path, \"random_subset\")\n",
    "\n",
    "            if not os.path.exists(subset_file_path):\n",
    "                print(f\"\\n  Warning: 'random_subset' file not found in '{folder_name}'. Skipping folder.\")\n",
    "                continue\n",
    "            \n",
    "            files_in_this_folder = 0\n",
    "            try:\n",
    "                # Read all pair IDs from the subset file\n",
    "                with open(subset_file_path, 'r') as f:\n",
    "                    pair_ids = f.readlines()\n",
    "                \n",
    "                for pair_id in pair_ids:\n",
    "                    pair_id = pair_id.strip() # Remove newline characters (e.g., \"pair00000\\n\")\n",
    "                    if not pair_id: # Skip any empty lines\n",
    "                        continue\n",
    "                        \n",
    "                    # Construct filenames from the ID\n",
    "                    # e.g., pair_id = \"pair00123\"\n",
    "                    input_filename = f\"{pair_id}_for_train.npy\"\n",
    "                    label_filename = f\"{pair_id}_path_loss.npy\"\n",
    "                    \n",
    "                    input_path = os.path.join(folder_path, input_filename)\n",
    "                    label_path = os.path.join(folder_path, label_filename)\n",
    "\n",
    "                    # Check if both files actually exist before adding\n",
    "                    if os.path.exists(input_path) and os.path.exists(label_path):\n",
    "                        self.file_pairs.append((input_path, label_path))\n",
    "                        files_in_this_folder += 1\n",
    "                    else:\n",
    "                        # This warning is important, in case 'random_subset' is stale\n",
    "                        print(f\"\\n  Warning: Files for '{pair_id}' listed in 'random_subset' but not found in '{folder_name}'. Skipping.\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"\\n  Error reading 'random_subset' in '{folder_name}': {e}\")\n",
    "            \n",
    "            total_files_loaded += files_in_this_folder\n",
    "\n",
    "        print(f\"\\nLoaded a total of {total_files_loaded} file pairs from all 'random_subset' files.\")\n",
    "        print(f\"Total dataset size: {len(self.file_pairs)} files.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label = np.load(label_path).astype(np.float32)\n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_tensor = torch.from_numpy(label).squeeze()\n",
    "        return pc_tensor, label_tensor\n",
    "\n",
    "# --- 3. MODIFIED: Dual-Stream PointNet Model ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Modified PointNet encoder.\n",
    "    Processes (x,y,z) coordinates and (other) features in separate streams\n",
    "    before combining them. This is closer to the PointNet++ concept.\n",
    "    \"\"\"\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        \n",
    "        # --- Stream 1: Process Coordinates (x,y,z) ---\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "\n",
    "        # --- Stream 2: Process Features (is_bldg, f1, f2, f3) ---\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        \n",
    "        # --- Combined Stream ---\n",
    "        # Takes the concatenated features (128 from pos + 128 from feat = 256)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: (batch, input_dim, num_points), e.g., (batch, 7, 7000)\n",
    "        \n",
    "        # Split the input into coordinates and features\n",
    "        pos_stream = x[:, :3, :] # (batch, 3, 7000)\n",
    "        feat_stream = x[:, 3:, :] # (batch, 4, 7000)\n",
    "\n",
    "        # Process coordinates\n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out))) # (batch, 128, 7000)\n",
    "        \n",
    "        # Process features\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out))) # (batch, 128, 7000)\n",
    "\n",
    "        # Combine the processed streams\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1) # (batch, 256, 7000)\n",
    "\n",
    "        # Process the combined features\n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x))) # (batch, feature_dim_out, 7000)\n",
    "\n",
    "        # Global max pooling\n",
    "        x = torch.max(x, 2)[0]  # (batch, feature_dim_out)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    \"\"\"PointNet for path loss prediction (Regression Head)\"\"\"\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        # Use the new Dual-Stream Encoder\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "\n",
    "        # Regression head\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: (batch, num_points, input_dim), e.g., (batch, 7000, 7)\n",
    "        x = x.transpose(1, 2)  # -> (batch, 7, 7000)\n",
    "        \n",
    "        # Encoder processes the 7D input, splitting it internally\n",
    "        x = self.encoder(x) # -> (batch, feature_dim_encoder)\n",
    "\n",
    "        # Regression head\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "# --- 4. Main Training Script (WITH CHECKPOINT FIX) ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- Setup ---\n",
    "    # *** THIS IS THE FIX ***\n",
    "    # Use 'cuda' to automatically select the available GPU (e.g., cuda:0)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    # *** END FIX ***\n",
    "    \n",
    "    print(f\"Starting training with LEARNING_RATE = {LEARNING_RATE} for {NUM_EPOCHS} epochs.\")\n",
    "\n",
    "    # --- Create Datasets and Dataloaders ---\n",
    "    train_dataset = StandardPointCloudDataset(\n",
    "        data_folders=ALL_DATA_FOLDERS,\n",
    "        base_dir=BASE_TRAIN_DIR\n",
    "        # No 'num_samples_per_folder' needed, it's now controlled by 'random_subset'\n",
    "    )\n",
    "\n",
    "    if len(train_dataset) == 0:\n",
    "        raise ValueError(\"Dataset is empty after filtering and loading from 'random_subset' files. Check paths and files.\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "\n",
    "    # --- Initialize Model ---\n",
    "    model = PointNetPathLoss().to(device) # This now uses the Dual-Stream model\n",
    "\n",
    "    # Calculate Model Size\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model Initialized: {model.__class__.__name__} (Dual-Stream Encoder)\")\n",
    "    print(f\"Target Encoder Output Dimension: {FEATURE_DIM}\")\n",
    "    print(f\"Total Trainable Parameters: {total_params:,}\")\n",
    "    \n",
    "    # --- Initialize Loss and Optimizer (MOVED UP) ---\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    # --- Load existing MODEL and OPTIMIZER states ---\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"Loading existing checkpoint from {MODEL_SAVE_PATH}\")\n",
    "        try:\n",
    "            # The 'map_location=device' handles moving the checkpoint\n",
    "            # from one GPU (e.g., cuda:1) to another (e.g., cuda:0)\n",
    "            checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "            \n",
    "            # Load model weights (use strict=True if architecture is stable)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'], strict=True) \n",
    "            print(\"Model weights loaded successfully.\")\n",
    "            \n",
    "            # Check if optimizer and epoch are in the checkpoint\n",
    "            if 'optimizer_state_dict' in checkpoint and 'epoch' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                start_epoch = checkpoint['epoch'] + 1\n",
    "                print(f\"Optimizer state loaded. Resuming training from epoch {start_epoch + 1}.\")\n",
    "                \n",
    "                # Check if we've already finished training\n",
    "                if start_epoch >= NUM_EPOCHS:\n",
    "                    print(f\"Warning: Model has already completed {start_epoch} epochs. \")\n",
    "                    print(f\"         NUM_EPOCHS is set to {NUM_EPOCHS}. Increase NUM_EPOCHS to train further.\")\n",
    "            else:\n",
    "                print(\"Optimizer state/epoch not in checkpoint. Starting from epoch 0.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint: {e}. Starting fresh from epoch 0.\")\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        print(f\"No existing model found at {MODEL_SAVE_PATH}. Starting fresh from epoch 0.\")\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "    # Only train if start_epoch is less than NUM_EPOCHS\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        avg_train_loss = 0 # Initialize here\n",
    "\n",
    "        for i, (pc_batch, label_batch) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")):\n",
    "            pc_batch = pc_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(pc_batch)\n",
    "            loss = criterion(out, label_batch)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"Warning: Encountered non-finite loss: {loss.item()} at step {i}. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * pc_batch.size(0)\n",
    "\n",
    "        if len(train_loader.dataset) > 0:\n",
    "            avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "            avg_train_rmse = np.sqrt(max(0, avg_train_loss))\n",
    "            print(f\"Epoch {epoch+1:02d} | Train RMSE: {avg_train_rmse:8.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1:02d} | No data processed.\")\n",
    "\n",
    "        # --- Save Checkpoint After Each Epoch ---\n",
    "        print(f\"Saving model checkpoint after epoch {epoch+1}...\")\n",
    "        try:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_train_loss, # Save the average loss\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model checkpoint: {e}\")\n",
    "        # ----------------------------------------\n",
    "\n",
    "    print(\"--- Training Complete ---\")\n",
    "    if start_epoch >= NUM_EPOCHS:\n",
    "         print(f\"Training was already complete at {start_epoch} epochs.\")\n",
    "    else:\n",
    "        print(f\"Finished training. Final model state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b21a1dcb-632f-4d5c-a9d7-a4d8b71e2ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical Batch Size: 32\n",
      "Filtered to 15 folders for Tx IDs: [1, 18, 8, 19, 2]\n",
      "Using device: cuda\n",
      "Starting training with LEARNING_RATE = 0.001 for 50 epochs.\n",
      "Scanning 15 folders for 'random_subset' files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning folders: 100%|██████████| 15/15 [00:00<00:00, 20.75it/s]\n",
      "/tmp/ipykernel_87127/1862504709.py:280: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded a total of 120000 file pairs from all 'random_subset' files.\n",
      "Total dataset size: 120000 files.\n",
      "Model Initialized: PointNetPathLoss (Dual-Stream Encoder)\n",
      "Target Encoder Output Dimension: 1536\n",
      "Total Trainable Parameters: 3,175,489\n",
      "Loading existing checkpoint from pointnet_dual_stream_model_1536.pth\n",
      "Model weights loaded successfully.\n",
      "Optimizer state loaded. Resuming training from epoch 31.\n",
      "\n",
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [Train]: 100%|██████████| 3750/3750 [05:09<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train RMSE:  11.8113\n",
      "Saving model checkpoint after epoch 31...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 [Train]: 100%|██████████| 3750/3750 [05:09<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train RMSE:  11.7476\n",
      "Saving model checkpoint after epoch 32...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 [Train]: 100%|██████████| 3750/3750 [05:09<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train RMSE:  11.7358\n",
      "Saving model checkpoint after epoch 33...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train RMSE:  11.6376\n",
      "Saving model checkpoint after epoch 34...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train RMSE:  11.6029\n",
      "Saving model checkpoint after epoch 35...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train RMSE:  11.5774\n",
      "Saving model checkpoint after epoch 36...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 [Train]: 100%|██████████| 3750/3750 [05:09<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train RMSE:  11.5521\n",
      "Saving model checkpoint after epoch 37...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train RMSE:  11.5135\n",
      "Saving model checkpoint after epoch 38...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 [Train]: 100%|██████████| 3750/3750 [05:09<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train RMSE:  11.4843\n",
      "Saving model checkpoint after epoch 39...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 [Train]: 100%|██████████| 3750/3750 [05:09<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train RMSE:  11.4140\n",
      "Saving model checkpoint after epoch 40...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train RMSE:  11.4296\n",
      "Saving model checkpoint after epoch 41...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train RMSE:  11.4101\n",
      "Saving model checkpoint after epoch 42...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train RMSE:  11.4184\n",
      "Saving model checkpoint after epoch 43...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Train RMSE:  11.3911\n",
      "Saving model checkpoint after epoch 44...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train RMSE:  11.3132\n",
      "Saving model checkpoint after epoch 45...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 [Train]: 100%|██████████| 3750/3750 [05:09<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Train RMSE:  11.3187\n",
      "Saving model checkpoint after epoch 46...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Train RMSE:  11.2766\n",
      "Saving model checkpoint after epoch 47...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train RMSE:  11.2911\n",
      "Saving model checkpoint after epoch 48...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 [Train]: 100%|██████████| 3750/3750 [05:09<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Train RMSE:  11.2838\n",
      "Saving model checkpoint after epoch 49...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 [Train]: 100%|██████████| 3750/3750 [05:08<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train RMSE:  11.2461\n",
      "Saving model checkpoint after epoch 50...\n",
      "Model saved to pointnet_dual_stream_model_1536.pth\n",
      "--- Training Complete ---\n",
      "Finished training. Final model state\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random # Needed for sampling\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "# Base directory for all ..._for_training_Tx_... folders\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "\n",
    "# --- Checkpoint Configuration ---\n",
    "MODEL_SAVE_PATH = \"pointnet_dual_stream_model_1536.pth\" # New save path\n",
    "# ... (rest of config) ...\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "print(f\"Physical Batch Size: {BATCH_SIZE}\")\n",
    "TX_SUBSET_SELECTED = [1, 18, 8, 19, 2]\n",
    "# NUM_SAMPLES_PER_FOLDER = 8000 # <-- This is no longer needed, we use 'random_subset'\n",
    "FEATURE_DIM = 1536 # This will be the output of the encoder\n",
    "\n",
    "# List of ALL potential folders (will be filtered)\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_1\", \"28GHz_processed__for_training_Tx_10\",\n",
    "    \"28GHz_processed__for_training_Tx_11\", \"28GHz_processed__for_training_Tx_13\",\n",
    "    \"28GHz_processed__for_training_Tx_15\", \"28GHz_processed__for_training_Tx_16\",\n",
    "    \"28GHz_processed__for_training_Tx_17\", \"28GHz_processed__for_training_Tx_18\",\n",
    "    \"28GHz_processed__for_training_Tx_19\", \"28GHz_processed__for_training_Tx_2\",\n",
    "    \"28GHz_processed__for_training_Tx_3\", \"28GHz_processed__for_training_Tx_4\",\n",
    "    \"28GHz_processed__for_training_Tx_6\", \"28GHz_processed__for_training_Tx_7\",\n",
    "    \"28GHz_processed__for_training_Tx_8\",\n",
    "    \"7GHz_processed__for_training_Tx_1\", \"7GHz_processed__for_training_Tx_10\",\n",
    "    \"7GHz_processed__for_training_Tx_11\", \"7GHz_processed__for_training_Tx_13\",\n",
    "    \"7GHz_processed__for_training_Tx_15\", \"7GHz_processed__for_training_Tx_16\",\n",
    "    \"7Gzz_processed__for_training_Tx_17\", \"7GHz_processed__for_training_Tx_18\",\n",
    "    \"7GHz_processed__for_training_Tx_19\", \"7GHz_processed__for_training_Tx_2\",\n",
    "    \"7GHz_processed__for_training_Tx_3\", \"7GHz_processed__for_training_Tx_4\",\n",
    "    \"7GHz_processed__for_training_Tx_6\", \"7GHz_processed__for_training_Tx_7\",\n",
    "    \"7GHz_processed__for_training_Tx_8\",\n",
    "    \"800MHz_processed__for_training_Tx_1\", \"800MHz_processed__for_training_Tx_10\",\n",
    "    \"800MHz_processed__for_training_Tx_11\", \"800MHz_processed__for_training_Tx_13\",\n",
    "    \"800MHz_processed__for_training_Tx_15\", \"800MHz_processed__for_training_Tx_16\",\n",
    "    \"800MHz_processed__for_training_Tx_17\", \"800MHz_processed__for_training_Tx_18\",\n",
    "    \"800MHz_processed__for_training_Tx_19\", \"800MHz_processed__for_training_Tx_2\",\n",
    "    \"800MHz_processed__for_training_Tx_3\", \"800MHz_processed__for_training_Tx_4\",\n",
    "    \"800MHz_processed__for_training_Tx_6\", \"800MHz_processed__for_training_Tx_7\",\n",
    "    \"800MHz_processed__for_training_Tx_8\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "ALL_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str\n",
    "]\n",
    "if not ALL_DATA_FOLDERS:\n",
    "    raise ValueError(\"No data folders found matching the TX_SUBSET_SELECTED. Check folder names and IDs.\")\n",
    "print(f\"Filtered to {len(ALL_DATA_FOLDERS)} folders for Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "\n",
    "# --- 2. MODIFIED: Dataset reads from 'random_subset' ---\n",
    "class StandardPointCloudDataset(Dataset):\n",
    "    def __init__(self, data_folders, base_dir):\n",
    "        self.file_pairs = []\n",
    "        print(f\"Scanning {len(data_folders)} folders for 'random_subset' files...\")\n",
    "        \n",
    "        total_files_loaded = 0\n",
    "\n",
    "        for folder_name in tqdm(data_folders, desc=\"Scanning folders\"):\n",
    "            folder_path = os.path.join(base_dir, folder_name)\n",
    "            # This is the file we created in the previous step\n",
    "            subset_file_path = os.path.join(folder_path, \"random_subset\")\n",
    "\n",
    "            if not os.path.exists(subset_file_path):\n",
    "                print(f\"\\n  Warning: 'random_subset' file not found in '{folder_name}'. Skipping folder.\")\n",
    "                continue\n",
    "            \n",
    "            files_in_this_folder = 0\n",
    "            try:\n",
    "                # Read all pair IDs from the subset file\n",
    "                with open(subset_file_path, 'r') as f:\n",
    "                    pair_ids = f.readlines()\n",
    "                \n",
    "                for pair_id in pair_ids:\n",
    "                    pair_id = pair_id.strip() # Remove newline characters (e.g., \"pair00000\\n\")\n",
    "                    if not pair_id: # Skip any empty lines\n",
    "                        continue\n",
    "                        \n",
    "                    # Construct filenames from the ID\n",
    "                    # e.g., pair_id = \"pair00123\"\n",
    "                    input_filename = f\"{pair_id}_for_train.npy\"\n",
    "                    label_filename = f\"{pair_id}_path_loss.npy\"\n",
    "                    \n",
    "                    input_path = os.path.join(folder_path, input_filename)\n",
    "                    label_path = os.path.join(folder_path, label_filename)\n",
    "\n",
    "                    # Check if both files actually exist before adding\n",
    "                    if os.path.exists(input_path) and os.path.exists(label_path):\n",
    "                        self.file_pairs.append((input_path, label_path))\n",
    "                        files_in_this_folder += 1\n",
    "                    else:\n",
    "                        # This warning is important, in case 'random_subset' is stale\n",
    "                        print(f\"\\n  Warning: Files for '{pair_id}' listed in 'random_subset' but not found in '{folder_name}'. Skipping.\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"\\n  Error reading 'random_subset' in '{folder_name}': {e}\")\n",
    "            \n",
    "            total_files_loaded += files_in_this_folder\n",
    "\n",
    "        print(f\"\\nLoaded a total of {total_files_loaded} file pairs from all 'random_subset' files.\")\n",
    "        print(f\"Total dataset size: {len(self.file_pairs)} files.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label = np.load(label_path).astype(np.float32)\n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_tensor = torch.from_numpy(label).squeeze()\n",
    "        return pc_tensor, label_tensor\n",
    "\n",
    "# --- 3. MODIFIED: Dual-Stream PointNet Model ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Modified PointNet encoder.\n",
    "    Processes (x,y,z) coordinates and (other) features in separate streams\n",
    "    before combining them. This is closer to the PointNet++ concept.\n",
    "    \"\"\"\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        \n",
    "        # --- Stream 1: Process Coordinates (x,y,z) ---\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "\n",
    "        # --- Stream 2: Process Features (is_bldg, f1, f2, f3) ---\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        \n",
    "        # --- Combined Stream ---\n",
    "        # Takes the concatenated features (128 from pos + 128 from feat = 256)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: (batch, input_dim, num_points), e.g., (batch, 7, 7000)\n",
    "        \n",
    "        # Split the input into coordinates and features\n",
    "        pos_stream = x[:, :3, :] # (batch, 3, 7000)\n",
    "        feat_stream = x[:, 3:, :] # (batch, 4, 7000)\n",
    "\n",
    "        # Process coordinates\n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out))) # (batch, 128, 7000)\n",
    "        \n",
    "        # Process features\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out))) # (batch, 128, 7000)\n",
    "\n",
    "        # Combine the processed streams\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1) # (batch, 256, 7000)\n",
    "\n",
    "        # Process the combined features\n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x))) # (batch, feature_dim_out, 7000)\n",
    "\n",
    "        # Global max pooling\n",
    "        x = torch.max(x, 2)[0]  # (batch, feature_dim_out)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    \"\"\"PointNet for path loss prediction (Regression Head)\"\"\"\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        # Use the new Dual-Stream Encoder\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "\n",
    "        # Regression head\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: (batch, num_points, input_dim), e.g., (batch, 7000, 7)\n",
    "        x = x.transpose(1, 2)  # -> (batch, 7, 7000)\n",
    "        \n",
    "        # Encoder processes the 7D input, splitting it internally\n",
    "        x = self.encoder(x) # -> (batch, feature_dim_encoder)\n",
    "\n",
    "        # Regression head\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "# --- 4. Main Training Script (WITH CHECKPOINT FIX) ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- Setup ---\n",
    "    # *** THIS IS THE FIX ***\n",
    "    # Use 'cuda' to automatically select the available GPU (e.g., cuda:0)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    # *** END FIX ***\n",
    "    \n",
    "    print(f\"Starting training with LEARNING_RATE = {LEARNING_RATE} for {NUM_EPOCHS} epochs.\")\n",
    "\n",
    "    # --- Create Datasets and Dataloaders ---\n",
    "    train_dataset = StandardPointCloudDataset(\n",
    "        data_folders=ALL_DATA_FOLDERS,\n",
    "        base_dir=BASE_TRAIN_DIR\n",
    "        # No 'num_samples_per_folder' needed, it's now controlled by 'random_subset'\n",
    "    )\n",
    "\n",
    "    if len(train_dataset) == 0:\n",
    "        raise ValueError(\"Dataset is empty after filtering and loading from 'random_subset' files. Check paths and files.\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "\n",
    "    # --- Initialize Model ---\n",
    "    model = PointNetPathLoss().to(device) # This now uses the Dual-Stream model\n",
    "\n",
    "    # Calculate Model Size\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model Initialized: {model.__class__.__name__} (Dual-Stream Encoder)\")\n",
    "    print(f\"Target Encoder Output Dimension: {FEATURE_DIM}\")\n",
    "    print(f\"Total Trainable Parameters: {total_params:,}\")\n",
    "    \n",
    "    # --- Initialize Loss and Optimizer (MOVED UP) ---\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    # --- Load existing MODEL and OPTIMIZER states ---\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"Loading existing checkpoint from {MODEL_SAVE_PATH}\")\n",
    "        try:\n",
    "            # The 'map_location=device' handles moving the checkpoint\n",
    "            # from one GPU (e.g., cuda:1) to another (e.g., cuda:0)\n",
    "            checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "            \n",
    "            # Load model weights (use strict=True if architecture is stable)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'], strict=True) \n",
    "            print(\"Model weights loaded successfully.\")\n",
    "            \n",
    "            # Check if optimizer and epoch are in the checkpoint\n",
    "            if 'optimizer_state_dict' in checkpoint and 'epoch' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                start_epoch = checkpoint['epoch'] + 1\n",
    "                print(f\"Optimizer state loaded. Resuming training from epoch {start_epoch + 1}.\")\n",
    "                \n",
    "                # Check if we've already finished training\n",
    "                if start_epoch >= NUM_EPOCHS:\n",
    "                    print(f\"Warning: Model has already completed {start_epoch} epochs. \")\n",
    "                    print(f\"         NUM_EPOCHS is set to {NUM_EPOCHS}. Increase NUM_EPOCHS to train further.\")\n",
    "            else:\n",
    "                print(\"Optimizer state/epoch not in checkpoint. Starting from epoch 0.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint: {e}. Starting fresh from epoch 0.\")\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        print(f\"No existing model found at {MODEL_SAVE_PATH}. Starting fresh from epoch 0.\")\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "    # Only train if start_epoch is less than NUM_EPOCHS\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        avg_train_loss = 0 # Initialize here\n",
    "\n",
    "        for i, (pc_batch, label_batch) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")):\n",
    "            pc_batch = pc_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(pc_batch)\n",
    "            loss = criterion(out, label_batch)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"Warning: Encountered non-finite loss: {loss.item()} at step {i}. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * pc_batch.size(0)\n",
    "\n",
    "        if len(train_loader.dataset) > 0:\n",
    "            avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "            avg_train_rmse = np.sqrt(max(0, avg_train_loss))\n",
    "            print(f\"Epoch {epoch+1:02d} | Train RMSE: {avg_train_rmse:8.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1:02d} | No data processed.\")\n",
    "\n",
    "        # --- Save Checkpoint After Each Epoch ---\n",
    "        print(f\"Saving model checkpoint after epoch {epoch+1}...\")\n",
    "        try:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_train_loss, # Save the average loss\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model checkpoint: {e}\")\n",
    "        # ----------------------------------------\n",
    "\n",
    "    print(\"--- Training Complete ---\")\n",
    "    if start_epoch >= NUM_EPOCHS:\n",
    "         print(f\"Training was already complete at {start_epoch} epochs.\")\n",
    "    else:\n",
    "        print(f\"Finished training. Final model state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60ec944f-9fe9-4c78-acc7-a4b7ccd2cd27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 folders for evaluation for Tx IDs: [9, 12, 14, 20]\n",
      "Using device: cuda\n",
      "Model initialized.\n",
      "Successfully loaded model weights from pointnet_dual_stream_model.pth\n",
      "\n",
      "--- Starting Evaluation ---\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87127/901120766.py:168: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
      "  Evaluating: 100%|██████████| 729/729 [00:20<00:00, 34.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  26.5028\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_12.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 701/701 [00:20<00:00, 34.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  19.1019\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_14.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 685/685 [00:19<00:00, 34.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  21.8531\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_20.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 734/734 [00:21<00:00, 34.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  23.7486\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_9.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 751/751 [00:21<00:00, 34.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  22.0757\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_12.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 718/718 [00:20<00:00, 34.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  15.2719\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_14.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 696/696 [00:20<00:00, 34.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  19.2697\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_20.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 762/762 [00:21<00:00, 34.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  20.5933\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_9.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 751/751 [00:21<00:00, 34.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  20.9563\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_12.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 718/718 [00:20<00:00, 34.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  14.4491\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_14.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 696/696 [00:20<00:00, 34.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  16.4006\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_20.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 762/762 [00:21<00:00, 34.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  17.3675\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_9.csv\n",
      "\n",
      "--- Evaluation Complete ---\n",
      "Overall Test RMSE:  20.1140\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import re # Needed for parsing folder names\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "# Base directory for all ..._for_training_Tx_... folders\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/test\"\n",
    "# Directory to save the resulting CSVs\n",
    "TEST_SAVE_DIR = \"/home/mkrishne/PL_competition/extracted_regions/test\"\n",
    "os.makedirs(TEST_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- Checkpoint Configuration ---\n",
    "MODEL_SAVE_PATH = \"pointnet_dual_stream_model.pth\"\n",
    "FEATURE_DIM = 1536\n",
    "BATCH_SIZE = 32 # Can be larger for evaluation if VRAM allows\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# --- Test Set Configuration ---\n",
    "TX_SUBSET_SELECTED = [5, 9, 12, 14, 20]\n",
    "TX_SUBSET_SELECTED = [9, 12, 14, 20]\n",
    "# List of ALL potential folders for the test set\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_12\",\n",
    "    \"28GHz_processed__for_training_Tx_14\",\n",
    "    \"28GHz_processed__for_training_Tx_20\",\n",
    "    \"28GHz_processed__for_training_Tx_5\",\n",
    "    \"28GHz_processed__for_training_Tx_9\",\n",
    "    \"7GHz_processed__for_training_Tx_12\",\n",
    "    \"7GHz_processed__for_training_Tx_14\",\n",
    "    \"7GHz_processed__for_training_Tx_20\",\n",
    "    \"7GHz_processed__for_training_Tx_5\",\n",
    "    \"7GHz_processed__for_training_Tx_9\",\n",
    "    \"800MHz_processed__for_training_Tx_12\",\n",
    "    \"800MHz_processed__for_training_Tx_14\",\n",
    "    \"800MHz_processed__for_training_Tx_20\",\n",
    "    \"800MHz_processed__for_training_Tx_5\",\n",
    "    \"800MHz_processed__for_training_Tx_9\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "TEST_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str\n",
    "]\n",
    "if not TEST_DATA_FOLDERS:\n",
    "    raise ValueError(\"No data folders found matching the TX_SUBSET_SELECTED.\")\n",
    "print(f\"Found {len(TEST_DATA_FOLDERS)} folders for evaluation for Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "\n",
    "# --- 2. Dataset Definition for Evaluation ---\n",
    "# This dataset loads ALL files, not just a 'random_subset'\n",
    "class EvaluationPointCloudDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.file_pairs = []\n",
    "        # Find all input files in the folder\n",
    "        input_files = glob.glob(os.path.join(folder_path, \"*_for_train.npy\"))\n",
    "        \n",
    "        for input_path in input_files:\n",
    "            # Construct the corresponding label file path\n",
    "            label_path = input_path.replace(\"_for_train.npy\", \"_path_loss.npy\")\n",
    "            \n",
    "            if os.path.exists(label_path):\n",
    "                self.file_pairs.append((input_path, label_path))\n",
    "            else:\n",
    "                print(f\"Warning: Missing label for {input_path}. Skipping file.\")\n",
    "                \n",
    "        if not self.file_pairs:\n",
    "            print(f\"Warning: No valid file pairs found in {folder_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label = np.load(label_path).astype(np.float32)\n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_tensor = torch.from_numpy(label).squeeze()\n",
    "        return pc_tensor, label_tensor\n",
    "\n",
    "# --- 3. Model Definitions (Copied from your training script) ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :]\n",
    "        feat_stream = x[:, 3:, :]\n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1)\n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.max(x, 2)[0]\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "# --- 4. Main Evaluation Script ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- Setup ---\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # --- Initialize Model ---\n",
    "    model = PointNetPathLoss().to(device)\n",
    "    print(\"Model initialized.\")\n",
    "\n",
    "    # --- Load Checkpoint ---\n",
    "    if not os.path.exists(MODEL_SAVE_PATH):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {MODEL_SAVE_PATH}. Cannot evaluate.\")\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        print(f\"Successfully loaded model weights from {MODEL_SAVE_PATH}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading checkpoint: {e}. Ensure model definition matches checkpoint.\")\n",
    "\n",
    "    # Set model to evaluation mode (disables dropout, batchnorm updates)\n",
    "    model.eval()\n",
    "    criterion = torch.nn.MSELoss() # For calculating RMSE\n",
    "\n",
    "    # Lists to store results for overall RMSE\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"\\n--- Starting Evaluation ---\")\n",
    "    \n",
    "    # Loop through each folder in the test set\n",
    "    for folder_name in TEST_DATA_FOLDERS:\n",
    "        print(f\"\\n▶ Processing folder: {folder_name}\")\n",
    "        folder_path = os.path.join(BASE_TRAIN_DIR, folder_name)\n",
    "        \n",
    "        # --- Create Dataset and Dataloader ---\n",
    "        test_dataset = EvaluationPointCloudDataset(folder_path=folder_path)\n",
    "        if len(test_dataset) == 0:\n",
    "            print(\"  -> No files found. Skipping folder.\")\n",
    "            continue\n",
    "            \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False, # No need to shuffle for evaluation\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=True if device.type == 'cuda' else False\n",
    "        )\n",
    "        \n",
    "        # Lists for this folder's results\n",
    "        folder_preds_list = []\n",
    "        folder_labels_list = []\n",
    "\n",
    "        # --- Run Inference ---\n",
    "        with torch.no_grad(): # Disables gradient calculation\n",
    "            for pc_batch, label_batch in tqdm(test_loader, desc=\"  Evaluating\"):\n",
    "                pc_batch = pc_batch.to(device)\n",
    "                label_batch = label_batch.to(device)\n",
    "                \n",
    "                out = model(pc_batch)\n",
    "                \n",
    "                # Store results\n",
    "                folder_preds_list.append(out.cpu().numpy())\n",
    "                folder_labels_list.append(label_batch.cpu().numpy())\n",
    "        \n",
    "        # --- Process and Save Results for this Folder ---\n",
    "        \n",
    "        # Concatenate all batch results\n",
    "        predictions = np.concatenate(folder_preds_list)\n",
    "        labels = np.concatenate(folder_labels_list)\n",
    "        \n",
    "        # Add to overall lists for final RMSE\n",
    "        all_predictions.append(predictions)\n",
    "        all_labels.append(labels)\n",
    "        \n",
    "        # Calculate folder-specific RMSE\n",
    "        folder_mse = np.mean((predictions - labels)**2)\n",
    "        folder_rmse = np.sqrt(folder_mse)\n",
    "        print(f\"  -> Folder RMSE: {folder_rmse:8.4f}\")\n",
    "        \n",
    "        # --- Create and Save CSV ---\n",
    "        # Parse freq and tx_id from folder name\n",
    "        # e.g., \"800MHz_processed__for_training_Tx_5\"\n",
    "        match = re.match(r\"(\\w+)_processed__for_training_Tx_(\\d+)\", folder_name)\n",
    "        if not match:\n",
    "            print(f\"  -> ERROR: Could not parse folder name '{folder_name}'. Skipping CSV save.\")\n",
    "            continue\n",
    "            \n",
    "        freq = match.group(1)\n",
    "        tx_id = match.group(2)\n",
    "        \n",
    "        csv_filename = f\"test_{freq}_Tx_{tx_id}.csv\"\n",
    "        csv_save_path = os.path.join(TEST_SAVE_DIR, csv_filename)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        results_df = pd.DataFrame({\n",
    "            'predicted_pathloss': predictions,\n",
    "            'actual_pathloss': labels\n",
    "        })\n",
    "        \n",
    "        # Save to CSV\n",
    "        results_df.to_csv(csv_save_path, index=False)\n",
    "        print(f\"  -> Results saved to: {csv_save_path}\")\n",
    "\n",
    "    # --- Calculate and Print Overall RMSE ---\n",
    "    if all_predictions:\n",
    "        overall_preds = np.concatenate(all_predictions)\n",
    "        overall_labels = np.concatenate(all_labels)\n",
    "        \n",
    "        overall_mse = np.mean((overall_preds - overall_labels)**2)\n",
    "        overall_rmse = np.sqrt(overall_mse)\n",
    "        \n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(f\"Overall Test RMSE: {overall_rmse:8.4f}\")\n",
    "    else:\n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(\"No test data was processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f96a77c7-8eaf-4b28-8bb0-120ed72385d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 folders for evaluation for Tx IDs: [9, 12, 14, 20]\n",
      "Using device: cuda\n",
      "Model initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87127/2430055321.py:168: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model weights from pointnet_dual_stream_model_1536.pth\n",
      "\n",
      "--- Starting Evaluation ---\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 729/729 [00:47<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  26.2872\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_12.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 701/701 [00:45<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  20.7187\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_14.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 685/685 [00:44<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  22.9232\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_20.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 734/734 [00:47<00:00, 15.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  23.1738\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_9.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 751/751 [00:48<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  22.2459\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_12.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 718/718 [00:46<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  15.9398\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_14.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 696/696 [00:44<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  20.0133\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_20.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 762/762 [00:49<00:00, 15.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  19.2966\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_9.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 751/751 [00:48<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  20.7921\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_12.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 718/718 [00:46<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  15.3865\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_14.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 696/696 [00:45<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  18.9718\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_20.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 762/762 [00:49<00:00, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE:  18.9048\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_9.csv\n",
      "\n",
      "--- Evaluation Complete ---\n",
      "Overall Test RMSE:  20.5996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import re # Needed for parsing folder names\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "# Base directory for all ..._for_training_Tx_... folders\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/test\"\n",
    "# Directory to save the resulting CSVs\n",
    "TEST_SAVE_DIR = \"/home/mkrishne/PL_competition/extracted_regions/test\"\n",
    "os.makedirs(TEST_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- Checkpoint Configuration ---\n",
    "MODEL_SAVE_PATH = \"pointnet_dual_stream_model_1536.pth\"\n",
    "FEATURE_DIM = 1536\n",
    "BATCH_SIZE = 32 # Can be larger for evaluation if VRAM allows\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# --- Test Set Configuration ---\n",
    "TX_SUBSET_SELECTED = [5, 9, 12, 14, 20]\n",
    "TX_SUBSET_SELECTED = [9, 12, 14, 20]\n",
    "# List of ALL potential folders for the test set\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_12\",\n",
    "    \"28GHz_processed__for_training_Tx_14\",\n",
    "    \"28GHz_processed__for_training_Tx_20\",\n",
    "    \"28GHz_processed__for_training_Tx_5\",\n",
    "    \"28GHz_processed__for_training_Tx_9\",\n",
    "    \"7GHz_processed__for_training_Tx_12\",\n",
    "    \"7GHz_processed__for_training_Tx_14\",\n",
    "    \"7GHz_processed__for_training_Tx_20\",\n",
    "    \"7GHz_processed__for_training_Tx_5\",\n",
    "    \"7GHz_processed__for_training_Tx_9\",\n",
    "    \"800MHz_processed__for_training_Tx_12\",\n",
    "    \"800MHz_processed__for_training_Tx_14\",\n",
    "    \"800MHz_processed__for_training_Tx_20\",\n",
    "    \"800MHz_processed__for_training_Tx_5\",\n",
    "    \"800MHz_processed__for_training_Tx_9\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "TEST_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str\n",
    "]\n",
    "if not TEST_DATA_FOLDERS:\n",
    "    raise ValueError(\"No data folders found matching the TX_SUBSET_SELECTED.\")\n",
    "print(f\"Found {len(TEST_DATA_FOLDERS)} folders for evaluation for Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "\n",
    "# --- 2. Dataset Definition for Evaluation ---\n",
    "# This dataset loads ALL files, not just a 'random_subset'\n",
    "class EvaluationPointCloudDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.file_pairs = []\n",
    "        # Find all input files in the folder\n",
    "        input_files = glob.glob(os.path.join(folder_path, \"*_for_train.npy\"))\n",
    "        \n",
    "        for input_path in input_files:\n",
    "            # Construct the corresponding label file path\n",
    "            label_path = input_path.replace(\"_for_train.npy\", \"_path_loss.npy\")\n",
    "            \n",
    "            if os.path.exists(label_path):\n",
    "                self.file_pairs.append((input_path, label_path))\n",
    "            else:\n",
    "                print(f\"Warning: Missing label for {input_path}. Skipping file.\")\n",
    "                \n",
    "        if not self.file_pairs:\n",
    "            print(f\"Warning: No valid file pairs found in {folder_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label = np.load(label_path).astype(np.float32)\n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_tensor = torch.from_numpy(label).squeeze()\n",
    "        return pc_tensor, label_tensor\n",
    "\n",
    "# --- 3. Model Definitions (Copied from your training script) ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :]\n",
    "        feat_stream = x[:, 3:, :]\n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1)\n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.max(x, 2)[0]\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "# --- 4. Main Evaluation Script ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- Setup ---\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # --- Initialize Model ---\n",
    "    model = PointNetPathLoss().to(device)\n",
    "    print(\"Model initialized.\")\n",
    "\n",
    "    # --- Load Checkpoint ---\n",
    "    if not os.path.exists(MODEL_SAVE_PATH):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {MODEL_SAVE_PATH}. Cannot evaluate.\")\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        print(f\"Successfully loaded model weights from {MODEL_SAVE_PATH}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading checkpoint: {e}. Ensure model definition matches checkpoint.\")\n",
    "\n",
    "    # Set model to evaluation mode (disables dropout, batchnorm updates)\n",
    "    model.eval()\n",
    "    criterion = torch.nn.MSELoss() # For calculating RMSE\n",
    "\n",
    "    # Lists to store results for overall RMSE\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"\\n--- Starting Evaluation ---\")\n",
    "    \n",
    "    # Loop through each folder in the test set\n",
    "    for folder_name in TEST_DATA_FOLDERS:\n",
    "        print(f\"\\n▶ Processing folder: {folder_name}\")\n",
    "        folder_path = os.path.join(BASE_TRAIN_DIR, folder_name)\n",
    "        \n",
    "        # --- Create Dataset and Dataloader ---\n",
    "        test_dataset = EvaluationPointCloudDataset(folder_path=folder_path)\n",
    "        if len(test_dataset) == 0:\n",
    "            print(\"  -> No files found. Skipping folder.\")\n",
    "            continue\n",
    "            \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False, # No need to shuffle for evaluation\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=True if device.type == 'cuda' else False\n",
    "        )\n",
    "        \n",
    "        # Lists for this folder's results\n",
    "        folder_preds_list = []\n",
    "        folder_labels_list = []\n",
    "\n",
    "        # --- Run Inference ---\n",
    "        with torch.no_grad(): # Disables gradient calculation\n",
    "            for pc_batch, label_batch in tqdm(test_loader, desc=\"  Evaluating\"):\n",
    "                pc_batch = pc_batch.to(device)\n",
    "                label_batch = label_batch.to(device)\n",
    "                \n",
    "                out = model(pc_batch)\n",
    "                \n",
    "                # Store results\n",
    "                folder_preds_list.append(out.cpu().numpy())\n",
    "                folder_labels_list.append(label_batch.cpu().numpy())\n",
    "        \n",
    "        # --- Process and Save Results for this Folder ---\n",
    "        \n",
    "        # Concatenate all batch results\n",
    "        predictions = np.concatenate(folder_preds_list)\n",
    "        labels = np.concatenate(folder_labels_list)\n",
    "        \n",
    "        # Add to overall lists for final RMSE\n",
    "        all_predictions.append(predictions)\n",
    "        all_labels.append(labels)\n",
    "        \n",
    "        # Calculate folder-specific RMSE\n",
    "        folder_mse = np.mean((predictions - labels)**2)\n",
    "        folder_rmse = np.sqrt(folder_mse)\n",
    "        print(f\"  -> Folder RMSE: {folder_rmse:8.4f}\")\n",
    "        \n",
    "        # --- Create and Save CSV ---\n",
    "        # Parse freq and tx_id from folder name\n",
    "        # e.g., \"800MHz_processed__for_training_Tx_5\"\n",
    "        match = re.match(r\"(\\w+)_processed__for_training_Tx_(\\d+)\", folder_name)\n",
    "        if not match:\n",
    "            print(f\"  -> ERROR: Could not parse folder name '{folder_name}'. Skipping CSV save.\")\n",
    "            continue\n",
    "            \n",
    "        freq = match.group(1)\n",
    "        tx_id = match.group(2)\n",
    "        \n",
    "        csv_filename = f\"test_{freq}_Tx_{tx_id}.csv\"\n",
    "        csv_save_path = os.path.join(TEST_SAVE_DIR, csv_filename)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        results_df = pd.DataFrame({\n",
    "            'predicted_pathloss': predictions,\n",
    "            'actual_pathloss': labels\n",
    "        })\n",
    "        \n",
    "        # Save to CSV\n",
    "        results_df.to_csv(csv_save_path, index=False)\n",
    "        print(f\"  -> Results saved to: {csv_save_path}\")\n",
    "\n",
    "    # --- Calculate and Print Overall RMSE ---\n",
    "    if all_predictions:\n",
    "        overall_preds = np.concatenate(all_predictions)\n",
    "        overall_labels = np.concatenate(all_labels)\n",
    "        \n",
    "        overall_mse = np.mean((overall_preds - overall_labels)**2)\n",
    "        overall_rmse = np.sqrt(overall_mse)\n",
    "        \n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(f\"Overall Test RMSE: {overall_rmse:8.4f}\")\n",
    "    else:\n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(\"No test data was processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6b38621-2379-45a6-969f-4d856fca4758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical Batch Size: 32\n",
      "Filtered to 5 folders for Tx IDs: [1, 18, 8, 19, 2]\n",
      "Using device: cuda\n",
      "Starting classification training with LEARNING_RATE = 0.001 for 20 epochs.\n",
      "Scanning 5 folders for 'random_subset' files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning folders: 100%|██████████| 5/5 [00:00<00:00, 18.61it/s]\n",
      "/tmp/ipykernel_87127/4290524856.py:234: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded a total of 40000 file pairs from all 'random_subset' files.\n",
      "Total dataset size: 40000 files.\n",
      "Model Initialized: PointNetPathLoss (Classifier)\n",
      "Target Encoder Output Dimension: 512\n",
      "Total Trainable Parameters: 845,008\n",
      "Loading existing checkpoint from pointnet_classifier_model_800.pth\n",
      "Model weights loaded (strict=False).\n",
      "Resuming training from epoch 11.\n",
      "\n",
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss:   1.3646 | Train Accuracy:  43.99%\n",
      "Saving model checkpoint after epoch 11...\n",
      "Model saved to pointnet_classifier_model_800.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss:   1.3454 | Train Accuracy:  44.68%\n",
      "Saving model checkpoint after epoch 12...\n",
      "Model saved to pointnet_classifier_model_800.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss:   1.3382 | Train Accuracy:  44.76%\n",
      "Saving model checkpoint after epoch 13...\n",
      "Model saved to pointnet_classifier_model_800.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss:   1.3365 | Train Accuracy:  44.94%\n",
      "Saving model checkpoint after epoch 14...\n",
      "Model saved to pointnet_classifier_model_800.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss:   1.3312 | Train Accuracy:  44.90%\n",
      "Saving model checkpoint after epoch 15...\n",
      "Model saved to pointnet_classifier_model_800.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss:   1.3289 | Train Accuracy:  45.01%\n",
      "Saving model checkpoint after epoch 16...\n",
      "Model saved to pointnet_classifier_model_800.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss:   1.3202 | Train Accuracy:  45.20%\n",
      "Saving model checkpoint after epoch 17...\n",
      "Model saved to pointnet_classifier_model_800.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss:   1.3199 | Train Accuracy:  45.29%\n",
      "Saving model checkpoint after epoch 18...\n",
      "Model saved to pointnet_classifier_model_800.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss:   1.3131 | Train Accuracy:  45.78%\n",
      "Saving model checkpoint after epoch 19...\n",
      "Model saved to pointnet_classifier_model_800.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss:   1.3134 | Train Accuracy:  45.55%\n",
      "Saving model checkpoint after epoch 20...\n",
      "Model saved to pointnet_classifier_model_800.pth\n",
      "--- Training Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "\n",
    "# --- MODIFIED: Checkpoint, Feature Dim, and Class Config ---\n",
    "FEATURE_DIM = 512 # REDUCED from 1536 to lower parameter count\n",
    "NUM_CLASSES = 16  # (200 - 50) / 10 + 1 = 16 classes (50, 60, ..., 200)\n",
    "MODEL_SAVE_PATH = \"pointnet_classifier_model_800.pth\" # New path for the new model\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "print(f\"Physical Batch Size: {BATCH_SIZE}\")\n",
    "TX_SUBSET_SELECTED = [1, 18, 8, 19, 2]\n",
    "\n",
    "# List of ALL potential folders (will be filtered)\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"800MHz_processed__for_training_Tx_1\", \"800MHz_processed__for_training_Tx_10\",\n",
    "    \"800MHz_processed__for_training_Tx_11\", \"800MHz_processed__for_training_Tx_13\",\n",
    "    \"800MHz_processed__for_training_Tx_15\", \"800MHz_processed__for_training_Tx_16\",\n",
    "    \"800MHz_processed__for_training_Tx_17\", \"800MHz_processed__for_training_Tx_18\",\n",
    "    \"800MHz_processed__for_training_Tx_19\", \"800MHz_processed__for_training_Tx_2\",\n",
    "    \"800MHz_processed__for_training_Tx_3\", \"800MHz_processed__for_training_Tx_4\",\n",
    "    \"800MHz_processed__for_training_Tx_6\", \"800MHz_processed__for_training_Tx_7\",\n",
    "    \"800MHz_processed__for_training_Tx_8\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "ALL_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str\n",
    "]\n",
    "if not ALL_DATA_FOLDERS:\n",
    "    raise ValueError(\"No data folders found matching the TX_SUBSET_SELECTED.\")\n",
    "print(f\"Filtered to {len(ALL_DATA_FOLDERS)} folders for Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "# --- 2. MODIFIED: Dataset handles classification ---\n",
    "\n",
    "def pl_to_class(pl_tensor):\n",
    "    \"\"\"Converts a raw path loss value to a class index.\"\"\"\n",
    "    # 1. Round to nearest 10\n",
    "    pl_rounded = torch.round(pl_tensor / 10.0) * 10.0\n",
    "    # 2. Clip to the valid range [50, 200]\n",
    "    pl_clipped = torch.clamp(pl_rounded, 50.0, 200.0)\n",
    "    # 3. Convert to class index: (50 -> 0, 60 -> 1, ..., 200 -> 15)\n",
    "    class_index = (pl_clipped - 50.0) / 10.0\n",
    "    # 4. Return as a long integer for CrossEntropyLoss\n",
    "    return class_index.long()\n",
    "\n",
    "class StandardPointCloudDataset(Dataset):\n",
    "    def __init__(self, data_folders, base_dir):\n",
    "        self.file_pairs = []\n",
    "        print(f\"Scanning {len(data_folders)} folders for 'random_subset' files...\")\n",
    "        \n",
    "        total_files_loaded = 0\n",
    "\n",
    "        for folder_name in tqdm(data_folders, desc=\"Scanning folders\"):\n",
    "            folder_path = os.path.join(base_dir, folder_name)\n",
    "            subset_file_path = os.path.join(folder_path, \"random_subset\")\n",
    "\n",
    "            if not os.path.exists(subset_file_path):\n",
    "                print(f\"\\n  Warning: 'random_subset' file not found in '{folder_name}'. Skipping folder.\")\n",
    "                continue\n",
    "            \n",
    "            files_in_this_folder = 0\n",
    "            try:\n",
    "                with open(subset_file_path, 'r') as f:\n",
    "                    pair_ids = f.readlines()\n",
    "                \n",
    "                for pair_id in pair_ids:\n",
    "                    pair_id = pair_id.strip() \n",
    "                    if not pair_id: \n",
    "                        continue\n",
    "                        \n",
    "                    input_filename = f\"{pair_id}_for_train.npy\"\n",
    "                    label_filename = f\"{pair_id}_path_loss.npy\"\n",
    "                    \n",
    "                    input_path = os.path.join(folder_path, input_filename)\n",
    "                    label_path = os.path.join(folder_path, label_filename)\n",
    "\n",
    "                    if os.path.exists(input_path) and os.path.exists(label_path):\n",
    "                        self.file_pairs.append((input_path, label_path))\n",
    "                        files_in_this_folder += 1\n",
    "                    else:\n",
    "                        print(f\"\\n  Warning: Files for '{pair_id}' listed but not found in '{folder_name}'. Skipping.\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"\\n  Error reading 'random_subset' in '{folder_name}': {e}\")\n",
    "            \n",
    "            total_files_loaded += files_in_this_folder\n",
    "\n",
    "        print(f\"\\nLoaded a total of {total_files_loaded} file pairs from all 'random_subset' files.\")\n",
    "        print(f\"Total dataset size: {len(self.file_pairs)} files.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label = np.load(label_path).astype(np.float32) # Load as float\n",
    "        \n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_tensor_float = torch.from_numpy(label).squeeze()\n",
    "        \n",
    "        # --- MODIFIED: Convert float label to class index ---\n",
    "        label_class_tensor = pl_to_class(label_tensor_float)\n",
    "        \n",
    "        return pc_tensor, label_class_tensor # Return class index\n",
    "\n",
    "# --- 3. MODIFIED: Model head reduced and outputting 16 classes ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        # (This part is unchanged, but feature_dim_out is now 512)\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1) # -> (batch, 512, 7000)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :] \n",
    "        feat_stream = x[:, 3:, :] \n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1) \n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x))) \n",
    "        x = torch.max(x, 2)[0]  # -> (batch, 512)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "\n",
    "        # --- MODIFIED: Reduced Regression head for ~1M params & classification ---\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 512) # 512 -> 512\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, NUM_CLASSES) # Output 16 classes\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # -> (batch, 7, 7000)\n",
    "        x = self.encoder(x)    # -> (batch, 512)\n",
    "\n",
    "        # Classification head\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x) # -> (batch, 16)\n",
    "        return x # Do not squeeze\n",
    "\n",
    "# --- 4. Main Training Script (Modified for Classification) ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    print(f\"Starting classification training with LEARNING_RATE = {LEARNING_RATE} for {NUM_EPOCHS} epochs.\")\n",
    "\n",
    "    # --- Create Datasets and Dataloaders ---\n",
    "    train_dataset = StandardPointCloudDataset(\n",
    "        data_folders=ALL_DATA_FOLDERS,\n",
    "        base_dir=BASE_TRAIN_DIR\n",
    "    )\n",
    "    if len(train_dataset) == 0:\n",
    "        raise ValueError(\"Dataset is empty. Check paths and 'random_subset' files.\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "\n",
    "    # --- Initialize Model ---\n",
    "    model = PointNetPathLoss().to(device) # Model head is now for classification\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model Initialized: {model.__class__.__name__} (Classifier)\")\n",
    "    print(f\"Target Encoder Output Dimension: {FEATURE_DIM}\")\n",
    "    print(f\"Total Trainable Parameters: {total_params:,}\") # ~838k\n",
    "    \n",
    "    # --- MODIFIED: Loss and Optimizer ---\n",
    "    criterion = torch.nn.CrossEntropyLoss() # Switched to CrossEntropy for classification\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    # ------------------------------------\n",
    "\n",
    "    # --- Load Checkpoint ---\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"Loading existing checkpoint from {MODEL_SAVE_PATH}\")\n",
    "        try:\n",
    "            checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "            \n",
    "            # Use strict=False because architecture changed (output layer)\n",
    "            # This will load all matching layers (the encoder)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'], strict=False) \n",
    "            print(\"Model weights loaded (strict=False).\")\n",
    "            \n",
    "            # Note: We don't load optimizer state as the head is different.\n",
    "            # We will start from epoch 0 or the saved epoch, but optimizer is fresh.\n",
    "            if 'epoch' in checkpoint:\n",
    "                 start_epoch = checkpoint['epoch'] + 1\n",
    "                 print(f\"Resuming training from epoch {start_epoch + 1}.\")\n",
    "            else:\n",
    "                 print(\"Starting fresh training from epoch 0.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint: {e}. Starting fresh from epoch 0.\")\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        print(f\"No existing model found at {MODEL_SAVE_PATH}. Starting fresh from epoch 0.\")\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        total_correct = 0 # For accuracy\n",
    "        total_samples = 0 # For accuracy\n",
    "\n",
    "        for i, (pc_batch, label_batch) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")):\n",
    "            # label_batch is already a long tensor of class indices\n",
    "            pc_batch = pc_batch.to(device)\n",
    "            label_batch = label_batch.to(device) # (batch_size,)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(pc_batch) # (batch_size, 16)\n",
    "            loss = criterion(out, label_batch)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"Warning: Encountered non-finite loss: {loss.item()} at step {i}. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * pc_batch.size(0)\n",
    "            \n",
    "            # --- Calculate Accuracy ---\n",
    "            _, predicted_class = torch.max(out, 1) # Get the index of the max logit\n",
    "            total_correct += (predicted_class == label_batch).sum().item()\n",
    "            total_samples += label_batch.size(0)\n",
    "\n",
    "        # --- MODIFIED: Report Accuracy ---\n",
    "        if total_samples > 0:\n",
    "            avg_train_loss = total_train_loss / total_samples\n",
    "            avg_train_acc = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1:02d} | Train Loss: {avg_train_loss:8.4f} | Train Accuracy: {avg_train_acc * 100:6.2f}%\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1:02d} | No data processed.\")\n",
    "\n",
    "        # --- Save Checkpoint After Each Epoch ---\n",
    "        print(f\"Saving model checkpoint after epoch {epoch+1}...\")\n",
    "        try:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'accuracy': avg_train_acc, # Save accuracy\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model checkpoint: {e}\")\n",
    "        # ----------------------------------------\n",
    "\n",
    "    print(\"--- Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85bfb93e-5f90-4659-96a7-1ee414120596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical Batch Size: 32\n",
      "Filtered to 5 folders for Tx IDs: [1, 18, 8, 19, 2]\n",
      "Using device: cuda\n",
      "Starting classification training with LEARNING_RATE = 0.001 for 30 epochs.\n",
      "Scanning 5 folders for 'random_subset' files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning folders: 100%|██████████| 5/5 [00:00<00:00, 18.28it/s]\n",
      "/tmp/ipykernel_87127/1653669814.py:235: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded a total of 40000 file pairs from all 'random_subset' files.\n",
      "Total dataset size: 40000 files.\n",
      "Model Initialized: PointNetPathLoss (Classifier)\n",
      "Target Encoder Output Dimension: 512\n",
      "Target Output Classes: 31\n",
      "Total Trainable Parameters: 846,943\n",
      "Loading existing checkpoint from pointnet_classifier_model_31class_800MHz.pth\n",
      "Model weights loaded successfully (strict=True).\n",
      "Optimizer state loaded. Resuming training from epoch 21.\n",
      "\n",
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss:   1.9863 | Train Accuracy:  27.77%\n",
      "Saving model checkpoint after epoch 21...\n",
      "Model saved to pointnet_classifier_model_31class_800MHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss:   1.9781 | Train Accuracy:  27.96%\n",
      "Saving model checkpoint after epoch 22...\n",
      "Model saved to pointnet_classifier_model_31class_800MHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss:   1.9704 | Train Accuracy:  28.09%\n",
      "Saving model checkpoint after epoch 23...\n",
      "Model saved to pointnet_classifier_model_31class_800MHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss:   1.9701 | Train Accuracy:  28.21%\n",
      "Saving model checkpoint after epoch 24...\n",
      "Model saved to pointnet_classifier_model_31class_800MHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss:   1.9696 | Train Accuracy:  28.23%\n",
      "Saving model checkpoint after epoch 25...\n",
      "Model saved to pointnet_classifier_model_31class_800MHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss:   1.9582 | Train Accuracy:  28.17%\n",
      "Saving model checkpoint after epoch 26...\n",
      "Model saved to pointnet_classifier_model_31class_800MHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss:   1.9582 | Train Accuracy:  28.16%\n",
      "Saving model checkpoint after epoch 27...\n",
      "Model saved to pointnet_classifier_model_31class_800MHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss:   1.9543 | Train Accuracy:  28.51%\n",
      "Saving model checkpoint after epoch 28...\n",
      "Model saved to pointnet_classifier_model_31class_800MHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss:   1.9455 | Train Accuracy:  28.81%\n",
      "Saving model checkpoint after epoch 29...\n",
      "Model saved to pointnet_classifier_model_31class_800MHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss:   1.9440 | Train Accuracy:  28.68%\n",
      "Saving model checkpoint after epoch 30...\n",
      "Model saved to pointnet_classifier_model_31class_800MHz.pth\n",
      "--- Training Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "\n",
    "# --- MODIFIED: Checkpoint, Feature Dim, and Class Config ---\n",
    "FEATURE_DIM = 512 # REDUCED from 1536 to lower parameter count\n",
    "NUM_CLASSES = 31  # (200 - 50) / 5 + 1 = 31 classes (50, 55, ..., 200)\n",
    "MODEL_SAVE_PATH = \"pointnet_classifier_model_31class_800MHz.pth\" # New path for new task\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "print(f\"Physical Batch Size: {BATCH_SIZE}\")\n",
    "TX_SUBSET_SELECTED = [1, 18, 8, 19, 2]\n",
    "\n",
    "# List of ALL potential folders (will be filtered)\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"800MHz_processed__for_training_Tx_1\", \"800MHz_processed__for_training_Tx_10\",\n",
    "    \"800MHz_processed__for_training_Tx_11\", \"800MHz_processed__for_training_Tx_13\",\n",
    "    \"800MHz_processed__for_training_Tx_15\", \"800MHz_processed__for_training_Tx_16\",\n",
    "    \"800MHz_processed__for_training_Tx_17\", \"800MHz_processed__for_training_Tx_18\",\n",
    "    \"800MHz_processed__for_training_Tx_19\", \"800MHz_processed__for_training_Tx_2\",\n",
    "    \"800MHz_processed__for_training_Tx_3\", \"800MHz_processed__for_training_Tx_4\",\n",
    "    \"800MHz_processed__for_training_Tx_6\", \"800MHz_processed__for_training_Tx_7\",\n",
    "    \"800MHz_processed__for_training_Tx_8\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "ALL_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str\n",
    "]\n",
    "if not ALL_DATA_FOLDERS:\n",
    "    raise ValueError(\"No data folders found matching the TX_SUBSET_SELECTED.\")\n",
    "print(f\"Filtered to {len(ALL_DATA_FOLDERS)} folders for Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "# --- 2. MODIFIED: Dataset handles classification ---\n",
    "\n",
    "def pl_to_class(pl_tensor):\n",
    "    \"\"\"Converts a raw path loss value to a class index.\"\"\"\n",
    "    # 1. Round to nearest 5\n",
    "    pl_rounded = torch.round(pl_tensor / 5.0) * 5.0\n",
    "    # 2. Clip to the valid range [50, 200]\n",
    "    pl_clipped = torch.clamp(pl_rounded, 50.0, 200.0)\n",
    "    # 3. Convert to class index: (50 -> 0, 55 -> 1, ..., 200 -> 30)\n",
    "    class_index = (pl_clipped - 50.0) / 5.0\n",
    "    # 4. Return as a long integer for CrossEntropyLoss\n",
    "    return class_index.long()\n",
    "\n",
    "class StandardPointCloudDataset(Dataset):\n",
    "    def __init__(self, data_folders, base_dir):\n",
    "        self.file_pairs = []\n",
    "        print(f\"Scanning {len(data_folders)} folders for 'random_subset' files...\")\n",
    "        \n",
    "        total_files_loaded = 0\n",
    "\n",
    "        for folder_name in tqdm(data_folders, desc=\"Scanning folders\"):\n",
    "            folder_path = os.path.join(base_dir, folder_name)\n",
    "            subset_file_path = os.path.join(folder_path, \"random_subset\")\n",
    "\n",
    "            if not os.path.exists(subset_file_path):\n",
    "                print(f\"\\n  Warning: 'random_subset' file not found in '{folder_name}'. Skipping folder.\")\n",
    "                continue\n",
    "            \n",
    "            files_in_this_folder = 0\n",
    "            try:\n",
    "                with open(subset_file_path, 'r') as f:\n",
    "                    pair_ids = f.readlines()\n",
    "                \n",
    "                for pair_id in pair_ids:\n",
    "                    pair_id = pair_id.strip() \n",
    "                    if not pair_id: \n",
    "                        continue\n",
    "                        \n",
    "                    input_filename = f\"{pair_id}_for_train.npy\"\n",
    "                    label_filename = f\"{pair_id}_path_loss.npy\"\n",
    "                    \n",
    "                    input_path = os.path.join(folder_path, input_filename)\n",
    "                    label_path = os.path.join(folder_path, label_filename)\n",
    "\n",
    "                    if os.path.exists(input_path) and os.path.exists(label_path):\n",
    "                        self.file_pairs.append((input_path, label_path))\n",
    "                        files_in_this_folder += 1\n",
    "                    else:\n",
    "                        print(f\"\\n  Warning: Files for '{pair_id}' listed but not found in '{folder_name}'. Skipping.\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"\\n  Error reading 'random_subset' in '{folder_name}': {e}\")\n",
    "            \n",
    "            total_files_loaded += files_in_this_folder\n",
    "\n",
    "        print(f\"\\nLoaded a total of {total_files_loaded} file pairs from all 'random_subset' files.\")\n",
    "        print(f\"Total dataset size: {len(self.file_pairs)} files.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label = np.load(label_path).astype(np.float32) # Load as float\n",
    "        \n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_tensor_float = torch.from_numpy(label).squeeze()\n",
    "        \n",
    "        # --- MODIFIED: Convert float label to class index ---\n",
    "        label_class_tensor = pl_to_class(label_tensor_float)\n",
    "        \n",
    "        return pc_tensor, label_class_tensor # Return class index\n",
    "\n",
    "# --- 3. MODIFIED: Model head reduced and outputting 31 classes ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1) # -> (batch, 512, 7000)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :] \n",
    "        feat_stream = x[:, 3:, :] \n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1) \n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x))) \n",
    "        x = torch.max(x, 2)[0]  # -> (batch, 512)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "\n",
    "        # --- MODIFIED: Final layer outputs NUM_CLASSES (31) ---\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 512) # 512 -> 512\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, NUM_CLASSES) # Output 31 classes\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # -> (batch, 7, 7000)\n",
    "        x = self.encoder(x)    # -> (batch, 512)\n",
    "\n",
    "        # Classification head\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x) # -> (batch, 31)\n",
    "        return x # Do not squeeze\n",
    "\n",
    "# --- 4. Main Training Script (Modified for Classification) ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    print(f\"Starting classification training with LEARNING_RATE = {LEARNING_RATE} for {NUM_EPOCHS} epochs.\")\n",
    "\n",
    "    # --- Create Datasets and Dataloaders ---\n",
    "    train_dataset = StandardPointCloudDataset(\n",
    "        data_folders=ALL_DATA_FOLDERS,\n",
    "        base_dir=BASE_TRAIN_DIR\n",
    "    )\n",
    "    if len(train_dataset) == 0:\n",
    "        raise ValueError(\"Dataset is empty. Check paths and 'random_subset' files.\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "\n",
    "    # --- Initialize Model ---\n",
    "    model = PointNetPathLoss().to(device) # Model head is now for classification\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model Initialized: {model.__class__.__name__} (Classifier)\")\n",
    "    print(f\"Target Encoder Output Dimension: {FEATURE_DIM}\")\n",
    "    print(f\"Target Output Classes: {NUM_CLASSES}\")\n",
    "    print(f\"Total Trainable Parameters: {total_params:,}\") # ~840k\n",
    "    \n",
    "    # --- MODIFIED: Loss and Optimizer ---\n",
    "    criterion = torch.nn.CrossEntropyLoss() # Switched to CrossEntropy for classification\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    # ------------------------------------\n",
    "\n",
    "    # --- Load Checkpoint ---\n",
    "    start_epoch = 0\n",
    "    # We check for the new model path\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"Loading existing checkpoint from {MODEL_SAVE_PATH}\")\n",
    "        try:\n",
    "            checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "            \n",
    "            # Try to load the model weights\n",
    "            model.load_state_dict(checkpoint['model_state_dict'], strict=True) \n",
    "            print(\"Model weights loaded successfully (strict=True).\")\n",
    "            \n",
    "            # Try to load optimizer and epoch\n",
    "            if 'optimizer_state_dict' in checkpoint and 'epoch' in checkpoint:\n",
    "                 optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                 start_epoch = checkpoint['epoch'] + 1\n",
    "                 print(f\"Optimizer state loaded. Resuming training from epoch {start_epoch + 1}.\")\n",
    "            else:\n",
    "                 print(\"Optimizer/epoch not in checkpoint. Starting from epoch 0.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # This will happen if the old (16-class) model is at this path\n",
    "            print(f\"Error loading checkpoint (likely architecture mismatch): {e}.\")\n",
    "            print(\"Starting fresh training from epoch 0.\")\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        print(f\"No existing model found at {MODEL_SAVE_PATH}. Starting fresh from epoch 0.\")\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        total_correct = 0 # For accuracy\n",
    "        total_samples = 0 # For accuracy\n",
    "        avg_train_acc = 0.0 # Initialize for checkpoint saving\n",
    "\n",
    "        for i, (pc_batch, label_batch) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")):\n",
    "            pc_batch = pc_batch.to(device)\n",
    "            label_batch = label_batch.to(device) # (batch_size,)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(pc_batch) # (batch_size, 31)\n",
    "            loss = criterion(out, label_batch)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"Warning: Encountered non-finite loss: {loss.item()} at step {i}. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * pc_batch.size(0)\n",
    "            \n",
    "            # --- Calculate Accuracy ---\n",
    "            _, predicted_class = torch.max(out, 1) # Get the index of the max logit\n",
    "            total_correct += (predicted_class == label_batch).sum().item()\n",
    "            total_samples += label_batch.size(0)\n",
    "\n",
    "        # --- MODIFIED: Report Accuracy ---\n",
    "        if total_samples > 0:\n",
    "            avg_train_loss = total_train_loss / total_samples\n",
    "            avg_train_acc = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1:02d} | Train Loss: {avg_train_loss:8.4f} | Train Accuracy: {avg_train_acc * 100:6.2f}%\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1:02d} | No data processed.\")\n",
    "\n",
    "        # --- Save Checkpoint After Each Epoch ---\n",
    "        print(f\"Saving model checkpoint after epoch {epoch+1}...\")\n",
    "        try:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'accuracy': avg_train_acc, # Save accuracy\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model checkpoint: {e}\")\n",
    "        # ----------------------------------------\n",
    "\n",
    "    print(\"--- Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a63c2c5-2093-4028-9d5f-2efa8dad44c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical Batch Size: 32\n",
      "Filtered to 5 folders for Tx IDs: [1, 18, 8, 19, 2]\n",
      "Using device: cuda\n",
      "Starting classification training with LEARNING_RATE = 0.001 for 30 epochs.\n",
      "Scanning 5 folders for 'random_subset' files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning folders: 100%|██████████| 5/5 [00:00<00:00, 19.30it/s]\n",
      "/tmp/ipykernel_87127/2304921788.py:235: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded a total of 40000 file pairs from all 'random_subset' files.\n",
      "Total dataset size: 40000 files.\n",
      "Model Initialized: PointNetPathLoss (Classifier)\n",
      "Target Encoder Output Dimension: 512\n",
      "Target Output Classes: 31\n",
      "Total Trainable Parameters: 846,943\n",
      "Loading existing checkpoint from pointnet_classifier_model_31class_7GHz.pth\n",
      "Model weights loaded successfully (strict=True).\n",
      "Optimizer state loaded. Resuming training from epoch 11.\n",
      "\n",
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss:   2.0885 | Train Accuracy:  28.67%\n",
      "Saving model checkpoint after epoch 11...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss:   2.0739 | Train Accuracy:  28.80%\n",
      "Saving model checkpoint after epoch 12...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss:   2.0634 | Train Accuracy:  29.19%\n",
      "Saving model checkpoint after epoch 13...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss:   2.0658 | Train Accuracy:  29.14%\n",
      "Saving model checkpoint after epoch 14...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss:   2.0574 | Train Accuracy:  29.28%\n",
      "Saving model checkpoint after epoch 15...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss:   2.0407 | Train Accuracy:  29.78%\n",
      "Saving model checkpoint after epoch 16...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss:   2.0364 | Train Accuracy:  30.22%\n",
      "Saving model checkpoint after epoch 17...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss:   2.0276 | Train Accuracy:  29.95%\n",
      "Saving model checkpoint after epoch 18...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss:   2.0266 | Train Accuracy:  30.08%\n",
      "Saving model checkpoint after epoch 19...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss:   2.0232 | Train Accuracy:  30.22%\n",
      "Saving model checkpoint after epoch 20...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss:   2.0172 | Train Accuracy:  30.32%\n",
      "Saving model checkpoint after epoch 21...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss:   2.0082 | Train Accuracy:  30.95%\n",
      "Saving model checkpoint after epoch 22...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss:   2.0047 | Train Accuracy:  30.71%\n",
      "Saving model checkpoint after epoch 23...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss:   2.0021 | Train Accuracy:  30.74%\n",
      "Saving model checkpoint after epoch 24...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss:   2.0001 | Train Accuracy:  30.96%\n",
      "Saving model checkpoint after epoch 25...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss:   1.9925 | Train Accuracy:  31.25%\n",
      "Saving model checkpoint after epoch 26...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss:   1.9940 | Train Accuracy:  31.00%\n",
      "Saving model checkpoint after epoch 27...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss:   1.9855 | Train Accuracy:  31.35%\n",
      "Saving model checkpoint after epoch 28...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss:   1.9852 | Train Accuracy:  31.47%\n",
      "Saving model checkpoint after epoch 29...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 [Train]: 100%|██████████| 1250/1250 [01:00<00:00, 20.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss:   1.9856 | Train Accuracy:  31.40%\n",
      "Saving model checkpoint after epoch 30...\n",
      "Model saved to pointnet_classifier_model_31class_7GHz.pth\n",
      "--- Training Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "\n",
    "# --- MODIFIED: Checkpoint, Feature Dim, and Class Config ---\n",
    "FEATURE_DIM = 512 # REDUCED from 1536 to lower parameter count\n",
    "NUM_CLASSES = 31  # (200 - 50) / 5 + 1 = 31 classes (50, 55, ..., 200)\n",
    "MODEL_SAVE_PATH = \"pointnet_classifier_model_31class_7GHz.pth\" # New path for new task\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "print(f\"Physical Batch Size: {BATCH_SIZE}\")\n",
    "TX_SUBSET_SELECTED = [1, 18, 8, 19, 2]\n",
    "\n",
    "# List of ALL potential folders (will be filtered)\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"7GHz_processed__for_training_Tx_1\", \"7GHz_processed__for_training_Tx_10\",\n",
    "    \"7GHz_processed__for_training_Tx_11\", \"7GHz_processed__for_training_Tx_13\",\n",
    "    \"7GHz_processed__for_training_Tx_15\", \"7GHz_processed__for_training_Tx_16\",\n",
    "    \"7GHz_processed__for_training_Tx_17\", \"7GHz_processed__for_training_Tx_18\",\n",
    "    \"7GHz_processed__for_training_Tx_19\", \"7GHz_processed__for_training_Tx_2\",\n",
    "    \"7GHz_processed__for_training_Tx_3\", \"7GHz_processed__for_training_Tx_4\",\n",
    "    \"7GHz_processed__for_training_Tx_6\", \"7GHz_processed__for_training_Tx_7\",\n",
    "    \"7GHz_processed__for_training_Tx_8\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "ALL_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str\n",
    "]\n",
    "if not ALL_DATA_FOLDERS:\n",
    "    raise ValueError(\"No data folders found matching the TX_SUBSET_SELECTED.\")\n",
    "print(f\"Filtered to {len(ALL_DATA_FOLDERS)} folders for Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "# --- 2. MODIFIED: Dataset handles classification ---\n",
    "\n",
    "def pl_to_class(pl_tensor):\n",
    "    \"\"\"Converts a raw path loss value to a class index.\"\"\"\n",
    "    # 1. Round to nearest 5\n",
    "    pl_rounded = torch.round(pl_tensor / 5.0) * 5.0\n",
    "    # 2. Clip to the valid range [50, 200]\n",
    "    pl_clipped = torch.clamp(pl_rounded, 50.0, 200.0)\n",
    "    # 3. Convert to class index: (50 -> 0, 55 -> 1, ..., 200 -> 30)\n",
    "    class_index = (pl_clipped - 50.0) / 5.0\n",
    "    # 4. Return as a long integer for CrossEntropyLoss\n",
    "    return class_index.long()\n",
    "\n",
    "class StandardPointCloudDataset(Dataset):\n",
    "    def __init__(self, data_folders, base_dir):\n",
    "        self.file_pairs = []\n",
    "        print(f\"Scanning {len(data_folders)} folders for 'random_subset' files...\")\n",
    "        \n",
    "        total_files_loaded = 0\n",
    "\n",
    "        for folder_name in tqdm(data_folders, desc=\"Scanning folders\"):\n",
    "            folder_path = os.path.join(base_dir, folder_name)\n",
    "            subset_file_path = os.path.join(folder_path, \"random_subset\")\n",
    "\n",
    "            if not os.path.exists(subset_file_path):\n",
    "                print(f\"\\n  Warning: 'random_subset' file not found in '{folder_name}'. Skipping folder.\")\n",
    "                continue\n",
    "            \n",
    "            files_in_this_folder = 0\n",
    "            try:\n",
    "                with open(subset_file_path, 'r') as f:\n",
    "                    pair_ids = f.readlines()\n",
    "                \n",
    "                for pair_id in pair_ids:\n",
    "                    pair_id = pair_id.strip() \n",
    "                    if not pair_id: \n",
    "                        continue\n",
    "                        \n",
    "                    input_filename = f\"{pair_id}_for_train.npy\"\n",
    "                    label_filename = f\"{pair_id}_path_loss.npy\"\n",
    "                    \n",
    "                    input_path = os.path.join(folder_path, input_filename)\n",
    "                    label_path = os.path.join(folder_path, label_filename)\n",
    "\n",
    "                    if os.path.exists(input_path) and os.path.exists(label_path):\n",
    "                        self.file_pairs.append((input_path, label_path))\n",
    "                        files_in_this_folder += 1\n",
    "                    else:\n",
    "                        print(f\"\\n  Warning: Files for '{pair_id}' listed but not found in '{folder_name}'. Skipping.\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"\\n  Error reading 'random_subset' in '{folder_name}': {e}\")\n",
    "            \n",
    "            total_files_loaded += files_in_this_folder\n",
    "\n",
    "        print(f\"\\nLoaded a total of {total_files_loaded} file pairs from all 'random_subset' files.\")\n",
    "        print(f\"Total dataset size: {len(self.file_pairs)} files.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label = np.load(label_path).astype(np.float32) # Load as float\n",
    "        \n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_tensor_float = torch.from_numpy(label).squeeze()\n",
    "        \n",
    "        # --- MODIFIED: Convert float label to class index ---\n",
    "        label_class_tensor = pl_to_class(label_tensor_float)\n",
    "        \n",
    "        return pc_tensor, label_class_tensor # Return class index\n",
    "\n",
    "# --- 3. MODIFIED: Model head reduced and outputting 31 classes ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1) # -> (batch, 512, 7000)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :] \n",
    "        feat_stream = x[:, 3:, :] \n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1) \n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x))) \n",
    "        x = torch.max(x, 2)[0]  # -> (batch, 512)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "\n",
    "        # --- MODIFIED: Final layer outputs NUM_CLASSES (31) ---\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 512) # 512 -> 512\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, NUM_CLASSES) # Output 31 classes\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # -> (batch, 7, 7000)\n",
    "        x = self.encoder(x)    # -> (batch, 512)\n",
    "\n",
    "        # Classification head\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x) # -> (batch, 31)\n",
    "        return x # Do not squeeze\n",
    "\n",
    "# --- 4. Main Training Script (Modified for Classification) ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    print(f\"Starting classification training with LEARNING_RATE = {LEARNING_RATE} for {NUM_EPOCHS} epochs.\")\n",
    "\n",
    "    # --- Create Datasets and Dataloaders ---\n",
    "    train_dataset = StandardPointCloudDataset(\n",
    "        data_folders=ALL_DATA_FOLDERS,\n",
    "        base_dir=BASE_TRAIN_DIR\n",
    "    )\n",
    "    if len(train_dataset) == 0:\n",
    "        raise ValueError(\"Dataset is empty. Check paths and 'random_subset' files.\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "\n",
    "    # --- Initialize Model ---\n",
    "    model = PointNetPathLoss().to(device) # Model head is now for classification\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model Initialized: {model.__class__.__name__} (Classifier)\")\n",
    "    print(f\"Target Encoder Output Dimension: {FEATURE_DIM}\")\n",
    "    print(f\"Target Output Classes: {NUM_CLASSES}\")\n",
    "    print(f\"Total Trainable Parameters: {total_params:,}\") # ~840k\n",
    "    \n",
    "    # --- MODIFIED: Loss and Optimizer ---\n",
    "    criterion = torch.nn.CrossEntropyLoss() # Switched to CrossEntropy for classification\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    # ------------------------------------\n",
    "\n",
    "    # --- Load Checkpoint ---\n",
    "    start_epoch = 0\n",
    "    # We check for the new model path\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"Loading existing checkpoint from {MODEL_SAVE_PATH}\")\n",
    "        try:\n",
    "            checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "            \n",
    "            # Try to load the model weights\n",
    "            model.load_state_dict(checkpoint['model_state_dict'], strict=True) \n",
    "            print(\"Model weights loaded successfully (strict=True).\")\n",
    "            \n",
    "            # Try to load optimizer and epoch\n",
    "            if 'optimizer_state_dict' in checkpoint and 'epoch' in checkpoint:\n",
    "                 optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                 start_epoch = checkpoint['epoch'] + 1\n",
    "                 print(f\"Optimizer state loaded. Resuming training from epoch {start_epoch + 1}.\")\n",
    "            else:\n",
    "                 print(\"Optimizer/epoch not in checkpoint. Starting from epoch 0.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # This will happen if the old (16-class) model is at this path\n",
    "            print(f\"Error loading checkpoint (likely architecture mismatch): {e}.\")\n",
    "            print(\"Starting fresh training from epoch 0.\")\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        print(f\"No existing model found at {MODEL_SAVE_PATH}. Starting fresh from epoch 0.\")\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        total_correct = 0 # For accuracy\n",
    "        total_samples = 0 # For accuracy\n",
    "        avg_train_acc = 0.0 # Initialize for checkpoint saving\n",
    "\n",
    "        for i, (pc_batch, label_batch) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")):\n",
    "            pc_batch = pc_batch.to(device)\n",
    "            label_batch = label_batch.to(device) # (batch_size,)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(pc_batch) # (batch_size, 31)\n",
    "            loss = criterion(out, label_batch)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"Warning: Encountered non-finite loss: {loss.item()} at step {i}. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * pc_batch.size(0)\n",
    "            \n",
    "            # --- Calculate Accuracy ---\n",
    "            _, predicted_class = torch.max(out, 1) # Get the index of the max logit\n",
    "            total_correct += (predicted_class == label_batch).sum().item()\n",
    "            total_samples += label_batch.size(0)\n",
    "\n",
    "        # --- MODIFIED: Report Accuracy ---\n",
    "        if total_samples > 0:\n",
    "            avg_train_loss = total_train_loss / total_samples\n",
    "            avg_train_acc = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1:02d} | Train Loss: {avg_train_loss:8.4f} | Train Accuracy: {avg_train_acc * 100:6.2f}%\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1:02d} | No data processed.\")\n",
    "\n",
    "        # --- Save Checkpoint After Each Epoch ---\n",
    "        print(f\"Saving model checkpoint after epoch {epoch+1}...\")\n",
    "        try:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'accuracy': avg_train_acc, # Save accuracy\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model checkpoint: {e}\")\n",
    "        # ----------------------------------------\n",
    "\n",
    "    print(\"--- Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "427bcc6f-d6fe-4938-89ab-aec1b4cf1070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical Batch Size: 32\n",
      "Filtered to 5 folders for Tx IDs: [1, 18, 8, 19, 2]\n",
      "Using device: cuda\n",
      "Starting classification training with LEARNING_RATE = 0.01 for 10 epochs.\n",
      "Scanning 5 folders for 'random_subset' files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning folders: 100%|██████████| 5/5 [00:00<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded a total of 40000 file pairs from all 'random_subset' files.\n",
      "Total dataset size: 40000 files.\n",
      "Model Initialized: PointNetPathLoss (Classifier)\n",
      "Target Encoder Output Dimension: 512\n",
      "Target Output Classes: 31\n",
      "Total Trainable Parameters: 846,943\n",
      "No existing model found at pointnet_classifier_model_31class_28GHz.pth. Starting fresh from epoch 0.\n",
      "\n",
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 20.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss:   2.5711 | Train Accuracy:  17.26%\n",
      "Saving model checkpoint after epoch 1...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 20.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss:   2.4697 | Train Accuracy:  19.00%\n",
      "Saving model checkpoint after epoch 2...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss:   2.4185 | Train Accuracy:  20.41%\n",
      "Saving model checkpoint after epoch 3...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss:   2.3839 | Train Accuracy:  21.63%\n",
      "Saving model checkpoint after epoch 4...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 20.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss:   2.3510 | Train Accuracy:  22.14%\n",
      "Saving model checkpoint after epoch 5...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 20.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss:   2.3288 | Train Accuracy:  23.22%\n",
      "Saving model checkpoint after epoch 6...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss:   2.3062 | Train Accuracy:  23.93%\n",
      "Saving model checkpoint after epoch 7...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss:   2.2854 | Train Accuracy:  24.21%\n",
      "Saving model checkpoint after epoch 8...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss:   2.2696 | Train Accuracy:  24.71%\n",
      "Saving model checkpoint after epoch 9...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 1250/1250 [00:59<00:00, 21.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss:   2.2594 | Train Accuracy:  24.82%\n",
      "Saving model checkpoint after epoch 10...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n",
      "--- Training Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "\n",
    "# --- MODIFIED: Checkpoint, Feature Dim, and Class Config ---\n",
    "FEATURE_DIM = 512 # REDUCED from 1536 to lower parameter count\n",
    "NUM_CLASSES = 31  # (200 - 50) / 5 + 1 = 31 classes (50, 55, ..., 200)\n",
    "MODEL_SAVE_PATH = \"pointnet_classifier_model_31class_28GHz.pth\" # New path for new task\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "print(f\"Physical Batch Size: {BATCH_SIZE}\")\n",
    "TX_SUBSET_SELECTED = [1, 18, 8, 19, 2]\n",
    "\n",
    "# List of ALL potential folders (will be filtered)\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_1\", \"28GHz_processed__for_training_Tx_10\",\n",
    "    \"28GHz_processed__for_training_Tx_11\", \"28GHz_processed__for_training_Tx_13\",\n",
    "    \"28GHz_processed__for_training_Tx_15\", \"28GHz_processed__for_training_Tx_16\",\n",
    "    \"28GHz_processed__for_training_Tx_17\", \"28GHz_processed__for_training_Tx_18\",\n",
    "    \"28GHz_processed__for_training_Tx_19\", \"28GHz_processed__for_training_Tx_2\",\n",
    "    \"28GHz_processed__for_training_Tx_3\", \"28GHz_processed__for_training_Tx_4\",\n",
    "    \"28GHz_processed__for_training_Tx_6\", \"28GHz_processed__for_training_Tx_7\",\n",
    "    \"28GHz_processed__for_training_Tx_8\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "ALL_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str\n",
    "]\n",
    "if not ALL_DATA_FOLDERS:\n",
    "    raise ValueError(\"No data folders found matching the TX_SUBSET_SELECTED.\")\n",
    "print(f\"Filtered to {len(ALL_DATA_FOLDERS)} folders for Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "# --- 2. MODIFIED: Dataset handles classification ---\n",
    "\n",
    "def pl_to_class(pl_tensor):\n",
    "    \"\"\"Converts a raw path loss value to a class index.\"\"\"\n",
    "    # 1. Round to nearest 5\n",
    "    pl_rounded = torch.round(pl_tensor / 5.0) * 5.0\n",
    "    # 2. Clip to the valid range [50, 200]\n",
    "    pl_clipped = torch.clamp(pl_rounded, 50.0, 200.0)\n",
    "    # 3. Convert to class index: (50 -> 0, 55 -> 1, ..., 200 -> 30)\n",
    "    class_index = (pl_clipped - 50.0) / 5.0\n",
    "    # 4. Return as a long integer for CrossEntropyLoss\n",
    "    return class_index.long()\n",
    "\n",
    "class StandardPointCloudDataset(Dataset):\n",
    "    def __init__(self, data_folders, base_dir):\n",
    "        self.file_pairs = []\n",
    "        print(f\"Scanning {len(data_folders)} folders for 'random_subset' files...\")\n",
    "        \n",
    "        total_files_loaded = 0\n",
    "\n",
    "        for folder_name in tqdm(data_folders, desc=\"Scanning folders\"):\n",
    "            folder_path = os.path.join(base_dir, folder_name)\n",
    "            subset_file_path = os.path.join(folder_path, \"random_subset\")\n",
    "\n",
    "            if not os.path.exists(subset_file_path):\n",
    "                print(f\"\\n  Warning: 'random_subset' file not found in '{folder_name}'. Skipping folder.\")\n",
    "                continue\n",
    "            \n",
    "            files_in_this_folder = 0\n",
    "            try:\n",
    "                with open(subset_file_path, 'r') as f:\n",
    "                    pair_ids = f.readlines()\n",
    "                \n",
    "                for pair_id in pair_ids:\n",
    "                    pair_id = pair_id.strip() \n",
    "                    if not pair_id: \n",
    "                        continue\n",
    "                        \n",
    "                    input_filename = f\"{pair_id}_for_train.npy\"\n",
    "                    label_filename = f\"{pair_id}_path_loss.npy\"\n",
    "                    \n",
    "                    input_path = os.path.join(folder_path, input_filename)\n",
    "                    label_path = os.path.join(folder_path, label_filename)\n",
    "\n",
    "                    if os.path.exists(input_path) and os.path.exists(label_path):\n",
    "                        self.file_pairs.append((input_path, label_path))\n",
    "                        files_in_this_folder += 1\n",
    "                    else:\n",
    "                        print(f\"\\n  Warning: Files for '{pair_id}' listed but not found in '{folder_name}'. Skipping.\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"\\n  Error reading 'random_subset' in '{folder_name}': {e}\")\n",
    "            \n",
    "            total_files_loaded += files_in_this_folder\n",
    "\n",
    "        print(f\"\\nLoaded a total of {total_files_loaded} file pairs from all 'random_subset' files.\")\n",
    "        print(f\"Total dataset size: {len(self.file_pairs)} files.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label = np.load(label_path).astype(np.float32) # Load as float\n",
    "        \n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_tensor_float = torch.from_numpy(label).squeeze()\n",
    "        \n",
    "        # --- MODIFIED: Convert float label to class index ---\n",
    "        label_class_tensor = pl_to_class(label_tensor_float)\n",
    "        \n",
    "        return pc_tensor, label_class_tensor # Return class index\n",
    "\n",
    "# --- 3. MODIFIED: Model head reduced and outputting 31 classes ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1) # -> (batch, 512, 7000)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :] \n",
    "        feat_stream = x[:, 3:, :] \n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1) \n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x))) \n",
    "        x = torch.max(x, 2)[0]  # -> (batch, 512)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "\n",
    "        # --- MODIFIED: Final layer outputs NUM_CLASSES (31) ---\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 512) # 512 -> 512\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, NUM_CLASSES) # Output 31 classes\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # -> (batch, 7, 7000)\n",
    "        x = self.encoder(x)    # -> (batch, 512)\n",
    "\n",
    "        # Classification head\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x) # -> (batch, 31)\n",
    "        return x # Do not squeeze\n",
    "\n",
    "# --- 4. Main Training Script (Modified for Classification) ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    print(f\"Starting classification training with LEARNING_RATE = {LEARNING_RATE} for {NUM_EPOCHS} epochs.\")\n",
    "\n",
    "    # --- Create Datasets and Dataloaders ---\n",
    "    train_dataset = StandardPointCloudDataset(\n",
    "        data_folders=ALL_DATA_FOLDERS,\n",
    "        base_dir=BASE_TRAIN_DIR\n",
    "    )\n",
    "    if len(train_dataset) == 0:\n",
    "        raise ValueError(\"Dataset is empty. Check paths and 'random_subset' files.\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "\n",
    "    # --- Initialize Model ---\n",
    "    model = PointNetPathLoss().to(device) # Model head is now for classification\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model Initialized: {model.__class__.__name__} (Classifier)\")\n",
    "    print(f\"Target Encoder Output Dimension: {FEATURE_DIM}\")\n",
    "    print(f\"Target Output Classes: {NUM_CLASSES}\")\n",
    "    print(f\"Total Trainable Parameters: {total_params:,}\") # ~840k\n",
    "    \n",
    "    # --- MODIFIED: Loss and Optimizer ---\n",
    "    criterion = torch.nn.CrossEntropyLoss() # Switched to CrossEntropy for classification\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    # ------------------------------------\n",
    "\n",
    "    # --- Load Checkpoint ---\n",
    "    start_epoch = 0\n",
    "    # We check for the new model path\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"Loading existing checkpoint from {MODEL_SAVE_PATH}\")\n",
    "        try:\n",
    "            checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "            \n",
    "            # Try to load the model weights\n",
    "            model.load_state_dict(checkpoint['model_state_dict'], strict=True) \n",
    "            print(\"Model weights loaded successfully (strict=True).\")\n",
    "            \n",
    "            # Try to load optimizer and epoch\n",
    "            if 'optimizer_state_dict' in checkpoint and 'epoch' in checkpoint:\n",
    "                 optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                 start_epoch = checkpoint['epoch'] + 1\n",
    "                 print(f\"Optimizer state loaded. Resuming training from epoch {start_epoch + 1}.\")\n",
    "            else:\n",
    "                 print(\"Optimizer/epoch not in checkpoint. Starting from epoch 0.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # This will happen if the old (16-class) model is at this path\n",
    "            print(f\"Error loading checkpoint (likely architecture mismatch): {e}.\")\n",
    "            print(\"Starting fresh training from epoch 0.\")\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        print(f\"No existing model found at {MODEL_SAVE_PATH}. Starting fresh from epoch 0.\")\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        total_correct = 0 # For accuracy\n",
    "        total_samples = 0 # For accuracy\n",
    "        avg_train_acc = 0.0 # Initialize for checkpoint saving\n",
    "\n",
    "        for i, (pc_batch, label_batch) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")):\n",
    "            pc_batch = pc_batch.to(device)\n",
    "            label_batch = label_batch.to(device) # (batch_size,)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(pc_batch) # (batch_size, 31)\n",
    "            loss = criterion(out, label_batch)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"Warning: Encountered non-finite loss: {loss.item()} at step {i}. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * pc_batch.size(0)\n",
    "            \n",
    "            # --- Calculate Accuracy ---\n",
    "            _, predicted_class = torch.max(out, 1) # Get the index of the max logit\n",
    "            total_correct += (predicted_class == label_batch).sum().item()\n",
    "            total_samples += label_batch.size(0)\n",
    "\n",
    "        # --- MODIFIED: Report Accuracy ---\n",
    "        if total_samples > 0:\n",
    "            avg_train_loss = total_train_loss / total_samples\n",
    "            avg_train_acc = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1:02d} | Train Loss: {avg_train_loss:8.4f} | Train Accuracy: {avg_train_acc * 100:6.2f}%\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1:02d} | No data processed.\")\n",
    "\n",
    "        # --- Save Checkpoint After Each Epoch ---\n",
    "        print(f\"Saving model checkpoint after epoch {epoch+1}...\")\n",
    "        try:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'accuracy': avg_train_acc, # Save accuracy\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model checkpoint: {e}\")\n",
    "        # ----------------------------------------\n",
    "\n",
    "    print(\"--- Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b5c1c83f-d2b1-4fa7-a3d1-9c02f5057c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical Batch Size: 32\n",
      "Filtered to 5 folders for Tx IDs: [1, 18, 8, 19, 2]\n",
      "Using device: cuda\n",
      "Starting classification training with LEARNING_RATE = 0.001 for 30 epochs.\n",
      "Scanning 5 folders for 'random_subset' files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning folders: 100%|██████████| 5/5 [00:00<00:00, 21.07it/s]\n",
      "/tmp/ipykernel_87127/2506507942.py:235: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded a total of 40000 file pairs from all 'random_subset' files.\n",
      "Total dataset size: 40000 files.\n",
      "Model Initialized: PointNetPathLoss (Classifier)\n",
      "Target Encoder Output Dimension: 512\n",
      "Target Output Classes: 31\n",
      "Total Trainable Parameters: 846,943\n",
      "Loading existing checkpoint from pointnet_classifier_model_31class_28GHz.pth\n",
      "Model weights loaded successfully (strict=True).\n",
      "Optimizer state loaded. Resuming training from epoch 11.\n",
      "\n",
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss:   2.2541 | Train Accuracy:  25.33%\n",
      "Saving model checkpoint after epoch 11...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss:   2.2320 | Train Accuracy:  25.55%\n",
      "Saving model checkpoint after epoch 12...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss:   2.2288 | Train Accuracy:  25.69%\n",
      "Saving model checkpoint after epoch 13...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss:   2.2221 | Train Accuracy:  25.90%\n",
      "Saving model checkpoint after epoch 14...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss:   2.2153 | Train Accuracy:  25.78%\n",
      "Saving model checkpoint after epoch 15...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss:   2.2015 | Train Accuracy:  26.43%\n",
      "Saving model checkpoint after epoch 16...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss:   2.1982 | Train Accuracy:  26.47%\n",
      "Saving model checkpoint after epoch 17...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss:   2.1918 | Train Accuracy:  26.88%\n",
      "Saving model checkpoint after epoch 18...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss:   2.1850 | Train Accuracy:  27.16%\n",
      "Saving model checkpoint after epoch 19...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss:   2.1854 | Train Accuracy:  26.56%\n",
      "Saving model checkpoint after epoch 20...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss:   2.1745 | Train Accuracy:  27.07%\n",
      "Saving model checkpoint after epoch 21...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss:   2.1696 | Train Accuracy:  27.54%\n",
      "Saving model checkpoint after epoch 22...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss:   2.1662 | Train Accuracy:  27.54%\n",
      "Saving model checkpoint after epoch 23...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss:   2.1636 | Train Accuracy:  27.37%\n",
      "Saving model checkpoint after epoch 24...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss:   2.1600 | Train Accuracy:  27.69%\n",
      "Saving model checkpoint after epoch 25...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss:   2.1584 | Train Accuracy:  27.70%\n",
      "Saving model checkpoint after epoch 26...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss:   2.1564 | Train Accuracy:  27.70%\n",
      "Saving model checkpoint after epoch 27...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss:   2.1491 | Train Accuracy:  27.77%\n",
      "Saving model checkpoint after epoch 28...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss:   2.1400 | Train Accuracy:  28.19%\n",
      "Saving model checkpoint after epoch 29...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 [Train]: 100%|██████████| 1250/1250 [02:18<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss:   2.1403 | Train Accuracy:  28.13%\n",
      "Saving model checkpoint after epoch 30...\n",
      "Model saved to pointnet_classifier_model_31class_28GHz.pth\n",
      "--- Training Complete ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "\n",
    "# --- MODIFIED: Checkpoint, Feature Dim, and Class Config ---\n",
    "FEATURE_DIM = 512 # REDUCED from 1536 to lower parameter count\n",
    "NUM_CLASSES = 31  # (200 - 50) / 5 + 1 = 31 classes (50, 55, ..., 200)\n",
    "MODEL_SAVE_PATH = \"pointnet_classifier_model_31class_28GHz.pth\" # New path for new task\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "print(f\"Physical Batch Size: {BATCH_SIZE}\")\n",
    "TX_SUBSET_SELECTED = [1, 18, 8, 19, 2]\n",
    "\n",
    "# List of ALL potential folders (will be filtered)\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_1\", \"28GHz_processed__for_training_Tx_10\",\n",
    "    \"28GHz_processed__for_training_Tx_11\", \"28GHz_processed__for_training_Tx_13\",\n",
    "    \"28GHz_processed__for_training_Tx_15\", \"28GHz_processed__for_training_Tx_16\",\n",
    "    \"28GHz_processed__for_training_Tx_17\", \"28GHz_processed__for_training_Tx_18\",\n",
    "    \"28GHz_processed__for_training_Tx_19\", \"28GHz_processed__for_training_Tx_2\",\n",
    "    \"28GHz_processed__for_training_Tx_3\", \"28GHz_processed__for_training_Tx_4\",\n",
    "    \"28GHz_processed__for_training_Tx_6\", \"28GHz_processed__for_training_Tx_7\",\n",
    "    \"28GHz_processed__for_training_Tx_8\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "ALL_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str\n",
    "]\n",
    "if not ALL_DATA_FOLDERS:\n",
    "    raise ValueError(\"No data folders found matching the TX_SUBSET_SELECTED.\")\n",
    "print(f\"Filtered to {len(ALL_DATA_FOLDERS)} folders for Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "# --- 2. MODIFIED: Dataset handles classification ---\n",
    "\n",
    "def pl_to_class(pl_tensor):\n",
    "    \"\"\"Converts a raw path loss value to a class index.\"\"\"\n",
    "    # 1. Round to nearest 5\n",
    "    pl_rounded = torch.round(pl_tensor / 5.0) * 5.0\n",
    "    # 2. Clip to the valid range [50, 200]\n",
    "    pl_clipped = torch.clamp(pl_rounded, 50.0, 200.0)\n",
    "    # 3. Convert to class index: (50 -> 0, 55 -> 1, ..., 200 -> 30)\n",
    "    class_index = (pl_clipped - 50.0) / 5.0\n",
    "    # 4. Return as a long integer for CrossEntropyLoss\n",
    "    return class_index.long()\n",
    "\n",
    "class StandardPointCloudDataset(Dataset):\n",
    "    def __init__(self, data_folders, base_dir):\n",
    "        self.file_pairs = []\n",
    "        print(f\"Scanning {len(data_folders)} folders for 'random_subset' files...\")\n",
    "        \n",
    "        total_files_loaded = 0\n",
    "\n",
    "        for folder_name in tqdm(data_folders, desc=\"Scanning folders\"):\n",
    "            folder_path = os.path.join(base_dir, folder_name)\n",
    "            subset_file_path = os.path.join(folder_path, \"random_subset\")\n",
    "\n",
    "            if not os.path.exists(subset_file_path):\n",
    "                print(f\"\\n  Warning: 'random_subset' file not found in '{folder_name}'. Skipping folder.\")\n",
    "                continue\n",
    "            \n",
    "            files_in_this_folder = 0\n",
    "            try:\n",
    "                with open(subset_file_path, 'r') as f:\n",
    "                    pair_ids = f.readlines()\n",
    "                \n",
    "                for pair_id in pair_ids:\n",
    "                    pair_id = pair_id.strip() \n",
    "                    if not pair_id: \n",
    "                        continue\n",
    "                        \n",
    "                    input_filename = f\"{pair_id}_for_train.npy\"\n",
    "                    label_filename = f\"{pair_id}_path_loss.npy\"\n",
    "                    \n",
    "                    input_path = os.path.join(folder_path, input_filename)\n",
    "                    label_path = os.path.join(folder_path, label_filename)\n",
    "\n",
    "                    if os.path.exists(input_path) and os.path.exists(label_path):\n",
    "                        self.file_pairs.append((input_path, label_path))\n",
    "                        files_in_this_folder += 1\n",
    "                    else:\n",
    "                        print(f\"\\n  Warning: Files for '{pair_id}' listed but not found in '{folder_name}'. Skipping.\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"\\n  Error reading 'random_subset' in '{folder_name}': {e}\")\n",
    "            \n",
    "            total_files_loaded += files_in_this_folder\n",
    "\n",
    "        print(f\"\\nLoaded a total of {total_files_loaded} file pairs from all 'random_subset' files.\")\n",
    "        print(f\"Total dataset size: {len(self.file_pairs)} files.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label = np.load(label_path).astype(np.float32) # Load as float\n",
    "        \n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_tensor_float = torch.from_numpy(label).squeeze()\n",
    "        \n",
    "        # --- MODIFIED: Convert float label to class index ---\n",
    "        label_class_tensor = pl_to_class(label_tensor_float)\n",
    "        \n",
    "        return pc_tensor, label_class_tensor # Return class index\n",
    "\n",
    "# --- 3. MODIFIED: Model head reduced and outputting 31 classes ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1) # -> (batch, 512, 7000)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :] \n",
    "        feat_stream = x[:, 3:, :] \n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1) \n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x))) \n",
    "        x = torch.max(x, 2)[0]  # -> (batch, 512)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "\n",
    "        # --- MODIFIED: Final layer outputs NUM_CLASSES (31) ---\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 512) # 512 -> 512\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, NUM_CLASSES) # Output 31 classes\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # -> (batch, 7, 7000)\n",
    "        x = self.encoder(x)    # -> (batch, 512)\n",
    "\n",
    "        # Classification head\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x) # -> (batch, 31)\n",
    "        return x # Do not squeeze\n",
    "\n",
    "# --- 4. Main Training Script (Modified for Classification) ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    print(f\"Starting classification training with LEARNING_RATE = {LEARNING_RATE} for {NUM_EPOCHS} epochs.\")\n",
    "\n",
    "    # --- Create Datasets and Dataloaders ---\n",
    "    train_dataset = StandardPointCloudDataset(\n",
    "        data_folders=ALL_DATA_FOLDERS,\n",
    "        base_dir=BASE_TRAIN_DIR\n",
    "    )\n",
    "    if len(train_dataset) == 0:\n",
    "        raise ValueError(\"Dataset is empty. Check paths and 'random_subset' files.\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "\n",
    "    # --- Initialize Model ---\n",
    "    model = PointNetPathLoss().to(device) # Model head is now for classification\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model Initialized: {model.__class__.__name__} (Classifier)\")\n",
    "    print(f\"Target Encoder Output Dimension: {FEATURE_DIM}\")\n",
    "    print(f\"Target Output Classes: {NUM_CLASSES}\")\n",
    "    print(f\"Total Trainable Parameters: {total_params:,}\") # ~840k\n",
    "    \n",
    "    # --- MODIFIED: Loss and Optimizer ---\n",
    "    criterion = torch.nn.CrossEntropyLoss() # Switched to CrossEntropy for classification\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    # ------------------------------------\n",
    "\n",
    "    # --- Load Checkpoint ---\n",
    "    start_epoch = 0\n",
    "    # We check for the new model path\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        print(f\"Loading existing checkpoint from {MODEL_SAVE_PATH}\")\n",
    "        try:\n",
    "            checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "            \n",
    "            # Try to load the model weights\n",
    "            model.load_state_dict(checkpoint['model_state_dict'], strict=True) \n",
    "            print(\"Model weights loaded successfully (strict=True).\")\n",
    "            \n",
    "            # Try to load optimizer and epoch\n",
    "            if 'optimizer_state_dict' in checkpoint and 'epoch' in checkpoint:\n",
    "                 optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                 start_epoch = checkpoint['epoch'] + 1\n",
    "                 print(f\"Optimizer state loaded. Resuming training from epoch {start_epoch + 1}.\")\n",
    "            else:\n",
    "                 print(\"Optimizer/epoch not in checkpoint. Starting from epoch 0.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # This will happen if the old (16-class) model is at this path\n",
    "            print(f\"Error loading checkpoint (likely architecture mismatch): {e}.\")\n",
    "            print(\"Starting fresh training from epoch 0.\")\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        print(f\"No existing model found at {MODEL_SAVE_PATH}. Starting fresh from epoch 0.\")\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        total_correct = 0 # For accuracy\n",
    "        total_samples = 0 # For accuracy\n",
    "        avg_train_acc = 0.0 # Initialize for checkpoint saving\n",
    "\n",
    "        for i, (pc_batch, label_batch) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")):\n",
    "            pc_batch = pc_batch.to(device)\n",
    "            label_batch = label_batch.to(device) # (batch_size,)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(pc_batch) # (batch_size, 31)\n",
    "            loss = criterion(out, label_batch)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"Warning: Encountered non-finite loss: {loss.item()} at step {i}. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * pc_batch.size(0)\n",
    "            \n",
    "            # --- Calculate Accuracy ---\n",
    "            _, predicted_class = torch.max(out, 1) # Get the index of the max logit\n",
    "            total_correct += (predicted_class == label_batch).sum().item()\n",
    "            total_samples += label_batch.size(0)\n",
    "\n",
    "        # --- MODIFIED: Report Accuracy ---\n",
    "        if total_samples > 0:\n",
    "            avg_train_loss = total_train_loss / total_samples\n",
    "            avg_train_acc = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1:02d} | Train Loss: {avg_train_loss:8.4f} | Train Accuracy: {avg_train_acc * 100:6.2f}%\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1:02d} | No data processed.\")\n",
    "\n",
    "        # --- Save Checkpoint After Each Epoch ---\n",
    "        print(f\"Saving model checkpoint after epoch {epoch+1}...\")\n",
    "        try:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'accuracy': avg_train_acc, # Save accuracy\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model checkpoint: {e}\")\n",
    "        # ----------------------------------------\n",
    "\n",
    "    print(\"--- Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28507cdf-1562-4068-9142-f1b8cdc39e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 folders for evaluation for Freq: 800MHz, Tx IDs: [1, 18, 8, 19, 2]\n",
      "Using device: cuda\n",
      "Model initialized (Classifier).\n",
      "Successfully loaded model weights from pointnet_classifier_model_31class_800MHz.pth\n",
      "\n",
      "--- Starting Evaluation ---\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87127/338536579.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
      "  Evaluating: 100%|██████████| 924/924 [00:21<00:00, 43.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):   9.0920 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_800MHz_Tx_1.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 826/826 [00:19<00:00, 42.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  11.5491 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_800MHz_Tx_18.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 666/666 [00:15<00:00, 42.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  10.8294 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_800MHz_Tx_19.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 727/727 [00:17<00:00, 42.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  10.4897 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_800MHz_Tx_2.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 751/751 [00:17<00:00, 42.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  11.5676 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_800MHz_Tx_8.csv\n",
      "\n",
      "--- Evaluation Complete ---\n",
      "Overall Test RMSE (on rounded values):  10.6917 dB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import re \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "TEST_SAVE_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "os.makedirs(TEST_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- MODIFIED: Model Configuration ---\n",
    "MODEL_SAVE_PATH = \"pointnet_classifier_model_31class_800MHz.pth\" # Classifier model\n",
    "FEATURE_DIM = 512    # Must match the trained classifier\n",
    "NUM_CLASSES = 31     # Must match the trained classifier (50-200 in 5dB steps)\n",
    "\n",
    "# --- Evaluation Run Configuration ---\n",
    "FREQ_TO_TEST = \"800MHz\" # Run for only one frequency\n",
    "TX_SUBSET_SELECTED = [1, 18, 8, 19, 2]\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# List of ALL potential folders for the test set\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_1\", \"28GHz_processed__for_training_Tx_10\",\n",
    "    \"28GHz_processed__for_training_Tx_11\", \"28GHz_processed__for_training_Tx_13\",\n",
    "    \"28GHz_processed__for_training_Tx_15\", \"28GHz_processed__for_training_Tx_16\",\n",
    "    \"28GHz_processed__for_training_Tx_17\", \"28GHz_processed__for_training_Tx_18\",\n",
    "    \"28GHz_processed__for_training_Tx_19\", \"28GHz_processed__for_training_Tx_2\",\n",
    "    \"28GHz_processed__for_training_Tx_3\", \"28GHz_processed__for_training_Tx_4\",\n",
    "    \"28GHz_processed__for_training_Tx_6\", \"28GHz_processed__for_training_Tx_7\",\n",
    "    \"28GHz_processed__for_training_Tx_8\",\n",
    "    \"7GHz_processed__for_training_Tx_1\", \"7GHz_processed__for_training_Tx_10\",\n",
    "    \"7GHz_processed__for_training_Tx_11\", \"7GHz_processed__for_training_Tx_13\",\n",
    "    \"7GHz_processed__for_training_Tx_15\", \"7GHz_processed__for_training_Tx_16\",\n",
    "    \"7Gzz_processed__for_training_Tx_17\", \"7GHz_processed__for_training_Tx_18\",\n",
    "    \"7GHz_processed__for_training_Tx_19\", \"7GHz_processed__for_training_Tx_2\",\n",
    "    \"7GHz_processed__for_training_Tx_3\", \"7GHz_processed__for_training_Tx_4\",\n",
    "    \"7GHz_processed__for_training_Tx_6\", \"7GHz_processed__for_training_Tx_7\",\n",
    "    \"7GHz_processed__for_training_Tx_8\",\n",
    "    \"800MHz_processed__for_training_Tx_1\", \"800MHz_processed__for_training_Tx_10\",\n",
    "    \"800MHz_processed__for_training_Tx_11\", \"800MHz_processed__for_training_Tx_13\",\n",
    "    \"800MHz_processed__for_training_Tx_15\", \"800MHz_processed__for_training_Tx_16\",\n",
    "    \"800MHz_processed__for_training_Tx_17\", \"800MHz_processed__for_training_Tx_18\",\n",
    "    \"800MHz_processed__for_training_Tx_19\", \"800MHz_processed__for_training_Tx_2\",\n",
    "    \"800MHz_processed__for_training_Tx_3\", \"800MHz_processed__for_training_Tx_4\",\n",
    "    \"800MHz_processed__for_training_Tx_6\", \"800MHz_processed__for_training_Tx_7\",\n",
    "    \"800MHz_processed__for_training_Tx_8\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED AND FREQ_TO_TEST ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "TEST_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str and folder.startswith(FREQ_TO_TEST)\n",
    "]\n",
    "if not TEST_DATA_FOLDERS:\n",
    "    raise ValueError(f\"No folders found for Tx IDs {TX_SUBSET_SELECTED} and Freq {FREQ_TO_TEST}.\")\n",
    "print(f\"Found {len(TEST_DATA_FOLDERS)} folders for evaluation for Freq: {FREQ_TO_TEST}, Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "# --- 2. Label Conversion Functions ---\n",
    "\n",
    "def pl_to_class(pl_tensor):\n",
    "    \"\"\"Converts a raw path loss value to a class index (0-30).\"\"\"\n",
    "    pl_rounded = torch.round(pl_tensor / 5.0) * 5.0\n",
    "    pl_clipped = torch.clamp(pl_rounded, 50.0, 200.0)\n",
    "    class_index = (pl_clipped - 50.0) / 5.0\n",
    "    return class_index.long()\n",
    "\n",
    "def class_to_pl(class_index_tensor):\n",
    "    \"\"\"Converts a class index (0-30) back to a path loss value (50-200).\"\"\"\n",
    "    # Note: Needs to be done with torch tensors to keep on-device\n",
    "    return (class_index_tensor.float() * 5.0) + 50.0\n",
    "\n",
    "# --- 3. Dataset Definition for Evaluation ---\n",
    "\n",
    "class EvaluationPointCloudDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.file_pairs = []\n",
    "        input_files = glob.glob(os.path.join(folder_path, \"*_for_train.npy\"))\n",
    "        \n",
    "        for input_path in input_files:\n",
    "            label_path = input_path.replace(\"_for_train.npy\", \"_path_loss.npy\")\n",
    "            if os.path.exists(label_path):\n",
    "                self.file_pairs.append((input_path, label_path))\n",
    "            else:\n",
    "                print(f\"Warning: Missing label for {input_path}. Skipping file.\")\n",
    "        if not self.file_pairs:\n",
    "            print(f\"Warning: No valid file pairs found in {folder_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label_original_float = np.load(label_path).astype(np.float32)\n",
    "        \n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_original_tensor = torch.from_numpy(label_original_float).squeeze()\n",
    "        \n",
    "        # Also return the class index for calculating rounded truth\n",
    "        label_class_tensor = pl_to_class(label_original_tensor)\n",
    "        \n",
    "        return pc_tensor, label_class_tensor, label_original_tensor\n",
    "\n",
    "# --- 4. Model Definitions (CLASSIFIER VERSION) ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1) # -> 512\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :]\n",
    "        feat_stream = x[:, 3:, :]\n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1)\n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.max(x, 2)[0] # -> (batch, 512)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, NUM_CLASSES) # -> 31 outputs\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x) # -> (batch, 31)\n",
    "        return x # Return logits\n",
    "\n",
    "# --- 5. Main Evaluation Script ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = PointNetPathLoss().to(device)\n",
    "    print(\"Model initialized (Classifier).\")\n",
    "\n",
    "    if not os.path.exists(MODEL_SAVE_PATH):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {MODEL_SAVE_PATH}.\")\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        print(f\"Successfully loaded model weights from {MODEL_SAVE_PATH}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading checkpoint: {e}. Ensure model definition matches checkpoint.\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions_rounded = []\n",
    "    all_labels_rounded = []\n",
    "    all_labels_original = [] # For the CSV\n",
    "\n",
    "    print(\"\\n--- Starting Evaluation ---\")\n",
    "    \n",
    "    for folder_name in TEST_DATA_FOLDERS:\n",
    "        print(f\"\\n▶ Processing folder: {folder_name}\")\n",
    "        folder_path = os.path.join(BASE_TRAIN_DIR, folder_name)\n",
    "        \n",
    "        test_dataset = EvaluationPointCloudDataset(folder_path=folder_path)\n",
    "        if len(test_dataset) == 0:\n",
    "            print(\"  -> No files found. Skipping folder.\")\n",
    "            continue\n",
    "            \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "            num_workers=NUM_WORKERS, pin_memory=(device.type == 'cuda')\n",
    "        )\n",
    "        \n",
    "        # Lists for this folder's results\n",
    "        folder_preds_list = []\n",
    "        folder_true_rounded_list = []\n",
    "        folder_true_original_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for pc_batch, label_class_batch, label_original_batch in tqdm(test_loader, desc=\"  Evaluating\"):\n",
    "                pc_batch = pc_batch.to(device)\n",
    "                label_class_batch = label_class_batch.to(device) # True class index\n",
    "                # label_original_batch stays on CPU, we just need it for the CSV\n",
    "                \n",
    "                out_logits = model(pc_batch) # -> (batch, 31)\n",
    "                \n",
    "                # Get predicted class index\n",
    "                _, predicted_class_idx = torch.max(out_logits, 1)\n",
    "                \n",
    "                # --- Convert indices back to dB values for RMSE and CSV ---\n",
    "                predicted_pl = class_to_pl(predicted_class_idx)\n",
    "                true_rounded_pl = class_to_pl(label_class_batch)\n",
    "                \n",
    "                # Store results\n",
    "                folder_preds_list.append(predicted_pl.cpu().numpy())\n",
    "                folder_true_rounded_list.append(true_rounded_pl.cpu().numpy())\n",
    "                folder_true_original_list.append(label_original_batch.cpu().numpy())\n",
    "        \n",
    "        # Concatenate all batch results\n",
    "        predictions = np.concatenate(folder_preds_list)\n",
    "        labels_rounded = np.concatenate(folder_true_rounded_list)\n",
    "        labels_original = np.concatenate(folder_true_original_list)\n",
    "        \n",
    "        all_predictions_rounded.append(predictions)\n",
    "        all_labels_rounded.append(labels_rounded)\n",
    "        \n",
    "        # Calculate folder-specific RMSE using ROUNDED values\n",
    "        folder_mse = np.mean((predictions - labels_rounded)**2)\n",
    "        folder_rmse = np.sqrt(folder_mse)\n",
    "        print(f\"  -> Folder RMSE (on rounded values): {folder_rmse:8.4f} dB\")\n",
    "        \n",
    "        # --- Create and Save CSV ---\n",
    "        match = re.match(r\"(\\w+)_processed__for_training_Tx_(\\d+)\", folder_name)\n",
    "        if not match:\n",
    "            print(f\"  -> ERROR: Could not parse folder name '{folder_name}'. Skipping CSV save.\")\n",
    "            continue\n",
    "            \n",
    "        freq = match.group(1)\n",
    "        tx_id = match.group(2)\n",
    "        \n",
    "        csv_filename = f\"test_{freq}_Tx_{tx_id}.csv\"\n",
    "        csv_save_path = os.path.join(TEST_SAVE_DIR, csv_filename)\n",
    "        \n",
    "        # Create DataFrame with the 3 requested columns\n",
    "        results_df = pd.DataFrame({\n",
    "            'predicted_pathloss': predictions,\n",
    "            'true_pathloss_rounded': labels_rounded,\n",
    "            'original_pathloss': labels_original\n",
    "        })\n",
    "        \n",
    "        results_df.to_csv(csv_save_path, index=False)\n",
    "        print(f\"  -> Results saved to: {csv_save_path}\")\n",
    "\n",
    "    # --- Calculate and Print Overall RMSE ---\n",
    "    if all_predictions_rounded:\n",
    "        overall_preds = np.concatenate(all_predictions_rounded)\n",
    "        overall_labels = np.concatenate(all_labels_rounded)\n",
    "        \n",
    "        overall_mse = np.mean((overall_preds - overall_labels)**2)\n",
    "        overall_rmse = np.sqrt(overall_mse)\n",
    "        \n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(f\"Overall Test RMSE (on rounded values): {overall_rmse:8.4f} dB\")\n",
    "    else:\n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(\"No test data was processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00364f57-de0d-4e7e-9749-064939bf91ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import re \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "TEST_SAVE_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "os.makedirs(TEST_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- MODIFIED: Model Configuration ---\n",
    "MODEL_SAVE_PATH = \"pointnet_classifier_model_31class_800MHz.pth\" # Classifier model\n",
    "FEATURE_DIM = 512    # Must match the trained classifier\n",
    "NUM_CLASSES = 31     # Must match the trained classifier (50-200 in 5dB steps)\n",
    "\n",
    "# --- Evaluation Run Configuration ---\n",
    "FREQ_TO_TEST = \"800MHz\" # Run for only one frequency\n",
    "TX_SUBSET_SELECTED = [1, 18, 8, 19, 2]\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# List of ALL potential folders for the test set\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_1\", \"28GHz_processed__for_training_Tx_10\",\n",
    "    \"28GHz_processed__for_training_Tx_11\", \"28GHz_processed__for_training_Tx_13\",\n",
    "    \"28GHz_processed__for_training_Tx_15\", \"28GHz_processed__for_training_Tx_16\",\n",
    "    \"28GHz_processed__for_training_Tx_17\", \"28GHz_processed__for_training_Tx_18\",\n",
    "    \"28GHz_processed__for_training_Tx_19\", \"28GHz_processed__for_training_Tx_2\",\n",
    "    \"28GHz_processed__for_training_Tx_3\", \"28GHz_processed__for_training_Tx_4\",\n",
    "    \"28GHz_processed__for_training_Tx_6\", \"28GHz_processed__for_training_Tx_7\",\n",
    "    \"28GHz_processed__for_training_Tx_8\",\n",
    "    \"7GHz_processed__for_training_Tx_1\", \"7GHz_processed__for_training_Tx_10\",\n",
    "    \"7GHz_processed__for_training_Tx_11\", \"7GHz_processed__for_training_Tx_13\",\n",
    "    \"7GHz_processed__for_training_Tx_15\", \"7GHz_processed__for_training_Tx_16\",\n",
    "    \"7Gzz_processed__for_training_Tx_17\", \"7GHz_processed__for_training_Tx_18\",\n",
    "    \"7GHz_processed__for_training_Tx_19\", \"7GHz_processed__for_training_Tx_2\",\n",
    "    \"7GHz_processed__for_training_Tx_3\", \"7GHz_processed__for_training_Tx_4\",\n",
    "    \"7GHz_processed__for_training_Tx_6\", \"7GHz_processed__for_training_Tx_7\",\n",
    "    \"7GHz_processed__for_training_Tx_8\",\n",
    "    \"800MHz_processed__for_training_Tx_1\", \"800MHz_processed__for_training_Tx_10\",\n",
    "    \"800MHz_processed__for_training_Tx_11\", \"800MHz_processed__for_training_Tx_13\",\n",
    "    \"800MHz_processed__for_training_Tx_15\", \"800MHz_processed__for_training_Tx_16\",\n",
    "    \"800MHz_processed__for_training_Tx_17\", \"800MHz_processed__for_training_Tx_18\",\n",
    "    \"800MHz_processed__for_training_Tx_19\", \"800MHz_processed__for_training_Tx_2\",\n",
    "    \"800MHz_processed__for_training_Tx_3\", \"800MHz_processed__for_training_Tx_4\",\n",
    "    \"800MHz_processed__for_training_Tx_6\", \"800MHz_processed__for_training_Tx_7\",\n",
    "    \"800MHz_processed__for_training_Tx_8\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED AND FREQ_TO_TEST ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "TEST_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str and folder.startswith(FREQ_TO_TEST)\n",
    "]\n",
    "if not TEST_DATA_FOLDERS:\n",
    "    raise ValueError(f\"No folders found for Tx IDs {TX_SUBSET_SELECTED} and Freq {FREQ_TO_TEST}.\")\n",
    "print(f\"Found {len(TEST_DATA_FOLDERS)} folders for evaluation for Freq: {FREQ_TO_TEST}, Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "# --- 2. Label Conversion Functions ---\n",
    "\n",
    "def pl_to_class(pl_tensor):\n",
    "    \"\"\"Converts a raw path loss value to a class index (0-30).\"\"\"\n",
    "    pl_rounded = torch.round(pl_tensor / 5.0) * 5.0\n",
    "    pl_clipped = torch.clamp(pl_rounded, 50.0, 200.0)\n",
    "    class_index = (pl_clipped - 50.0) / 5.0\n",
    "    return class_index.long()\n",
    "\n",
    "def class_to_pl(class_index_tensor):\n",
    "    \"\"\"Converts a class index (0-30) back to a path loss value (50-200).\"\"\"\n",
    "    # Note: Needs to be done with torch tensors to keep on-device\n",
    "    return (class_index_tensor.float() * 5.0) + 50.0\n",
    "\n",
    "# --- 3. Dataset Definition for Evaluation ---\n",
    "\n",
    "class EvaluationPointCloudDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.file_pairs = []\n",
    "        input_files = glob.glob(os.path.join(folder_path, \"*_for_train.npy\"))\n",
    "        \n",
    "        for input_path in input_files:\n",
    "            label_path = input_path.replace(\"_for_train.npy\", \"_path_loss.npy\")\n",
    "            if os.path.exists(label_path):\n",
    "                self.file_pairs.append((input_path, label_path))\n",
    "            else:\n",
    "                print(f\"Warning: Missing label for {input_path}. Skipping file.\")\n",
    "        if not self.file_pairs:\n",
    "            print(f\"Warning: No valid file pairs found in {folder_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label_original_float = np.load(label_path).astype(np.float32)\n",
    "        \n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_original_tensor = torch.from_numpy(label_original_float).squeeze()\n",
    "        \n",
    "        # Also return the class index for calculating rounded truth\n",
    "        label_class_tensor = pl_to_class(label_original_tensor)\n",
    "        \n",
    "        return pc_tensor, label_class_tensor, label_original_tensor\n",
    "\n",
    "# --- 4. Model Definitions (CLASSIFIER VERSION) ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1) # -> 512\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :]\n",
    "        feat_stream = x[:, 3:, :]\n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1)\n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.max(x, 2)[0] # -> (batch, 512)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, NUM_CLASSES) # -> 31 outputs\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x) # -> (batch, 31)\n",
    "        return x # Return logits\n",
    "\n",
    "# --- 5. Main Evaluation Script ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = PointNetPathLoss().to(device)\n",
    "    print(\"Model initialized (Classifier).\")\n",
    "\n",
    "    if not os.path.exists(MODEL_SAVE_PATH):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {MODEL_SAVE_PATH}.\")\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        print(f\"Successfully loaded model weights from {MODEL_SAVE_PATH}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading checkpoint: {e}. Ensure model definition matches checkpoint.\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions_rounded = []\n",
    "    all_labels_rounded = []\n",
    "    all_labels_original = [] # For the CSV\n",
    "\n",
    "    print(\"\\n--- Starting Evaluation ---\")\n",
    "    \n",
    "    for folder_name in TEST_DATA_FOLDERS:\n",
    "        print(f\"\\n▶ Processing folder: {folder_name}\")\n",
    "        folder_path = os.path.join(BASE_TRAIN_DIR, folder_name)\n",
    "        \n",
    "        test_dataset = EvaluationPointCloudDataset(folder_path=folder_path)\n",
    "        if len(test_dataset) == 0:\n",
    "            print(\"  -> No files found. Skipping folder.\")\n",
    "            continue\n",
    "            \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "            num_workers=NUM_WORKERS, pin_memory=(device.type == 'cuda')\n",
    "        )\n",
    "        \n",
    "        # Lists for this folder's results\n",
    "        folder_preds_list = []\n",
    "        folder_true_rounded_list = []\n",
    "        folder_true_original_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for pc_batch, label_class_batch, label_original_batch in tqdm(test_loader, desc=\"  Evaluating\"):\n",
    "                pc_batch = pc_batch.to(device)\n",
    "                label_class_batch = label_class_batch.to(device) # True class index\n",
    "                # label_original_batch stays on CPU, we just need it for the CSV\n",
    "                \n",
    "                out_logits = model(pc_batch) # -> (batch, 31)\n",
    "                \n",
    "                # Get predicted class index\n",
    "                _, predicted_class_idx = torch.max(out_logits, 1)\n",
    "                \n",
    "                # --- Convert indices back to dB values for RMSE and CSV ---\n",
    "                predicted_pl = class_to_pl(predicted_class_idx)\n",
    "                true_rounded_pl = class_to_pl(label_class_batch)\n",
    "                \n",
    "                # Store results\n",
    "                folder_preds_list.append(predicted_pl.cpu().numpy())\n",
    "                folder_true_rounded_list.append(true_rounded_pl.cpu().numpy())\n",
    "                folder_true_original_list.append(label_original_batch.cpu().numpy())\n",
    "        \n",
    "        # Concatenate all batch results\n",
    "        predictions = np.concatenate(folder_preds_list)\n",
    "        labels_rounded = np.concatenate(folder_true_rounded_list)\n",
    "        labels_original = np.concatenate(folder_true_original_list)\n",
    "        \n",
    "        all_predictions_rounded.append(predictions)\n",
    "        all_labels_rounded.append(labels_rounded)\n",
    "        \n",
    "        # Calculate folder-specific RMSE using ROUNDED values\n",
    "        folder_mse = np.mean((predictions - labels_rounded)**2)\n",
    "        folder_rmse = np.sqrt(folder_mse)\n",
    "        print(f\"  -> Folder RMSE (on rounded values): {folder_rmse:8.4f} dB\")\n",
    "        \n",
    "        # --- Create and Save CSV ---\n",
    "        match = re.match(r\"(\\w+)_processed__for_training_Tx_(\\d+)\", folder_name)\n",
    "        if not match:\n",
    "            print(f\"  -> ERROR: Could not parse folder name '{folder_name}'. Skipping CSV save.\")\n",
    "            continue\n",
    "            \n",
    "        freq = match.group(1)\n",
    "        tx_id = match.group(2)\n",
    "        \n",
    "        csv_filename = f\"test_{freq}_Tx_{tx_id}.csv\"\n",
    "        csv_save_path = os.path.join(TEST_SAVE_DIR, csv_filename)\n",
    "        \n",
    "        # Create DataFrame with the 3 requested columns\n",
    "        results_df = pd.DataFrame({\n",
    "            'predicted_pathloss': predictions,\n",
    "            'true_pathloss_rounded': labels_rounded,\n",
    "            'original_pathloss': labels_original\n",
    "        })\n",
    "        \n",
    "        results_df.to_csv(csv_save_path, index=False)\n",
    "        print(f\"  -> Results saved to: {csv_save_path}\")\n",
    "\n",
    "    # --- Calculate and Print Overall RMSE ---\n",
    "    if all_predictions_rounded:\n",
    "        overall_preds = np.concatenate(all_predictions_rounded)\n",
    "        overall_labels = np.concatenate(all_labels_rounded)\n",
    "        \n",
    "        overall_mse = np.mean((overall_preds - overall_labels)**2)\n",
    "        overall_rmse = np.sqrt(overall_mse)\n",
    "        \n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(f\"Overall Test RMSE (on rounded values): {overall_rmse:8.4f} dB\")\n",
    "    else:\n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(\"No test data was processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ebdd149-5204-46c1-b8fd-a7935eedaf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 folders for evaluation for Freq: 800MHz, Tx IDs: [5, 9, 12, 14, 20]\n",
      "Using device: cuda\n",
      "Model initialized (Classifier).\n",
      "Successfully loaded model weights from pointnet_classifier_model_31class_800MHz.pth\n",
      "\n",
      "--- Starting Evaluation ---\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87127/1428384949.py:173: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
      "  Evaluating: 100%|██████████| 730/730 [00:12<00:00, 58.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  17.8930 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_5.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 762/762 [00:13<00:00, 57.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  17.3058 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_9.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 751/751 [00:13<00:00, 56.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  23.7526 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_12.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 718/718 [00:12<00:00, 57.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  16.2086 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_14.csv\n",
      "\n",
      "▶ Processing folder: 800MHz_processed__for_training_Tx_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 696/696 [00:12<00:00, 57.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  15.2857 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_800MHz_Tx_20.csv\n",
      "\n",
      "--- Evaluation Complete ---\n",
      "Overall Test RMSE (on rounded values):  18.3914 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import re \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/test\"\n",
    "TEST_SAVE_DIR = \"/home/mkrishne/PL_competition/extracted_regions/test\"\n",
    "os.makedirs(TEST_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- MODIFIED: Model Configuration ---\n",
    "MODEL_SAVE_PATH = \"pointnet_classifier_model_31class_800MHz.pth\" # Classifier model\n",
    "FEATURE_DIM = 512    # Must match the trained classifier\n",
    "NUM_CLASSES = 31     # Must match the trained classifier (50-200 in 5dB steps)\n",
    "\n",
    "# --- Evaluation Run Configuration ---\n",
    "FREQ_TO_TEST = \"800MHz\" # Run for only one frequency\n",
    "TX_SUBSET_SELECTED = [5,9,12,14,20]\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# List of ALL potential folders for the test set\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_5\", \"28GHz_processed__for_training_Tx_9\",\n",
    "    \"28GHz_processed__for_training_Tx_12\", \"28GHz_processed__for_training_Tx_14\",\n",
    "    \"28GHz_processed__for_training_Tx_20\",\n",
    "    \"7GHz_processed__for_training_Tx_5\", \"7GHz_processed__for_training_Tx_9\",\n",
    "    \"7GHz_processed__for_training_Tx_12\", \"7GHz_processed__for_training_Tx_14\",\n",
    "    \"7GHz_processed__for_training_Tx_20\",\n",
    "    \"800MHz_processed__for_training_Tx_5\", \"800MHz_processed__for_training_Tx_9\",\n",
    "    \"800MHz_processed__for_training_Tx_12\", \"800MHz_processed__for_training_Tx_14\",\n",
    "    \"800MHz_processed__for_training_Tx_20\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED AND FREQ_TO_TEST ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "TEST_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str and folder.startswith(FREQ_TO_TEST)\n",
    "]\n",
    "if not TEST_DATA_FOLDERS:\n",
    "    raise ValueError(f\"No folders found for Tx IDs {TX_SUBSET_SELECTED} and Freq {FREQ_TO_TEST}.\")\n",
    "print(f\"Found {len(TEST_DATA_FOLDERS)} folders for evaluation for Freq: {FREQ_TO_TEST}, Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "# --- 2. Label Conversion Functions ---\n",
    "\n",
    "def pl_to_class(pl_tensor):\n",
    "    \"\"\"Converts a raw path loss value to a class index (0-30).\"\"\"\n",
    "    pl_rounded = torch.round(pl_tensor / 5.0) * 5.0\n",
    "    pl_clipped = torch.clamp(pl_rounded, 50.0, 200.0)\n",
    "    class_index = (pl_clipped - 50.0) / 5.0\n",
    "    return class_index.long()\n",
    "\n",
    "def class_to_pl(class_index_tensor):\n",
    "    \"\"\"Converts a class index (0-30) back to a path loss value (50-200).\"\"\"\n",
    "    # Note: Needs to be done with torch tensors to keep on-device\n",
    "    return (class_index_tensor.float() * 5.0) + 50.0\n",
    "\n",
    "# --- 3. Dataset Definition for Evaluation ---\n",
    "\n",
    "class EvaluationPointCloudDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.file_pairs = []\n",
    "        input_files = glob.glob(os.path.join(folder_path, \"*_for_train.npy\"))\n",
    "        \n",
    "        for input_path in input_files:\n",
    "            label_path = input_path.replace(\"_for_train.npy\", \"_path_loss.npy\")\n",
    "            if os.path.exists(label_path):\n",
    "                self.file_pairs.append((input_path, label_path))\n",
    "            else:\n",
    "                print(f\"Warning: Missing label for {input_path}. Skipping file.\")\n",
    "        if not self.file_pairs:\n",
    "            print(f\"Warning: No valid file pairs found in {folder_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label_original_float = np.load(label_path).astype(np.float32)\n",
    "        \n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_original_tensor = torch.from_numpy(label_original_float).squeeze()\n",
    "        \n",
    "        # Also return the class index for calculating rounded truth\n",
    "        label_class_tensor = pl_to_class(label_original_tensor)\n",
    "        \n",
    "        return pc_tensor, label_class_tensor, label_original_tensor\n",
    "\n",
    "# --- 4. Model Definitions (CLASSIFIER VERSION) ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1) # -> 512\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :]\n",
    "        feat_stream = x[:, 3:, :]\n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1)\n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.max(x, 2)[0] # -> (batch, 512)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, NUM_CLASSES) # -> 31 outputs\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x) # -> (batch, 31)\n",
    "        return x # Return logits\n",
    "\n",
    "# --- 5. Main Evaluation Script ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = PointNetPathLoss().to(device)\n",
    "    print(\"Model initialized (Classifier).\")\n",
    "\n",
    "    if not os.path.exists(MODEL_SAVE_PATH):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {MODEL_SAVE_PATH}.\")\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        print(f\"Successfully loaded model weights from {MODEL_SAVE_PATH}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading checkpoint: {e}. Ensure model definition matches checkpoint.\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions_rounded = []\n",
    "    all_labels_rounded = []\n",
    "    all_labels_original = [] # For the CSV\n",
    "\n",
    "    print(\"\\n--- Starting Evaluation ---\")\n",
    "    \n",
    "    for folder_name in TEST_DATA_FOLDERS:\n",
    "        print(f\"\\n▶ Processing folder: {folder_name}\")\n",
    "        folder_path = os.path.join(BASE_TRAIN_DIR, folder_name)\n",
    "        \n",
    "        test_dataset = EvaluationPointCloudDataset(folder_path=folder_path)\n",
    "        if len(test_dataset) == 0:\n",
    "            print(\"  -> No files found. Skipping folder.\")\n",
    "            continue\n",
    "            \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "            num_workers=NUM_WORKERS, pin_memory=(device.type == 'cuda')\n",
    "        )\n",
    "        \n",
    "        # Lists for this folder's results\n",
    "        folder_preds_list = []\n",
    "        folder_true_rounded_list = []\n",
    "        folder_true_original_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for pc_batch, label_class_batch, label_original_batch in tqdm(test_loader, desc=\"  Evaluating\"):\n",
    "                pc_batch = pc_batch.to(device)\n",
    "                label_class_batch = label_class_batch.to(device) # True class index\n",
    "                # label_original_batch stays on CPU, we just need it for the CSV\n",
    "                \n",
    "                out_logits = model(pc_batch) # -> (batch, 31)\n",
    "                \n",
    "                # Get predicted class index\n",
    "                _, predicted_class_idx = torch.max(out_logits, 1)\n",
    "                \n",
    "                # --- Convert indices back to dB values for RMSE and CSV ---\n",
    "                predicted_pl = class_to_pl(predicted_class_idx)\n",
    "                true_rounded_pl = class_to_pl(label_class_batch)\n",
    "                \n",
    "                # Store results\n",
    "                folder_preds_list.append(predicted_pl.cpu().numpy())\n",
    "                folder_true_rounded_list.append(true_rounded_pl.cpu().numpy())\n",
    "                folder_true_original_list.append(label_original_batch.cpu().numpy())\n",
    "        \n",
    "        # Concatenate all batch results\n",
    "        predictions = np.concatenate(folder_preds_list)\n",
    "        labels_rounded = np.concatenate(folder_true_rounded_list)\n",
    "        labels_original = np.concatenate(folder_true_original_list)\n",
    "        \n",
    "        all_predictions_rounded.append(predictions)\n",
    "        all_labels_rounded.append(labels_rounded)\n",
    "        \n",
    "        # Calculate folder-specific RMSE using ROUNDED values\n",
    "        folder_mse = np.mean((predictions - labels_rounded)**2)\n",
    "        folder_rmse = np.sqrt(folder_mse)\n",
    "        print(f\"  -> Folder RMSE (on rounded values): {folder_rmse:8.4f} dB\")\n",
    "        \n",
    "        # --- Create and Save CSV ---\n",
    "        match = re.match(r\"(\\w+)_processed__for_training_Tx_(\\d+)\", folder_name)\n",
    "        if not match:\n",
    "            print(f\"  -> ERROR: Could not parse folder name '{folder_name}'. Skipping CSV save.\")\n",
    "            continue\n",
    "            \n",
    "        freq = match.group(1)\n",
    "        tx_id = match.group(2)\n",
    "        \n",
    "        csv_filename = f\"test_{freq}_Tx_{tx_id}.csv\"\n",
    "        csv_save_path = os.path.join(TEST_SAVE_DIR, csv_filename)\n",
    "        \n",
    "        # Create DataFrame with the 3 requested columns\n",
    "        results_df = pd.DataFrame({\n",
    "            'predicted_pathloss': predictions,\n",
    "            'true_pathloss_rounded': labels_rounded,\n",
    "            'original_pathloss': labels_original\n",
    "        })\n",
    "        \n",
    "        results_df.to_csv(csv_save_path, index=False)\n",
    "        print(f\"  -> Results saved to: {csv_save_path}\")\n",
    "\n",
    "    # --- Calculate and Print Overall RMSE ---\n",
    "    if all_predictions_rounded:\n",
    "        overall_preds = np.concatenate(all_predictions_rounded)\n",
    "        overall_labels = np.concatenate(all_labels_rounded)\n",
    "        \n",
    "        overall_mse = np.mean((overall_preds - overall_labels)**2)\n",
    "        overall_rmse = np.sqrt(overall_mse)\n",
    "        \n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(f\"Overall Test RMSE (on rounded values): {overall_rmse:8.4f} dB\")\n",
    "    else:\n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(\"No test data was processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb46268e-da98-4f61-bbc9-f88afd4654d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 folders for evaluation for Freq: 7GHz, Tx IDs: [1, 18, 8, 19, 2]\n",
      "Using device: cuda\n",
      "Model initialized (Classifier).\n",
      "Successfully loaded model weights from pointnet_classifier_model_31class_7GHz.pth\n",
      "\n",
      "--- Starting Evaluation ---\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87127/3447722956.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
      "  Evaluating: 100%|██████████| 924/924 [00:21<00:00, 42.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  11.6939 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_7GHz_Tx_1.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 826/826 [00:19<00:00, 41.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  12.5777 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_7GHz_Tx_18.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 666/666 [00:15<00:00, 42.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  13.8717 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_7GHz_Tx_19.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 727/727 [00:17<00:00, 42.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  12.0951 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_7GHz_Tx_2.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 751/751 [00:17<00:00, 42.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  15.2090 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_7GHz_Tx_8.csv\n",
      "\n",
      "--- Evaluation Complete ---\n",
      "Overall Test RMSE (on rounded values):  13.0704 dB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import re \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "TEST_SAVE_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "os.makedirs(TEST_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- MODIFIED: Model Configuration ---\n",
    "MODEL_SAVE_PATH = \"pointnet_classifier_model_31class_7GHz.pth\" # Classifier model\n",
    "FEATURE_DIM = 512    # Must match the trained classifier\n",
    "NUM_CLASSES = 31     # Must match the trained classifier (50-200 in 5dB steps)\n",
    "\n",
    "# --- Evaluation Run Configuration ---\n",
    "FREQ_TO_TEST = \"7GHz\" # Run for only one frequency\n",
    "TX_SUBSET_SELECTED = [1, 18, 8, 19, 2]\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# List of ALL potential folders for the test set\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_1\", \"28GHz_processed__for_training_Tx_10\",\n",
    "    \"28GHz_processed__for_training_Tx_11\", \"28GHz_processed__for_training_Tx_13\",\n",
    "    \"28GHz_processed__for_training_Tx_15\", \"28GHz_processed__for_training_Tx_16\",\n",
    "    \"28GHz_processed__for_training_Tx_17\", \"28GHz_processed__for_training_Tx_18\",\n",
    "    \"28GHz_processed__for_training_Tx_19\", \"28GHz_processed__for_training_Tx_2\",\n",
    "    \"28GHz_processed__for_training_Tx_3\", \"28GHz_processed__for_training_Tx_4\",\n",
    "    \"28GHz_processed__for_training_Tx_6\", \"28GHz_processed__for_training_Tx_7\",\n",
    "    \"28GHz_processed__for_training_Tx_8\",\n",
    "    \"7GHz_processed__for_training_Tx_1\", \"7GHz_processed__for_training_Tx_10\",\n",
    "    \"7GHz_processed__for_training_Tx_11\", \"7GHz_processed__for_training_Tx_13\",\n",
    "    \"7GHz_processed__for_training_Tx_15\", \"7GHz_processed__for_training_Tx_16\",\n",
    "    \"7Gzz_processed__for_training_Tx_17\", \"7GHz_processed__for_training_Tx_18\",\n",
    "    \"7GHz_processed__for_training_Tx_19\", \"7GHz_processed__for_training_Tx_2\",\n",
    "    \"7GHz_processed__for_training_Tx_3\", \"7GHz_processed__for_training_Tx_4\",\n",
    "    \"7GHz_processed__for_training_Tx_6\", \"7GHz_processed__for_training_Tx_7\",\n",
    "    \"7GHz_processed__for_training_Tx_8\",\n",
    "    \"800MHz_processed__for_training_Tx_1\", \"800MHz_processed__for_training_Tx_10\",\n",
    "    \"800MHz_processed__for_training_Tx_11\", \"800MHz_processed__for_training_Tx_13\",\n",
    "    \"800MHz_processed__for_training_Tx_15\", \"800MHz_processed__for_training_Tx_16\",\n",
    "    \"800MHz_processed__for_training_Tx_17\", \"800MHz_processed__for_training_Tx_18\",\n",
    "    \"800MHz_processed__for_training_Tx_19\", \"800MHz_processed__for_training_Tx_2\",\n",
    "    \"800MHz_processed__for_training_Tx_3\", \"800MHz_processed__for_training_Tx_4\",\n",
    "    \"800MHz_processed__for_training_Tx_6\", \"800MHz_processed__for_training_Tx_7\",\n",
    "    \"800MHz_processed__for_training_Tx_8\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED AND FREQ_TO_TEST ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "TEST_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str and folder.startswith(FREQ_TO_TEST)\n",
    "]\n",
    "if not TEST_DATA_FOLDERS:\n",
    "    raise ValueError(f\"No folders found for Tx IDs {TX_SUBSET_SELECTED} and Freq {FREQ_TO_TEST}.\")\n",
    "print(f\"Found {len(TEST_DATA_FOLDERS)} folders for evaluation for Freq: {FREQ_TO_TEST}, Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "# --- 2. Label Conversion Functions ---\n",
    "\n",
    "def pl_to_class(pl_tensor):\n",
    "    \"\"\"Converts a raw path loss value to a class index (0-30).\"\"\"\n",
    "    pl_rounded = torch.round(pl_tensor / 5.0) * 5.0\n",
    "    pl_clipped = torch.clamp(pl_rounded, 50.0, 200.0)\n",
    "    class_index = (pl_clipped - 50.0) / 5.0\n",
    "    return class_index.long()\n",
    "\n",
    "def class_to_pl(class_index_tensor):\n",
    "    \"\"\"Converts a class index (0-30) back to a path loss value (50-200).\"\"\"\n",
    "    # Note: Needs to be done with torch tensors to keep on-device\n",
    "    return (class_index_tensor.float() * 5.0) + 50.0\n",
    "\n",
    "# --- 3. Dataset Definition for Evaluation ---\n",
    "\n",
    "class EvaluationPointCloudDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.file_pairs = []\n",
    "        input_files = glob.glob(os.path.join(folder_path, \"*_for_train.npy\"))\n",
    "        \n",
    "        for input_path in input_files:\n",
    "            label_path = input_path.replace(\"_for_train.npy\", \"_path_loss.npy\")\n",
    "            if os.path.exists(label_path):\n",
    "                self.file_pairs.append((input_path, label_path))\n",
    "            else:\n",
    "                print(f\"Warning: Missing label for {input_path}. Skipping file.\")\n",
    "        if not self.file_pairs:\n",
    "            print(f\"Warning: No valid file pairs found in {folder_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label_original_float = np.load(label_path).astype(np.float32)\n",
    "        \n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_original_tensor = torch.from_numpy(label_original_float).squeeze()\n",
    "        \n",
    "        # Also return the class index for calculating rounded truth\n",
    "        label_class_tensor = pl_to_class(label_original_tensor)\n",
    "        \n",
    "        return pc_tensor, label_class_tensor, label_original_tensor\n",
    "\n",
    "# --- 4. Model Definitions (CLASSIFIER VERSION) ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1) # -> 512\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :]\n",
    "        feat_stream = x[:, 3:, :]\n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1)\n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.max(x, 2)[0] # -> (batch, 512)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, NUM_CLASSES) # -> 31 outputs\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x) # -> (batch, 31)\n",
    "        return x # Return logits\n",
    "\n",
    "# --- 5. Main Evaluation Script ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = PointNetPathLoss().to(device)\n",
    "    print(\"Model initialized (Classifier).\")\n",
    "\n",
    "    if not os.path.exists(MODEL_SAVE_PATH):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {MODEL_SAVE_PATH}.\")\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        print(f\"Successfully loaded model weights from {MODEL_SAVE_PATH}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading checkpoint: {e}. Ensure model definition matches checkpoint.\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions_rounded = []\n",
    "    all_labels_rounded = []\n",
    "    all_labels_original = [] # For the CSV\n",
    "\n",
    "    print(\"\\n--- Starting Evaluation ---\")\n",
    "    \n",
    "    for folder_name in TEST_DATA_FOLDERS:\n",
    "        print(f\"\\n▶ Processing folder: {folder_name}\")\n",
    "        folder_path = os.path.join(BASE_TRAIN_DIR, folder_name)\n",
    "        \n",
    "        test_dataset = EvaluationPointCloudDataset(folder_path=folder_path)\n",
    "        if len(test_dataset) == 0:\n",
    "            print(\"  -> No files found. Skipping folder.\")\n",
    "            continue\n",
    "            \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "            num_workers=NUM_WORKERS, pin_memory=(device.type == 'cuda')\n",
    "        )\n",
    "        \n",
    "        # Lists for this folder's results\n",
    "        folder_preds_list = []\n",
    "        folder_true_rounded_list = []\n",
    "        folder_true_original_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for pc_batch, label_class_batch, label_original_batch in tqdm(test_loader, desc=\"  Evaluating\"):\n",
    "                pc_batch = pc_batch.to(device)\n",
    "                label_class_batch = label_class_batch.to(device) # True class index\n",
    "                # label_original_batch stays on CPU, we just need it for the CSV\n",
    "                \n",
    "                out_logits = model(pc_batch) # -> (batch, 31)\n",
    "                \n",
    "                # Get predicted class index\n",
    "                _, predicted_class_idx = torch.max(out_logits, 1)\n",
    "                \n",
    "                # --- Convert indices back to dB values for RMSE and CSV ---\n",
    "                predicted_pl = class_to_pl(predicted_class_idx)\n",
    "                true_rounded_pl = class_to_pl(label_class_batch)\n",
    "                \n",
    "                # Store results\n",
    "                folder_preds_list.append(predicted_pl.cpu().numpy())\n",
    "                folder_true_rounded_list.append(true_rounded_pl.cpu().numpy())\n",
    "                folder_true_original_list.append(label_original_batch.cpu().numpy())\n",
    "        \n",
    "        # Concatenate all batch results\n",
    "        predictions = np.concatenate(folder_preds_list)\n",
    "        labels_rounded = np.concatenate(folder_true_rounded_list)\n",
    "        labels_original = np.concatenate(folder_true_original_list)\n",
    "        \n",
    "        all_predictions_rounded.append(predictions)\n",
    "        all_labels_rounded.append(labels_rounded)\n",
    "        \n",
    "        # Calculate folder-specific RMSE using ROUNDED values\n",
    "        folder_mse = np.mean((predictions - labels_rounded)**2)\n",
    "        folder_rmse = np.sqrt(folder_mse)\n",
    "        print(f\"  -> Folder RMSE (on rounded values): {folder_rmse:8.4f} dB\")\n",
    "        \n",
    "        # --- Create and Save CSV ---\n",
    "        match = re.match(r\"(\\w+)_processed__for_training_Tx_(\\d+)\", folder_name)\n",
    "        if not match:\n",
    "            print(f\"  -> ERROR: Could not parse folder name '{folder_name}'. Skipping CSV save.\")\n",
    "            continue\n",
    "            \n",
    "        freq = match.group(1)\n",
    "        tx_id = match.group(2)\n",
    "        \n",
    "        csv_filename = f\"test_{freq}_Tx_{tx_id}.csv\"\n",
    "        csv_save_path = os.path.join(TEST_SAVE_DIR, csv_filename)\n",
    "        \n",
    "        # Create DataFrame with the 3 requested columns\n",
    "        results_df = pd.DataFrame({\n",
    "            'predicted_pathloss': predictions,\n",
    "            'true_pathloss_rounded': labels_rounded,\n",
    "            'original_pathloss': labels_original\n",
    "        })\n",
    "        \n",
    "        results_df.to_csv(csv_save_path, index=False)\n",
    "        print(f\"  -> Results saved to: {csv_save_path}\")\n",
    "\n",
    "    # --- Calculate and Print Overall RMSE ---\n",
    "    if all_predictions_rounded:\n",
    "        overall_preds = np.concatenate(all_predictions_rounded)\n",
    "        overall_labels = np.concatenate(all_labels_rounded)\n",
    "        \n",
    "        overall_mse = np.mean((overall_preds - overall_labels)**2)\n",
    "        overall_rmse = np.sqrt(overall_mse)\n",
    "        \n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(f\"Overall Test RMSE (on rounded values): {overall_rmse:8.4f} dB\")\n",
    "    else:\n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(\"No test data was processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a94cb25-e87e-4208-9ba2-3426a2f59cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 folders for evaluation for Freq: 7GHz, Tx IDs: [5, 9, 12, 14, 20]\n",
      "Using device: cuda\n",
      "Model initialized (Classifier).\n",
      "Successfully loaded model weights from pointnet_classifier_model_31class_7GHz.pth\n",
      "\n",
      "--- Starting Evaluation ---\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87127/1476253964.py:173: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
      "  Evaluating: 100%|██████████| 730/730 [00:12<00:00, 58.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  19.7999 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_5.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 762/762 [00:13<00:00, 58.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  19.8179 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_9.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 751/751 [00:12<00:00, 58.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  25.7740 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_12.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 718/718 [00:12<00:00, 58.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  18.8268 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_14.csv\n",
      "\n",
      "▶ Processing folder: 7GHz_processed__for_training_Tx_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 696/696 [00:12<00:00, 56.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  19.2944 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_7GHz_Tx_20.csv\n",
      "\n",
      "--- Evaluation Complete ---\n",
      "Overall Test RMSE (on rounded values):  20.9038 dB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import re \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/test\"\n",
    "TEST_SAVE_DIR = \"/home/mkrishne/PL_competition/extracted_regions/test\"\n",
    "os.makedirs(TEST_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- MODIFIED: Model Configuration ---\n",
    "MODEL_SAVE_PATH = \"pointnet_classifier_model_31class_7GHz.pth\" # Classifier model\n",
    "FEATURE_DIM = 512    # Must match the trained classifier\n",
    "NUM_CLASSES = 31     # Must match the trained classifier (50-200 in 5dB steps)\n",
    "\n",
    "# --- Evaluation Run Configuration ---\n",
    "FREQ_TO_TEST = \"7GHz\" # Run for only one frequency\n",
    "TX_SUBSET_SELECTED = [5,9,12,14,20]\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# List of ALL potential folders for the test set\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_5\", \"28GHz_processed__for_training_Tx_9\",\n",
    "    \"28GHz_processed__for_training_Tx_12\", \"28GHz_processed__for_training_Tx_14\",\n",
    "    \"28GHz_processed__for_training_Tx_20\",\n",
    "    \"7GHz_processed__for_training_Tx_5\", \"7GHz_processed__for_training_Tx_9\",\n",
    "    \"7GHz_processed__for_training_Tx_12\", \"7GHz_processed__for_training_Tx_14\",\n",
    "    \"7GHz_processed__for_training_Tx_20\",\n",
    "    \"800MHz_processed__for_training_Tx_5\", \"800MHz_processed__for_training_Tx_9\",\n",
    "    \"800MHz_processed__for_training_Tx_12\", \"800MHz_processed__for_training_Tx_14\",\n",
    "    \"800MHz_processed__for_training_Tx_20\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED AND FREQ_TO_TEST ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "TEST_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str and folder.startswith(FREQ_TO_TEST)\n",
    "]\n",
    "if not TEST_DATA_FOLDERS:\n",
    "    raise ValueError(f\"No folders found for Tx IDs {TX_SUBSET_SELECTED} and Freq {FREQ_TO_TEST}.\")\n",
    "print(f\"Found {len(TEST_DATA_FOLDERS)} folders for evaluation for Freq: {FREQ_TO_TEST}, Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "# --- 2. Label Conversion Functions ---\n",
    "\n",
    "def pl_to_class(pl_tensor):\n",
    "    \"\"\"Converts a raw path loss value to a class index (0-30).\"\"\"\n",
    "    pl_rounded = torch.round(pl_tensor / 5.0) * 5.0\n",
    "    pl_clipped = torch.clamp(pl_rounded, 50.0, 200.0)\n",
    "    class_index = (pl_clipped - 50.0) / 5.0\n",
    "    return class_index.long()\n",
    "\n",
    "def class_to_pl(class_index_tensor):\n",
    "    \"\"\"Converts a class index (0-30) back to a path loss value (50-200).\"\"\"\n",
    "    # Note: Needs to be done with torch tensors to keep on-device\n",
    "    return (class_index_tensor.float() * 5.0) + 50.0\n",
    "\n",
    "# --- 3. Dataset Definition for Evaluation ---\n",
    "\n",
    "class EvaluationPointCloudDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.file_pairs = []\n",
    "        input_files = glob.glob(os.path.join(folder_path, \"*_for_train.npy\"))\n",
    "        \n",
    "        for input_path in input_files:\n",
    "            label_path = input_path.replace(\"_for_train.npy\", \"_path_loss.npy\")\n",
    "            if os.path.exists(label_path):\n",
    "                self.file_pairs.append((input_path, label_path))\n",
    "            else:\n",
    "                print(f\"Warning: Missing label for {input_path}. Skipping file.\")\n",
    "        if not self.file_pairs:\n",
    "            print(f\"Warning: No valid file pairs found in {folder_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label_original_float = np.load(label_path).astype(np.float32)\n",
    "        \n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_original_tensor = torch.from_numpy(label_original_float).squeeze()\n",
    "        \n",
    "        # Also return the class index for calculating rounded truth\n",
    "        label_class_tensor = pl_to_class(label_original_tensor)\n",
    "        \n",
    "        return pc_tensor, label_class_tensor, label_original_tensor\n",
    "\n",
    "# --- 4. Model Definitions (CLASSIFIER VERSION) ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1) # -> 512\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :]\n",
    "        feat_stream = x[:, 3:, :]\n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1)\n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.max(x, 2)[0] # -> (batch, 512)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, NUM_CLASSES) # -> 31 outputs\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x) # -> (batch, 31)\n",
    "        return x # Return logits\n",
    "\n",
    "# --- 5. Main Evaluation Script ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = PointNetPathLoss().to(device)\n",
    "    print(\"Model initialized (Classifier).\")\n",
    "\n",
    "    if not os.path.exists(MODEL_SAVE_PATH):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {MODEL_SAVE_PATH}.\")\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        print(f\"Successfully loaded model weights from {MODEL_SAVE_PATH}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading checkpoint: {e}. Ensure model definition matches checkpoint.\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions_rounded = []\n",
    "    all_labels_rounded = []\n",
    "    all_labels_original = [] # For the CSV\n",
    "\n",
    "    print(\"\\n--- Starting Evaluation ---\")\n",
    "    \n",
    "    for folder_name in TEST_DATA_FOLDERS:\n",
    "        print(f\"\\n▶ Processing folder: {folder_name}\")\n",
    "        folder_path = os.path.join(BASE_TRAIN_DIR, folder_name)\n",
    "        \n",
    "        test_dataset = EvaluationPointCloudDataset(folder_path=folder_path)\n",
    "        if len(test_dataset) == 0:\n",
    "            print(\"  -> No files found. Skipping folder.\")\n",
    "            continue\n",
    "            \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "            num_workers=NUM_WORKERS, pin_memory=(device.type == 'cuda')\n",
    "        )\n",
    "        \n",
    "        # Lists for this folder's results\n",
    "        folder_preds_list = []\n",
    "        folder_true_rounded_list = []\n",
    "        folder_true_original_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for pc_batch, label_class_batch, label_original_batch in tqdm(test_loader, desc=\"  Evaluating\"):\n",
    "                pc_batch = pc_batch.to(device)\n",
    "                label_class_batch = label_class_batch.to(device) # True class index\n",
    "                # label_original_batch stays on CPU, we just need it for the CSV\n",
    "                \n",
    "                out_logits = model(pc_batch) # -> (batch, 31)\n",
    "                \n",
    "                # Get predicted class index\n",
    "                _, predicted_class_idx = torch.max(out_logits, 1)\n",
    "                \n",
    "                # --- Convert indices back to dB values for RMSE and CSV ---\n",
    "                predicted_pl = class_to_pl(predicted_class_idx)\n",
    "                true_rounded_pl = class_to_pl(label_class_batch)\n",
    "                \n",
    "                # Store results\n",
    "                folder_preds_list.append(predicted_pl.cpu().numpy())\n",
    "                folder_true_rounded_list.append(true_rounded_pl.cpu().numpy())\n",
    "                folder_true_original_list.append(label_original_batch.cpu().numpy())\n",
    "        \n",
    "        # Concatenate all batch results\n",
    "        predictions = np.concatenate(folder_preds_list)\n",
    "        labels_rounded = np.concatenate(folder_true_rounded_list)\n",
    "        labels_original = np.concatenate(folder_true_original_list)\n",
    "        \n",
    "        all_predictions_rounded.append(predictions)\n",
    "        all_labels_rounded.append(labels_rounded)\n",
    "        \n",
    "        # Calculate folder-specific RMSE using ROUNDED values\n",
    "        folder_mse = np.mean((predictions - labels_rounded)**2)\n",
    "        folder_rmse = np.sqrt(folder_mse)\n",
    "        print(f\"  -> Folder RMSE (on rounded values): {folder_rmse:8.4f} dB\")\n",
    "        \n",
    "        # --- Create and Save CSV ---\n",
    "        match = re.match(r\"(\\w+)_processed__for_training_Tx_(\\d+)\", folder_name)\n",
    "        if not match:\n",
    "            print(f\"  -> ERROR: Could not parse folder name '{folder_name}'. Skipping CSV save.\")\n",
    "            continue\n",
    "            \n",
    "        freq = match.group(1)\n",
    "        tx_id = match.group(2)\n",
    "        \n",
    "        csv_filename = f\"test_{freq}_Tx_{tx_id}.csv\"\n",
    "        csv_save_path = os.path.join(TEST_SAVE_DIR, csv_filename)\n",
    "        \n",
    "        # Create DataFrame with the 3 requested columns\n",
    "        results_df = pd.DataFrame({\n",
    "            'predicted_pathloss': predictions,\n",
    "            'true_pathloss_rounded': labels_rounded,\n",
    "            'original_pathloss': labels_original\n",
    "        })\n",
    "        \n",
    "        results_df.to_csv(csv_save_path, index=False)\n",
    "        print(f\"  -> Results saved to: {csv_save_path}\")\n",
    "\n",
    "    # --- Calculate and Print Overall RMSE ---\n",
    "    if all_predictions_rounded:\n",
    "        overall_preds = np.concatenate(all_predictions_rounded)\n",
    "        overall_labels = np.concatenate(all_labels_rounded)\n",
    "        \n",
    "        overall_mse = np.mean((overall_preds - overall_labels)**2)\n",
    "        overall_rmse = np.sqrt(overall_mse)\n",
    "        \n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(f\"Overall Test RMSE (on rounded values): {overall_rmse:8.4f} dB\")\n",
    "    else:\n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(\"No test data was processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d4bf62c-e386-490e-9aee-42e75ea416ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87127/2710928866.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 folders for evaluation for Freq: 28GHz, Tx IDs: [1, 18, 8, 19, 2]\n",
      "Using device: cuda\n",
      "Model initialized (Classifier).\n",
      "Successfully loaded model weights from pointnet_classifier_model_31class_28GHz.pth\n",
      "\n",
      "--- Starting Evaluation ---\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 922/922 [00:21<00:00, 42.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  14.0091 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_28GHz_Tx_1.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 824/824 [00:19<00:00, 42.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  14.4989 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_28GHz_Tx_18.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 652/652 [00:15<00:00, 42.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  15.5435 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_28GHz_Tx_19.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 721/721 [00:16<00:00, 42.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  14.1761 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_28GHz_Tx_2.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 732/732 [00:17<00:00, 42.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  16.0752 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/train/test_28GHz_Tx_8.csv\n",
      "\n",
      "--- Evaluation Complete ---\n",
      "Overall Test RMSE (on rounded values):  14.8195 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import re \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "TEST_SAVE_DIR = \"/home/mkrishne/PL_competition/extracted_regions/train\"\n",
    "os.makedirs(TEST_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- MODIFIED: Model Configuration ---\n",
    "MODEL_SAVE_PATH = \"pointnet_classifier_model_31class_28GHz.pth\" # Classifier model\n",
    "FEATURE_DIM = 512    # Must match the trained classifier\n",
    "NUM_CLASSES = 31     # Must match the trained classifier (50-200 in 5dB steps)\n",
    "\n",
    "# --- Evaluation Run Configuration ---\n",
    "FREQ_TO_TEST = \"28GHz\" # Run for only one frequency\n",
    "TX_SUBSET_SELECTED = [1, 18, 8, 19, 2]\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# List of ALL potential folders for the test set\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_1\", \"28GHz_processed__for_training_Tx_10\",\n",
    "    \"28GHz_processed__for_training_Tx_11\", \"28GHz_processed__for_training_Tx_13\",\n",
    "    \"28GHz_processed__for_training_Tx_15\", \"28GHz_processed__for_training_Tx_16\",\n",
    "    \"28GHz_processed__for_training_Tx_17\", \"28GHz_processed__for_training_Tx_18\",\n",
    "    \"28GHz_processed__for_training_Tx_19\", \"28GHz_processed__for_training_Tx_2\",\n",
    "    \"28GHz_processed__for_training_Tx_3\", \"28GHz_processed__for_training_Tx_4\",\n",
    "    \"28GHz_processed__for_training_Tx_6\", \"28GHz_processed__for_training_Tx_7\",\n",
    "    \"28GHz_processed__for_training_Tx_8\",\n",
    "    \"7GHz_processed__for_training_Tx_1\", \"7GHz_processed__for_training_Tx_10\",\n",
    "    \"7GHz_processed__for_training_Tx_11\", \"7GHz_processed__for_training_Tx_13\",\n",
    "    \"7GHz_processed__for_training_Tx_15\", \"7GHz_processed__for_training_Tx_16\",\n",
    "    \"7Gzz_processed__for_training_Tx_17\", \"7GHz_processed__for_training_Tx_18\",\n",
    "    \"7GHz_processed__for_training_Tx_19\", \"7GHz_processed__for_training_Tx_2\",\n",
    "    \"7GHz_processed__for_training_Tx_3\", \"7GHz_processed__for_training_Tx_4\",\n",
    "    \"7GHz_processed__for_training_Tx_6\", \"7GHz_processed__for_training_Tx_7\",\n",
    "    \"7GHz_processed__for_training_Tx_8\",\n",
    "    \"800MHz_processed__for_training_Tx_1\", \"800MHz_processed__for_training_Tx_10\",\n",
    "    \"800MHz_processed__for_training_Tx_11\", \"800MHz_processed__for_training_Tx_13\",\n",
    "    \"800MHz_processed__for_training_Tx_15\", \"800MHz_processed__for_training_Tx_16\",\n",
    "    \"800MHz_processed__for_training_Tx_17\", \"800MHz_processed__for_training_Tx_18\",\n",
    "    \"800MHz_processed__for_training_Tx_19\", \"800MHz_processed__for_training_Tx_2\",\n",
    "    \"800MHz_processed__for_training_Tx_3\", \"800MHz_processed__for_training_Tx_4\",\n",
    "    \"800MHz_processed__for_training_Tx_6\", \"800MHz_processed__for_training_Tx_7\",\n",
    "    \"800MHz_processed__for_training_Tx_8\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED AND FREQ_TO_TEST ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "TEST_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str and folder.startswith(FREQ_TO_TEST)\n",
    "]\n",
    "if not TEST_DATA_FOLDERS:\n",
    "    raise ValueError(f\"No folders found for Tx IDs {TX_SUBSET_SELECTED} and Freq {FREQ_TO_TEST}.\")\n",
    "print(f\"Found {len(TEST_DATA_FOLDERS)} folders for evaluation for Freq: {FREQ_TO_TEST}, Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "# --- 2. Label Conversion Functions ---\n",
    "\n",
    "def pl_to_class(pl_tensor):\n",
    "    \"\"\"Converts a raw path loss value to a class index (0-30).\"\"\"\n",
    "    pl_rounded = torch.round(pl_tensor / 5.0) * 5.0\n",
    "    pl_clipped = torch.clamp(pl_rounded, 50.0, 200.0)\n",
    "    class_index = (pl_clipped - 50.0) / 5.0\n",
    "    return class_index.long()\n",
    "\n",
    "def class_to_pl(class_index_tensor):\n",
    "    \"\"\"Converts a class index (0-30) back to a path loss value (50-200).\"\"\"\n",
    "    # Note: Needs to be done with torch tensors to keep on-device\n",
    "    return (class_index_tensor.float() * 5.0) + 50.0\n",
    "\n",
    "# --- 3. Dataset Definition for Evaluation ---\n",
    "\n",
    "class EvaluationPointCloudDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.file_pairs = []\n",
    "        input_files = glob.glob(os.path.join(folder_path, \"*_for_train.npy\"))\n",
    "        \n",
    "        for input_path in input_files:\n",
    "            label_path = input_path.replace(\"_for_train.npy\", \"_path_loss.npy\")\n",
    "            if os.path.exists(label_path):\n",
    "                self.file_pairs.append((input_path, label_path))\n",
    "            else:\n",
    "                print(f\"Warning: Missing label for {input_path}. Skipping file.\")\n",
    "        if not self.file_pairs:\n",
    "            print(f\"Warning: No valid file pairs found in {folder_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label_original_float = np.load(label_path).astype(np.float32)\n",
    "        \n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_original_tensor = torch.from_numpy(label_original_float).squeeze()\n",
    "        \n",
    "        # Also return the class index for calculating rounded truth\n",
    "        label_class_tensor = pl_to_class(label_original_tensor)\n",
    "        \n",
    "        return pc_tensor, label_class_tensor, label_original_tensor\n",
    "\n",
    "# --- 4. Model Definitions (CLASSIFIER VERSION) ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1) # -> 512\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :]\n",
    "        feat_stream = x[:, 3:, :]\n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1)\n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.max(x, 2)[0] # -> (batch, 512)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, NUM_CLASSES) # -> 31 outputs\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x) # -> (batch, 31)\n",
    "        return x # Return logits\n",
    "\n",
    "# --- 5. Main Evaluation Script ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = PointNetPathLoss().to(device)\n",
    "    print(\"Model initialized (Classifier).\")\n",
    "\n",
    "    if not os.path.exists(MODEL_SAVE_PATH):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {MODEL_SAVE_PATH}.\")\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        print(f\"Successfully loaded model weights from {MODEL_SAVE_PATH}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading checkpoint: {e}. Ensure model definition matches checkpoint.\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions_rounded = []\n",
    "    all_labels_rounded = []\n",
    "    all_labels_original = [] # For the CSV\n",
    "\n",
    "    print(\"\\n--- Starting Evaluation ---\")\n",
    "    \n",
    "    for folder_name in TEST_DATA_FOLDERS:\n",
    "        print(f\"\\n▶ Processing folder: {folder_name}\")\n",
    "        folder_path = os.path.join(BASE_TRAIN_DIR, folder_name)\n",
    "        \n",
    "        test_dataset = EvaluationPointCloudDataset(folder_path=folder_path)\n",
    "        if len(test_dataset) == 0:\n",
    "            print(\"  -> No files found. Skipping folder.\")\n",
    "            continue\n",
    "            \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "            num_workers=NUM_WORKERS, pin_memory=(device.type == 'cuda')\n",
    "        )\n",
    "        \n",
    "        # Lists for this folder's results\n",
    "        folder_preds_list = []\n",
    "        folder_true_rounded_list = []\n",
    "        folder_true_original_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for pc_batch, label_class_batch, label_original_batch in tqdm(test_loader, desc=\"  Evaluating\"):\n",
    "                pc_batch = pc_batch.to(device)\n",
    "                label_class_batch = label_class_batch.to(device) # True class index\n",
    "                # label_original_batch stays on CPU, we just need it for the CSV\n",
    "                \n",
    "                out_logits = model(pc_batch) # -> (batch, 31)\n",
    "                \n",
    "                # Get predicted class index\n",
    "                _, predicted_class_idx = torch.max(out_logits, 1)\n",
    "                \n",
    "                # --- Convert indices back to dB values for RMSE and CSV ---\n",
    "                predicted_pl = class_to_pl(predicted_class_idx)\n",
    "                true_rounded_pl = class_to_pl(label_class_batch)\n",
    "                \n",
    "                # Store results\n",
    "                folder_preds_list.append(predicted_pl.cpu().numpy())\n",
    "                folder_true_rounded_list.append(true_rounded_pl.cpu().numpy())\n",
    "                folder_true_original_list.append(label_original_batch.cpu().numpy())\n",
    "        \n",
    "        # Concatenate all batch results\n",
    "        predictions = np.concatenate(folder_preds_list)\n",
    "        labels_rounded = np.concatenate(folder_true_rounded_list)\n",
    "        labels_original = np.concatenate(folder_true_original_list)\n",
    "        \n",
    "        all_predictions_rounded.append(predictions)\n",
    "        all_labels_rounded.append(labels_rounded)\n",
    "        \n",
    "        # Calculate folder-specific RMSE using ROUNDED values\n",
    "        folder_mse = np.mean((predictions - labels_rounded)**2)\n",
    "        folder_rmse = np.sqrt(folder_mse)\n",
    "        print(f\"  -> Folder RMSE (on rounded values): {folder_rmse:8.4f} dB\")\n",
    "        \n",
    "        # --- Create and Save CSV ---\n",
    "        match = re.match(r\"(\\w+)_processed__for_training_Tx_(\\d+)\", folder_name)\n",
    "        if not match:\n",
    "            print(f\"  -> ERROR: Could not parse folder name '{folder_name}'. Skipping CSV save.\")\n",
    "            continue\n",
    "            \n",
    "        freq = match.group(1)\n",
    "        tx_id = match.group(2)\n",
    "        \n",
    "        csv_filename = f\"test_{freq}_Tx_{tx_id}.csv\"\n",
    "        csv_save_path = os.path.join(TEST_SAVE_DIR, csv_filename)\n",
    "        \n",
    "        # Create DataFrame with the 3 requested columns\n",
    "        results_df = pd.DataFrame({\n",
    "            'predicted_pathloss': predictions,\n",
    "            'true_pathloss_rounded': labels_rounded,\n",
    "            'original_pathloss': labels_original\n",
    "        })\n",
    "        \n",
    "        results_df.to_csv(csv_save_path, index=False)\n",
    "        print(f\"  -> Results saved to: {csv_save_path}\")\n",
    "\n",
    "    # --- Calculate and Print Overall RMSE ---\n",
    "    if all_predictions_rounded:\n",
    "        overall_preds = np.concatenate(all_predictions_rounded)\n",
    "        overall_labels = np.concatenate(all_labels_rounded)\n",
    "        \n",
    "        overall_mse = np.mean((overall_preds - overall_labels)**2)\n",
    "        overall_rmse = np.sqrt(overall_mse)\n",
    "        \n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(f\"Overall Test RMSE (on rounded values): {overall_rmse:8.4f} dB\")\n",
    "    else:\n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(\"No test data was processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "343e4522-d88c-47db-a530-372233f4ebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 folders for evaluation for Freq: 28GHz, Tx IDs: [5, 9, 12, 14, 20]\n",
      "Using device: cuda\n",
      "Model initialized (Classifier).\n",
      "Successfully loaded model weights from pointnet_classifier_model_31class_28GHz.pth\n",
      "\n",
      "--- Starting Evaluation ---\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87127/2420061968.py:173: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
      "  Evaluating: 100%|██████████| 702/702 [00:12<00:00, 56.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  22.8715 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_5.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 734/734 [00:12<00:00, 56.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  20.7851 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_9.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 729/729 [00:12<00:00, 56.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  28.6119 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_12.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 701/701 [00:12<00:00, 57.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  18.3972 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_14.csv\n",
      "\n",
      "▶ Processing folder: 28GHz_processed__for_training_Tx_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Evaluating: 100%|██████████| 685/685 [00:11<00:00, 57.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Folder RMSE (on rounded values):  20.0386 dB\n",
      "  -> Results saved to: /home/mkrishne/PL_competition/extracted_regions/test/test_28GHz_Tx_20.csv\n",
      "\n",
      "--- Evaluation Complete ---\n",
      "Overall Test RMSE (on rounded values):  22.4732 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import re \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "BASE_TRAIN_DIR = \"/home/mkrishne/PL_competition/extracted_regions/test\"\n",
    "TEST_SAVE_DIR = \"/home/mkrishne/PL_competition/extracted_regions/test\"\n",
    "os.makedirs(TEST_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- MODIFIED: Model Configuration ---\n",
    "MODEL_SAVE_PATH = \"pointnet_classifier_model_31class_28GHz.pth\" # Classifier model\n",
    "FEATURE_DIM = 512    # Must match the trained classifier\n",
    "NUM_CLASSES = 31     # Must match the trained classifier (50-200 in 5dB steps)\n",
    "\n",
    "# --- Evaluation Run Configuration ---\n",
    "FREQ_TO_TEST = \"28GHz\" # Run for only one frequency\n",
    "TX_SUBSET_SELECTED = [5,9,12,14,20]\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# List of ALL potential folders for the test set\n",
    "ALL_DATA_FOLDERS_POTENTIAL = [\n",
    "    \"28GHz_processed__for_training_Tx_5\", \"28GHz_processed__for_training_Tx_9\",\n",
    "    \"28GHz_processed__for_training_Tx_12\", \"28GHz_processed__for_training_Tx_14\",\n",
    "    \"28GHz_processed__for_training_Tx_20\",\n",
    "    \"7GHz_processed__for_training_Tx_5\", \"7GHz_processed__for_training_Tx_9\",\n",
    "    \"7GHz_processed__for_training_Tx_12\", \"7GHz_processed__for_training_Tx_14\",\n",
    "    \"7GHz_processed__for_training_Tx_20\",\n",
    "    \"800MHz_processed__for_training_Tx_5\", \"800MHz_processed__for_training_Tx_9\",\n",
    "    \"800MHz_processed__for_training_Tx_12\", \"800MHz_processed__for_training_Tx_14\",\n",
    "    \"800MHz_processed__for_training_Tx_20\"\n",
    "]\n",
    "\n",
    "# --- Filter folders based on TX_SUBSET_SELECTED AND FREQ_TO_TEST ---\n",
    "tx_subset_str = {str(tx_id) for tx_id in TX_SUBSET_SELECTED}\n",
    "TEST_DATA_FOLDERS = [\n",
    "    folder for folder in ALL_DATA_FOLDERS_POTENTIAL\n",
    "    if folder.split('_')[-1] in tx_subset_str and folder.startswith(FREQ_TO_TEST)\n",
    "]\n",
    "if not TEST_DATA_FOLDERS:\n",
    "    raise ValueError(f\"No folders found for Tx IDs {TX_SUBSET_SELECTED} and Freq {FREQ_TO_TEST}.\")\n",
    "print(f\"Found {len(TEST_DATA_FOLDERS)} folders for evaluation for Freq: {FREQ_TO_TEST}, Tx IDs: {TX_SUBSET_SELECTED}\")\n",
    "# -------------------------------------------------\n",
    "\n",
    "# --- 2. Label Conversion Functions ---\n",
    "\n",
    "def pl_to_class(pl_tensor):\n",
    "    \"\"\"Converts a raw path loss value to a class index (0-30).\"\"\"\n",
    "    pl_rounded = torch.round(pl_tensor / 5.0) * 5.0\n",
    "    pl_clipped = torch.clamp(pl_rounded, 50.0, 200.0)\n",
    "    class_index = (pl_clipped - 50.0) / 5.0\n",
    "    return class_index.long()\n",
    "\n",
    "def class_to_pl(class_index_tensor):\n",
    "    \"\"\"Converts a class index (0-30) back to a path loss value (50-200).\"\"\"\n",
    "    # Note: Needs to be done with torch tensors to keep on-device\n",
    "    return (class_index_tensor.float() * 5.0) + 50.0\n",
    "\n",
    "# --- 3. Dataset Definition for Evaluation ---\n",
    "\n",
    "class EvaluationPointCloudDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.file_pairs = []\n",
    "        input_files = glob.glob(os.path.join(folder_path, \"*_for_train.npy\"))\n",
    "        \n",
    "        for input_path in input_files:\n",
    "            label_path = input_path.replace(\"_for_train.npy\", \"_path_loss.npy\")\n",
    "            if os.path.exists(label_path):\n",
    "                self.file_pairs.append((input_path, label_path))\n",
    "            else:\n",
    "                print(f\"Warning: Missing label for {input_path}. Skipping file.\")\n",
    "        if not self.file_pairs:\n",
    "            print(f\"Warning: No valid file pairs found in {folder_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, label_path = self.file_pairs[idx]\n",
    "        pc_data = np.load(input_path).astype(np.float32)\n",
    "        label_original_float = np.load(label_path).astype(np.float32)\n",
    "        \n",
    "        pc_tensor = torch.from_numpy(pc_data)\n",
    "        label_original_tensor = torch.from_numpy(label_original_float).squeeze()\n",
    "        \n",
    "        # Also return the class index for calculating rounded truth\n",
    "        label_class_tensor = pl_to_class(label_original_tensor)\n",
    "        \n",
    "        return pc_tensor, label_class_tensor, label_original_tensor\n",
    "\n",
    "# --- 4. Model Definitions (CLASSIFIER VERSION) ---\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, pos_dim=3, feat_dim=4, feature_dim_out=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.conv1_pos = nn.Conv1d(pos_dim, 64, 1)\n",
    "        self.conv2_pos = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_pos = nn.BatchNorm1d(64)\n",
    "        self.bn2_pos = nn.BatchNorm1d(128)\n",
    "        self.conv1_feat = nn.Conv1d(feat_dim, 64, 1)\n",
    "        self.conv2_feat = nn.Conv1d(64, 128, 1)\n",
    "        self.bn1_feat = nn.BatchNorm1d(64)\n",
    "        self.bn2_feat = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv4 = nn.Conv1d(512, feature_dim_out, 1) # -> 512\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.bn4 = nn.BatchNorm1d(feature_dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos_stream = x[:, :3, :]\n",
    "        feat_stream = x[:, 3:, :]\n",
    "        pos_out = F.relu(self.bn1_pos(self.conv1_pos(pos_stream)))\n",
    "        pos_out = F.relu(self.bn2_pos(self.conv2_pos(pos_out)))\n",
    "        feat_out = F.relu(self.bn1_feat(self.conv1_feat(feat_stream)))\n",
    "        feat_out = F.relu(self.bn2_feat(self.conv2_feat(feat_out)))\n",
    "        combined = torch.cat([pos_out, feat_out], dim=1)\n",
    "        x = F.relu(self.bn3(self.conv3(combined)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.max(x, 2)[0] # -> (batch, 512)\n",
    "        return x\n",
    "\n",
    "class PointNetPathLoss(nn.Module):\n",
    "    def __init__(self, input_dim_pos=3, input_dim_feat=4, feature_dim_encoder=FEATURE_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(\n",
    "            pos_dim=input_dim_pos, \n",
    "            feat_dim=input_dim_feat, \n",
    "            feature_dim_out=feature_dim_encoder\n",
    "        )\n",
    "        self.fc1 = nn.Linear(feature_dim_encoder, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, NUM_CLASSES) # -> 31 outputs\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x) # -> (batch, 31)\n",
    "        return x # Return logits\n",
    "\n",
    "# --- 5. Main Evaluation Script ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = PointNetPathLoss().to(device)\n",
    "    print(\"Model initialized (Classifier).\")\n",
    "\n",
    "    if not os.path.exists(MODEL_SAVE_PATH):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {MODEL_SAVE_PATH}.\")\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        print(f\"Successfully loaded model weights from {MODEL_SAVE_PATH}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading checkpoint: {e}. Ensure model definition matches checkpoint.\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions_rounded = []\n",
    "    all_labels_rounded = []\n",
    "    all_labels_original = [] # For the CSV\n",
    "\n",
    "    print(\"\\n--- Starting Evaluation ---\")\n",
    "    \n",
    "    for folder_name in TEST_DATA_FOLDERS:\n",
    "        print(f\"\\n▶ Processing folder: {folder_name}\")\n",
    "        folder_path = os.path.join(BASE_TRAIN_DIR, folder_name)\n",
    "        \n",
    "        test_dataset = EvaluationPointCloudDataset(folder_path=folder_path)\n",
    "        if len(test_dataset) == 0:\n",
    "            print(\"  -> No files found. Skipping folder.\")\n",
    "            continue\n",
    "            \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "            num_workers=NUM_WORKERS, pin_memory=(device.type == 'cuda')\n",
    "        )\n",
    "        \n",
    "        # Lists for this folder's results\n",
    "        folder_preds_list = []\n",
    "        folder_true_rounded_list = []\n",
    "        folder_true_original_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for pc_batch, label_class_batch, label_original_batch in tqdm(test_loader, desc=\"  Evaluating\"):\n",
    "                pc_batch = pc_batch.to(device)\n",
    "                label_class_batch = label_class_batch.to(device) # True class index\n",
    "                # label_original_batch stays on CPU, we just need it for the CSV\n",
    "                \n",
    "                out_logits = model(pc_batch) # -> (batch, 31)\n",
    "                \n",
    "                # Get predicted class index\n",
    "                _, predicted_class_idx = torch.max(out_logits, 1)\n",
    "                \n",
    "                # --- Convert indices back to dB values for RMSE and CSV ---\n",
    "                predicted_pl = class_to_pl(predicted_class_idx)\n",
    "                true_rounded_pl = class_to_pl(label_class_batch)\n",
    "                \n",
    "                # Store results\n",
    "                folder_preds_list.append(predicted_pl.cpu().numpy())\n",
    "                folder_true_rounded_list.append(true_rounded_pl.cpu().numpy())\n",
    "                folder_true_original_list.append(label_original_batch.cpu().numpy())\n",
    "        \n",
    "        # Concatenate all batch results\n",
    "        predictions = np.concatenate(folder_preds_list)\n",
    "        labels_rounded = np.concatenate(folder_true_rounded_list)\n",
    "        labels_original = np.concatenate(folder_true_original_list)\n",
    "        \n",
    "        all_predictions_rounded.append(predictions)\n",
    "        all_labels_rounded.append(labels_rounded)\n",
    "        \n",
    "        # Calculate folder-specific RMSE using ROUNDED values\n",
    "        folder_mse = np.mean((predictions - labels_rounded)**2)\n",
    "        folder_rmse = np.sqrt(folder_mse)\n",
    "        print(f\"  -> Folder RMSE (on rounded values): {folder_rmse:8.4f} dB\")\n",
    "        \n",
    "        # --- Create and Save CSV ---\n",
    "        match = re.match(r\"(\\w+)_processed__for_training_Tx_(\\d+)\", folder_name)\n",
    "        if not match:\n",
    "            print(f\"  -> ERROR: Could not parse folder name '{folder_name}'. Skipping CSV save.\")\n",
    "            continue\n",
    "            \n",
    "        freq = match.group(1)\n",
    "        tx_id = match.group(2)\n",
    "        \n",
    "        csv_filename = f\"test_{freq}_Tx_{tx_id}.csv\"\n",
    "        csv_save_path = os.path.join(TEST_SAVE_DIR, csv_filename)\n",
    "        \n",
    "        # Create DataFrame with the 3 requested columns\n",
    "        results_df = pd.DataFrame({\n",
    "            'predicted_pathloss': predictions,\n",
    "            'true_pathloss_rounded': labels_rounded,\n",
    "            'original_pathloss': labels_original\n",
    "        })\n",
    "        \n",
    "        results_df.to_csv(csv_save_path, index=False)\n",
    "        print(f\"  -> Results saved to: {csv_save_path}\")\n",
    "\n",
    "    # --- Calculate and Print Overall RMSE ---\n",
    "    if all_predictions_rounded:\n",
    "        overall_preds = np.concatenate(all_predictions_rounded)\n",
    "        overall_labels = np.concatenate(all_labels_rounded)\n",
    "        \n",
    "        overall_mse = np.mean((overall_preds - overall_labels)**2)\n",
    "        overall_rmse = np.sqrt(overall_mse)\n",
    "        \n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(f\"Overall Test RMSE (on rounded values): {overall_rmse:8.4f} dB\")\n",
    "    else:\n",
    "        print(\"\\n--- Evaluation Complete ---\")\n",
    "        print(\"No test data was processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
